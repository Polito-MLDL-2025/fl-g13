{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffbee39c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T11:05:02.010180Z",
     "start_time": "2025-04-20T11:05:01.921351Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f52dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T11:05:09.664366Z",
     "start_time": "2025-04-20T11:05:03.864851Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-23 20:03:13.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfl_g13.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /home/massimiliano/Projects/fl-g13\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.optim as optim\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, RandomCrop, RandomHorizontalFlip, RandomVerticalFlip, Normalize, ToTensor\n",
    "\n",
    "from fl_g13.config import RAW_DATA_DIR\n",
    "from fl_g13.modeling import train, eval, save, load, backup\n",
    "from fl_g13.dataset import train_test_split\n",
    "\n",
    "from fl_g13.architectures import BaseDino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f11d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 40000\n",
      "Validation dataset size: 10000\n",
      "Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "# Define preprocessing pipeline\n",
    "train_transform = Compose([\n",
    "    Resize(256), # CIFRA100 is originally 32x32\n",
    "    RandomCrop(224), # But Dino works on 224x224\n",
    "    RandomHorizontalFlip(),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5071, 0.4866, 0.4409], std=[0.2673, 0.2564, 0.2762]),\n",
    "])\n",
    "\n",
    "eval_transform = Compose([\n",
    "    Resize(256), # CIFRA100 is originally 32x32\n",
    "    CenterCrop(224), # But Dino works on 224x224\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5071, 0.4866, 0.4409], std=[0.2673, 0.2564, 0.2762]),\n",
    "])\n",
    "\n",
    "cifar100_train = datasets.CIFAR100(root=RAW_DATA_DIR, train=True, download=True, transform=train_transform)\n",
    "cifar100_test = datasets.CIFAR100(root=RAW_DATA_DIR, train=False, download=True, transform=eval_transform)\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(cifar100_train, 0.8, random_state=None)\n",
    "test_dataset = cifar100_test\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "349a5230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/massimiliano/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading checkpoint from /home/massimiliano/Projects/fl-g13/checkpoints/BaseDino/arceus_BaseDino_epoch_80.pth\n",
      "üì¶ Model class in checkpoint: BaseDino\n",
      "‚öôÔ∏è Optimizer class in checkpoint: SGD\n",
      "üìà Scheduler class in checkpoint: CosineAnnealingWarmRestarts\n",
      "üîß Model configuration: {'variant': 'dino_vits16', 'dropout_rate': 0.1, 'head_hidden_size': 1024, 'head_layers': 5, 'num_classes': 100, 'unfreeze_blocks': 3, 'activation_fn': 'GELU', 'pretrained': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/massimiliano/.cache/torch/hub/facebookresearch_dino_main\n",
      "Using cache found in /home/massimiliano/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded checkpoint from /home/massimiliano/Projects/fl-g13/checkpoints/BaseDino/arceus_BaseDino_epoch_80.pth, resuming at epoch 81\n",
      "\n",
      "Model: BaseDino(\n",
      "  (net): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "    (head): Sequential(\n",
      "      (0): Linear(in_features=384, out_features=1024, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (4): GELU(approximate='none')\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (7): GELU(approximate='none')\n",
      "      (8): Dropout(p=0.1, inplace=False)\n",
      "      (9): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (10): GELU(approximate='none')\n",
      "      (11): Dropout(p=0.1, inplace=False)\n",
      "      (12): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (13): GELU(approximate='none')\n",
      "      (14): Dropout(p=0.1, inplace=False)\n",
      "      (15): Linear(in_features=1024, out_features=100, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "CHECKPOINT_DIR = \"/home/massimiliano/Projects/fl-g13/checkpoints\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "start_epoch=1\n",
    "num_epochs=30\n",
    "save_every=3\n",
    "backup_every=10\n",
    "\n",
    "# Hyper-parameters\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-2\n",
    "\n",
    "# Dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Optimizer, scheduler, and loss function\n",
    "model = BaseDino()\n",
    "model.to(device)\n",
    "optimizer = SGD(model.parameters(), lr=LR)\n",
    "scheduler = CosineAnnealingWarmRestarts(\n",
    "    optimizer, \n",
    "    T_0=8,           # First restart after 8 epochs\n",
    "    T_mult=2,        # Double the interval between restarts each time\n",
    "    eta_min=1e-5     # Minimum learning rate after annealing\n",
    ")\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Model loading (uncomment to properly overwrite)\n",
    "model, start_epoch = load(\n",
    "    f\"{CHECKPOINT_DIR}/BaseDino/arceus_BaseDino_epoch_80.pth\",\n",
    "    model_class=BaseDino,\n",
    "    device=device,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    verbose=True\n",
    ")\n",
    "model.to(device)\n",
    "print(f\"\\nModel: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db93142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preallocated lists: if the training interrupts, it will still save their values\n",
    "all_training_losses=[]       # Pre-allocated list for training losses\n",
    "all_validation_losses=[]     # Pre-allocated list for validation losses\n",
    "all_training_accuracies=[]   # Pre-allocated list for training accuracies\n",
    "all_validation_accuracies=[] # Pre-allocated list for validation accuracies\n",
    "\n",
    "name = \"arceus\"\n",
    "\n",
    "try:\n",
    "    _, _, _, _ = train(\n",
    "        checkpoint_dir=CHECKPOINT_DIR,\n",
    "        name=name,\n",
    "        start_epoch=start_epoch,\n",
    "        num_epochs=num_epochs,\n",
    "        save_every=save_every,\n",
    "        backup_every=backup_every,\n",
    "        train_dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        verbose=False,\n",
    "        all_training_losses=all_training_losses,\n",
    "        all_validation_losses=all_validation_losses,\n",
    "        all_training_accuracies=all_training_accuracies,\n",
    "        all_validation_accuracies=all_validation_accuracies,\n",
    "    )\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted manually. Backing up latest checkpoint...\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Training stopped due to error: {e}\")\n",
    "\n",
    "finally:\n",
    "    # This always runs no matter what (hopefully)\n",
    "    #backup(f\"{CHECKPOINT_DIR}\") # Backup the final checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca9191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot losses\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(all_training_losses, label='Training Loss')\n",
    "plt.plot(all_validation_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracies\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(all_training_accuracies, label='Training Accuracy')\n",
    "plt.plot(all_validation_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d39924a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Test Results:\n",
      "\tüìâ Test Loss: 2.9130\n",
      "\tüéØ Test Accuracy: 45.19%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation dataset\n",
    "test_loss, test_accuracy, _ = eval(dataloader=test_dataloader, model=model, criterion=criterion)\n",
    "\n",
    "print(\n",
    "    f\"üîç Test Results:\\n\"\n",
    "    f\"\\tüìâ Test Loss: {test_loss:.4f}\\n\"\n",
    "    f\"\\tüéØ Test Accuracy: {100 * test_accuracy:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa81a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-g13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
