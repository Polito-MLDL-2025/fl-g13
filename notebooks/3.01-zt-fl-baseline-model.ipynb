{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T17:08:22.371607Z",
     "start_time": "2025-04-20T17:08:22.269190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "5767f6b1a63e945b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T17:08:24.172094Z",
     "start_time": "2025-04-20T17:08:22.373607Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
   "id": "75ca9d6d54c4ce47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T17:08:30.519122Z",
     "start_time": "2025-04-20T17:08:24.173536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fl_g13.config import RAW_DATA_DIR\n",
    "\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from fl_g13 import dataset as dataset_handler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import flwr\n",
    "from flwr.common import Context\n",
    "\n",
    "from flwr.simulation import run_simulation\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-04-20 19:08:24.280\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mfl_g13.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T17:08:30.930539Z",
     "start_time": "2025-04-20T17:08:30.521125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# DEVICE = \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "# disable_progress_bar()"
   ],
   "id": "1a4ec3eb7baf32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Flower 1.17.0 / PyTorch 2.6.0+cu118\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load data",
   "id": "73fb84b164b0def7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T17:08:32.499804Z",
     "start_time": "2025-04-20T17:08:30.932540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "cifar100_train = datasets.CIFAR100(root=RAW_DATA_DIR, train=True, download=True, transform=transform)\n",
    "cifar100_test = datasets.CIFAR100(root=RAW_DATA_DIR, train=False, download=True, transform=transform)"
   ],
   "id": "6c6449ef9be1e422",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T17:08:32.866714Z",
     "start_time": "2025-04-20T17:08:32.500680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### train val split\n",
    "train_dataset,val_dataset = dataset_handler.train_test_split(cifar100_train,train_ratio=0.8)"
   ],
   "id": "a218d880822fdfba",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T17:08:33.247554Z",
     "start_time": "2025-04-20T17:08:32.868280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I.I.D Sharding Split\n",
    "## k client\n",
    "k =10\n",
    "clients_dataset_train= dataset_handler.iid_sharding(train_dataset,k)\n",
    "clients_dataset_val= dataset_handler.iid_sharding(val_dataset,k)"
   ],
   "id": "1e23159840c6708d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tiny model",
   "id": "3ef53dc011fa9499"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T17:08:33.626460Z",
     "start_time": "2025-04-20T17:08:33.248733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TinyCNN(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(TinyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))     # -> [B, 16, 32, 32]\n",
    "        x = F.max_pool2d(x, 2)        # -> [B, 16, 16, 16]\n",
    "        x = F.relu(self.conv2(x))     # -> [B, 32, 16, 16]\n",
    "        x = F.max_pool2d(x, 2)        # -> [B, 32, 8, 8]\n",
    "        x = x.view(x.size(0), -1)     # -> [B, 32*8*8]\n",
    "        x = self.fc1(x)               # -> [B, 100]\n",
    "        return x"
   ],
   "id": "fa219247a8a9d7c9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Init model , optimizer and loss function",
   "id": "4c0f23c3615c6d68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T17:08:34.402965Z",
     "start_time": "2025-04-20T17:08:33.627868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from fl_g13.architectures import BaseDino\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.optim import SGD\n",
    "\n",
    "# net = TinyCNN().to(DEVICE)\n",
    "# # optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "# optimizer = torch.optim.AdamW(net.parameters(), lr=1e-4, weight_decay=0.04)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "start_epoch=1\n",
    "num_epochs=50\n",
    "save_every=1\n",
    "backup_every=10\n",
    "\n",
    "# Hyper-parameters\n",
    "BATCH_SIZE = 128\n",
    "LR = 1e-2\n",
    "\n",
    "\n",
    "# Model\n",
    "model = BaseDino()\n",
    "model.to(DEVICE)\n",
    "print(f\"Model: {model}\")\n",
    "\n",
    "# Optimizer, scheduler, and loss function\n",
    "optimizer = SGD(model.parameters(), lr=LR)\n",
    "scheduler = CosineAnnealingWarmRestarts(\n",
    "    optimizer, \n",
    "    T_0=8,           # First restart after 8 epochs\n",
    "    T_mult=2,        # Double the interval between restarts each time\n",
    "    eta_min=1e-5     # Minimum learning rate after annealing\n",
    ")\n",
    "criterion = CrossEntropyLoss()"
   ],
   "id": "9046d19b28a38ed3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: BaseDino(\n",
      "  (net): VisionTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (blocks): ModuleList(\n",
      "      (0-11): 12 x Block(\n",
      "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "          (attn_drop): Dropout(p=0.1, inplace=False)\n",
      "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (proj_drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "    (head): Sequential(\n",
      "      (0): Linear(in_features=384, out_features=1024, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "      (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (4): GELU(approximate='none')\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (7): GELU(approximate='none')\n",
      "      (8): Dropout(p=0.1, inplace=False)\n",
      "      (9): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (10): GELU(approximate='none')\n",
      "      (11): Dropout(p=0.1, inplace=False)\n",
      "      (12): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (13): GELU(approximate='none')\n",
      "      (14): Dropout(p=0.1, inplace=False)\n",
      "      (15): Linear(in_features=1024, out_features=100, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define the ClientApp",
   "id": "e73656b5d73ac995"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build module local\n",
    "\n",
    "Build module local such that ClientApp can use it"
   ],
   "id": "b5a0319c8e40215a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T19:17:09.344940Z",
     "start_time": "2025-04-20T19:17:03.207722Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -e ..",
   "id": "8a11402a3317027f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/ADMIN/Desktop/BACKUP/study/Italy/polito/classes/20242/deep%20learning/project/source_code/fl-g13\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: fl_g13\n",
      "  Building editable for fl_g13 (pyproject.toml): started\n",
      "  Building editable for fl_g13 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for fl_g13: filename=fl_g13-0.0.1-py3-none-any.whl size=4649 sha256=a588eeccbccdbea56dbfe92e55bd612babd81e07366f39e361ccc99a5ffdec08\n",
      "  Stored in directory: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-we99gvxy\\wheels\\b7\\e0\\6d\\5d22ced2ef400b314cfe74883357cc37e1e1d5275e7ba9175e\n",
      "Successfully built fl_g13\n",
      "Installing collected packages: fl_g13\n",
      "  Attempting uninstall: fl_g13\n",
      "    Found existing installation: fl_g13 0.0.1\n",
      "    Uninstalling fl_g13-0.0.1:\n",
      "      Successfully uninstalled fl_g13-0.0.1\n",
      "Successfully installed fl_g13-0.0.1\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## create FlowerClient instances  ",
   "id": "97c881019a2b9e21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T17:08:40.449846Z",
     "start_time": "2025-04-20T17:08:40.054607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Function load data client is to simulate the distribution data into each client\n",
    "In the real case, each client will have its dataset\n",
    "'''\n",
    "def load_data_client(context: Context):\n",
    "    partition_id = context.node_config[\"partition-id\"] \n",
    "    print(f\"Client {partition_id} is ready to train\")\n",
    "    trainloader = DataLoader(clients_dataset_train[partition_id])\n",
    "    valloader = DataLoader(clients_dataset_val[partition_id])\n",
    "    return trainloader, valloader"
   ],
   "id": "f05bbd371d1a87d9",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create instant of ClientApp",
   "id": "babef0c5a1343937"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T17:08:41.759994Z",
     "start_time": "2025-04-20T17:08:40.451290Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fl_g13.fl_pytorch.client_app import get_client_app\n",
    "\n",
    "config={'local-epochs':1}\n",
    "client = get_client_app(load_data_client,model=model,optimizer=optimizer,criterion=criterion,device=DEVICE,config=config)"
   ],
   "id": "70467a37aa8c09c7",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Define the Flower ServerApp\n",
    "\n",
    "Customize built-in strategy Federated Averaging (FedAvg) of Flower to combine hyperparams in server-side and save model for each k epoch\n",
    "\n",
    "The strategy could also incremental training an"
   ],
   "id": "5ccd8dfd409b0385"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create instant of ServerApp",
   "id": "6f9276503ee2d47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T19:17:12.956631Z",
     "start_time": "2025-04-20T19:17:11.350698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from fl_g13.fl_pytorch.server_app import get_server_app\n",
    "\n",
    "def get_datatest_fn(context: Context):\n",
    "    return DataLoader(cifar100_test)\n",
    "\n",
    "## checkpoints directory\n",
    "current_path = Path.cwd()\n",
    "model_test_path = current_path / \"../models/fl_baseline\"\n",
    "model_test_path.resolve()\n",
    "\n",
    "\n",
    "num_rounds=2\n",
    "save_every =1\n",
    "fraction_fit=1.0  # Sample 100% of available clients for training\n",
    "fraction_evaluate=0.5  # Sample 50% of available clients for evaluation\n",
    "min_fit_clients=10  # Never sample less than 10 clients for training\n",
    "min_evaluate_clients=5  # Never sample less than 5 clients for evaluation\n",
    "min_available_clients=10  # Wait until all 10 clients are available\n",
    "device=DEVICE\n",
    "use_wandb=False\n",
    "\n",
    "\n",
    "server = get_server_app(checkpoint_dir=model_test_path.resolve(),\n",
    "                        model_class=BaseDino,\n",
    "                        optimizer=optimizer,\n",
    "                        criterion=criterion, \n",
    "                        scheduler=scheduler,\n",
    "                        get_datatest_fn=get_datatest_fn,\n",
    "                        num_rounds=num_rounds,\n",
    "                        fraction_fit=fraction_fit, \n",
    "                        fraction_evaluate=fraction_evaluate,  \n",
    "                        min_fit_clients=min_fit_clients,  \n",
    "                        min_evaluate_clients=min_evaluate_clients, \n",
    "                        min_available_clients=min_available_clients, \n",
    "                        device=device,\n",
    "                        use_wandb=use_wandb,\n",
    "                        save_every=save_every\n",
    "                        )"
   ],
   "id": "1cbac220e52a6d00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_baseline\\FL_BaseDino_epoch_1.pth\n",
      "📦 Model class in checkpoint: BaseDino\n",
      "🔧 Model configuration: {'variant': 'dino_vits16', 'dropout_rate': 0.1, 'head_hidden_size': 1024, 'head_layers': 5, 'num_classes': 100, 'unfreeze_blocks': 3, 'activation_fn': 'GELU', 'pretrained': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n",
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_baseline\\FL_BaseDino_epoch_1.pth, resuming at epoch 2\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run the training\n",
   "id": "1427a966f7544b94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T19:18:03.961765Z",
     "start_time": "2025-04-20T19:18:03.209351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if DEVICE == \"cuda\":\n",
    "    backend_config[\"client_resources\"]= {\"num_cpus\": 1, \"num_gpus\": 1}\n",
    "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
    "    # and how to set up the `backend_config`"
   ],
   "id": "1388e3308f7b212b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Download missing module for clients\n",
    "\n",
    "Dino model,that is serialized and sent to client by server, require some modules that have to download from source code of dino model\n"
   ],
   "id": "9399f1a9cedc8cc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T19:20:39.666310Z",
     "start_time": "2025-04-20T19:20:39.135376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "def download_if_not_exists(file_path: str, file_url: str):\n",
    "    \"\"\"\n",
    "    Checks if a file exists at the given path. If it does not, downloads it from the specified URL.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The local path to check and save the file.\n",
    "    - file_url (str): The URL from which to download the file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"'{file_path}' not found. Downloading from {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "            print(\"Download complete.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download file: {e}\")\n",
    "    else:\n",
    "        print(f\"'{file_path}' already exists.\")"
   ],
   "id": "beb2c855fcd8933c",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T19:21:33.089423Z",
     "start_time": "2025-04-20T19:21:32.462132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "download_if_not_exists(\"vision_transformer.py\", \"wget https://raw.githubusercontent.com/facebookresearch/dino/refs/heads/main/vision_transformer.py\")\n",
    "download_if_not_exists(\"utils.py\", \"wget https://raw.githubusercontent.com/facebookresearch/dino/refs/heads/main/utils.py\")\n"
   ],
   "id": "d93caca63a33c71f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'vision_transformer.py' already exists.\n",
      "'utils.py' already exists.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9a1db478a3e1221"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T19:21:38.403171Z",
     "start_time": "2025-04-20T19:21:37.630672Z"
    }
   },
   "cell_type": "code",
   "source": "NUM_CLIENTS =10",
   "id": "23d2a1e147f59ffc",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T19:44:53.725904Z",
     "start_time": "2025-04-20T19:21:39.054941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ],
   "id": "1451e826d4713ec9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue train model from epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      Starting Flower ServerApp, config: num_rounds=2, no round_timeout\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [INIT]\n",
      "\u001B[92mINFO \u001B[0m:      Using initial global parameters provided by strategy\n",
      "\u001B[92mINFO \u001B[0m:      Starting evaluation of initial global parameters\n",
      "\u001B[92mINFO \u001B[0m:      ROUND 0💡 New best global model found: 0.010000\n",
      "\u001B[92mINFO \u001B[0m:      initial parameters (loss, other metrics): 5.092082308197021, {'centralized_accuracy': 0.01}\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 1]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 2025-04-20 21:23:43.310 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 0 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: itchy_kakuna_98\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 5.3544\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 0.90%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 44.55s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:24\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 1 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: jazzy_pikachu_20\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 5.3812\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 0.92%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 42.50s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:25\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 2 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: giddy_charizard_50\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 5.3695\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 1.10%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 43.24s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:26\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 3 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: chirpy_pikachu_48\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 5.3712\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 0.85%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 44.68s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:26\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 4 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: grumpy_spearow_94\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 5.3602\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 0.73%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 47.89s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:27\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 5 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: spooky_clefairy_63\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 5.3502\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 0.90%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 47.09s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:28\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 6 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: spooky_pidgeot_39\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 5.3537\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 0.90%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 42.04s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:29\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 7 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: groovy_arbok_35\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 5.3458\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 1.20%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 43.84s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:29\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 8 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: peppy_butterfree_72\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 5.3658\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 0.80%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 49.03s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:30\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 9 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: sassy_raticate_87\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 5.3776\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 0.85%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 45.03s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:31\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001B[93mWARNING \u001B[0m:   No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving centralized model epoch 2 aggregated_parameters...\n",
      "💾 Saved checkpoint at: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_baseline\\FL_BaseDino_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      fit progress: (1, 4.665144852542877, {'centralized_accuracy': 0.0086}, 593.6897047999992)\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 1 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 2 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 3 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 5 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 8 is ready to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 2]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 0 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: jumpy_ekans_59\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 4.9584\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 1.07%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 49.23s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:35\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 1 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: perky_clefairy_27\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 4.9642\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 0.88%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 45.22s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:35\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 2 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: quirky_raichu_12\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 4.9543\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 1.10%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 43.51s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:36\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 3 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: wacky_metapod_37\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 4.9742\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 0.78%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 42.24s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:37\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 4 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: spooky_charmander_28\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 4.9531\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 1.23%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 44.05s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:38\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 5 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: jolly_venusaur_51\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 4.9584\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 0.85%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 49.64s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:39\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 6 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: zippy_clefairy_16\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 4.9515\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 1.30%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 48.56s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:39\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 7 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: cheeky_beedrill_33\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 4.9661\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 1.05%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 44.20s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:40\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 8 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: peppy_venusaur_17\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 4.9683\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 0.88%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 46.26s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:41\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 9 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: silly_nidoqueen_63\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m 🚀 Epoch 1/1 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t📊 Training Loss: 4.9589\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t✅ Training Accuracy: 1.00%\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t⏳ Elapsed Time: 46.97s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \t🕒 Completed At: 21:42\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving centralized model epoch 3 aggregated_parameters...\n",
      "💾 Saved checkpoint at: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_baseline\\FL_BaseDino_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      fit progress: (2, 4.645598405885696, {'centralized_accuracy': 0.01}, 1233.8158471999996)\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 0 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 3 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 4 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 7 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=10356)\u001B[0m Client 9 is ready to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [SUMMARY]\n",
      "\u001B[92mINFO \u001B[0m:      Run finished 2 round(s) in 1273.77s\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, distributed):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 4.867536987304687\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 4.804164573812485\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, centralized):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 0: 5.092082308197021\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 4.665144852542877\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 4.645598405885696\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'federated_evaluate_accuracy': [(1, 0.0102), (2, 0.0114)]}\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, centralized):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'centralized_accuracy': [(0, 0.01), (1, 0.0086), (2, 0.01)]}\n",
      "\u001B[92mINFO \u001B[0m:      \n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b34bb388cc930f5f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
