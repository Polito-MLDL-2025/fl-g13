{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:24.486308Z",
     "start_time": "2025-04-15T14:36:19.255218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install -U ipywidgets\n",
    "!pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision matplotlib\n"
   ],
   "id": "31cad28d1db9e384",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (8.1.6)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from ipywidgets) (8.35.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.14 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from ipywidgets) (3.0.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.13.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:24.502293Z",
     "start_time": "2025-04-15T14:36:24.488293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "current_directory\n",
    "sys.path.append(current_directory+'\\\\..\\\\fl_g13')"
   ],
   "id": "f9529e6e92f3d5af",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:31.213456Z",
     "start_time": "2025-04-15T14:36:24.504295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fl_g13.modeling.test import test_model\n",
    "from fl_g13.modeling.train import train_model\n",
    "from fl_g13.config import RAW_DATA_DIR\n",
    "from collections import OrderedDict\n",
    "from typing import List\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from collections import Counter\n",
    "\n",
    "from fl_g13.base_experimentation import dataset_handler\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import flwr\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Metrics, Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr_datasets import FederatedDataset\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-04-15 16:36:24.531\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mfl_g13.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:31.245122Z",
     "start_time": "2025-04-15T14:36:31.214454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "# disable_progress_bar()"
   ],
   "id": "1a4ec3eb7baf32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Flower 1.17.0 / PyTorch 2.6.0+cu118\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load data",
   "id": "73fb84b164b0def7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:31.944604Z",
     "start_time": "2025-04-15T14:36:31.247122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "cifar100_train = datasets.CIFAR100(root=RAW_DATA_DIR, train=True, download=True, transform=transform)"
   ],
   "id": "6c6449ef9be1e422",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:31.976582Z",
     "start_time": "2025-04-15T14:36:31.945596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### train val split\n",
    "train_dataset,val_dataset = dataset_handler.train_test_split(cifar100_train,train_ratio=0.8)"
   ],
   "id": "a218d880822fdfba",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:31.992582Z",
     "start_time": "2025-04-15T14:36:31.977566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I.I.D Sharding Split\n",
    "## k client\n",
    "k =10\n",
    "clients_dataset_train= dataset_handler.iid_sharding(train_dataset,k)\n",
    "clients_dataset_val= dataset_handler.iid_sharding(val_dataset,k)"
   ],
   "id": "1e23159840c6708d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:32.243864Z",
     "start_time": "2025-04-15T14:36:31.993565Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_handler.check_subset_distribution(clients_dataset_train[2])",
   "id": "e97d620dd73e7141",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({63: 57,\n",
       "         8: 53,\n",
       "         2: 50,\n",
       "         32: 50,\n",
       "         33: 49,\n",
       "         83: 49,\n",
       "         9: 49,\n",
       "         70: 48,\n",
       "         40: 48,\n",
       "         59: 47,\n",
       "         20: 47,\n",
       "         85: 47,\n",
       "         38: 46,\n",
       "         23: 46,\n",
       "         37: 46,\n",
       "         81: 45,\n",
       "         89: 45,\n",
       "         14: 45,\n",
       "         34: 45,\n",
       "         48: 45,\n",
       "         45: 45,\n",
       "         68: 44,\n",
       "         76: 44,\n",
       "         42: 44,\n",
       "         6: 44,\n",
       "         95: 44,\n",
       "         0: 43,\n",
       "         29: 43,\n",
       "         30: 43,\n",
       "         82: 43,\n",
       "         47: 42,\n",
       "         31: 42,\n",
       "         73: 42,\n",
       "         67: 42,\n",
       "         4: 42,\n",
       "         54: 42,\n",
       "         62: 42,\n",
       "         78: 42,\n",
       "         19: 42,\n",
       "         96: 41,\n",
       "         92: 41,\n",
       "         94: 41,\n",
       "         11: 41,\n",
       "         99: 41,\n",
       "         7: 41,\n",
       "         35: 40,\n",
       "         84: 40,\n",
       "         24: 40,\n",
       "         41: 40,\n",
       "         64: 39,\n",
       "         44: 39,\n",
       "         58: 39,\n",
       "         46: 39,\n",
       "         90: 39,\n",
       "         80: 39,\n",
       "         12: 39,\n",
       "         36: 39,\n",
       "         18: 39,\n",
       "         69: 38,\n",
       "         86: 38,\n",
       "         74: 38,\n",
       "         22: 38,\n",
       "         13: 38,\n",
       "         21: 38,\n",
       "         98: 38,\n",
       "         60: 38,\n",
       "         87: 38,\n",
       "         15: 37,\n",
       "         52: 37,\n",
       "         55: 37,\n",
       "         25: 37,\n",
       "         53: 37,\n",
       "         17: 37,\n",
       "         61: 37,\n",
       "         51: 36,\n",
       "         75: 36,\n",
       "         77: 36,\n",
       "         1: 36,\n",
       "         27: 36,\n",
       "         3: 36,\n",
       "         16: 36,\n",
       "         66: 36,\n",
       "         39: 36,\n",
       "         5: 35,\n",
       "         10: 35,\n",
       "         57: 34,\n",
       "         72: 34,\n",
       "         79: 34,\n",
       "         49: 33,\n",
       "         71: 33,\n",
       "         28: 33,\n",
       "         93: 33,\n",
       "         97: 33,\n",
       "         65: 32,\n",
       "         88: 31,\n",
       "         26: 31,\n",
       "         50: 31,\n",
       "         43: 30,\n",
       "         56: 28,\n",
       "         91: 26})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Update model parameters",
   "id": "5e8671a3a25de1ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:32.259859Z",
     "start_time": "2025-04-15T14:36:32.244868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
   ],
   "id": "5d5b32f2c4635aeb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define the ClientApp",
   "id": "e73656b5d73ac995"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:32.275793Z",
     "start_time": "2025-04-15T14:36:32.261863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from enum import Enum\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from loguru import logger\n",
    "from tqdm import tqdm\n",
    "import typer\n",
    "\n",
    "\n",
    "\n",
    "app = typer.Typer()\n",
    "\n",
    "class MODEL_DICTIONARY(Enum):\n",
    "    EPOCH = 'epoch'\n",
    "    MODEL_STATE_DICT = 'model_state_dict'\n",
    "    OPTIMIZER_STATE_DICT = 'optimizer_state_dict'\n",
    "\n",
    "\n",
    "def save_model(model, optimizer, checkpoint_dir, epoch=None, prefix_name=\"model\"):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    if epoch is None:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"{prefix_name}.pth\")\n",
    "    else:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"{prefix_name}_epoch_{epoch}.pth\")\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, checkpoint_path)\n",
    "\n",
    "    torch.save({\n",
    "        MODEL_DICTIONARY.EPOCH.value: epoch,\n",
    "        MODEL_DICTIONARY.MODEL_STATE_DICT.value: model.state_dict(),\n",
    "        MODEL_DICTIONARY.OPTIMIZER_STATE_DICT.value: optimizer.state_dict(),\n",
    "    }, checkpoint_path)\n",
    "\n",
    "    print(f\"💾 Saved checkpoint at: {checkpoint_path}\")\n",
    "\n",
    "\n",
    "def load_or_create_model(checkpoint_dir=None, model=None, optimizer=None, lr=1e-4, weight_decay=0.04, device=None):\n",
    "    if not checkpoint_dir and not model:\n",
    "        raise ValueError(\"Either checkpoint_dir or model must be provided.\")\n",
    "    if optimizer is None:\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    if not checkpoint_dir:\n",
    "        model.to(device)\n",
    "        return model, optimizer, 1\n",
    "\n",
    "    if not device:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if model is None:\n",
    "        vits16 = torch.hub.load('facebookresearch/dino:main', 'dino_vits16')\n",
    "        model = vits16\n",
    "        model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "    checkpoint_files = sorted(\n",
    "        glob.glob(os.path.join(checkpoint_dir, \"*.pth\")),\n",
    "        key=os.path.getmtime\n",
    "    )\n",
    "\n",
    "    if checkpoint_files:\n",
    "        # Load the latest checkpoint\n",
    "        latest_ckpt = checkpoint_files[-1]\n",
    "        checkpoint = torch.load(latest_ckpt, map_location=device)\n",
    "        model.load_state_dict(checkpoint[MODEL_DICTIONARY.MODEL_STATE_DICT.value])\n",
    "        optimizer.load_state_dict(checkpoint[MODEL_DICTIONARY.OPTIMIZER_STATE_DICT.value])\n",
    "        start_epoch = checkpoint[MODEL_DICTIONARY.EPOCH.value] + 1\n",
    "        print(f\"Loaded checkpoint from {latest_ckpt}, resuming at epoch {start_epoch}\")\n",
    "    else:\n",
    "        start_epoch = 1\n",
    "        print(f\"No checkpoint found, initializing new model from scratch.\")\n",
    "\n",
    "    return model, optimizer, start_epoch\n",
    "\n",
    "\n",
    "def _train(model, optimizer, dataloader, loss_fn, device, is_print=False):\n",
    "    # TODD\n",
    "    # print(\"Training...\")\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # print(f\"Batch {batch+1}/{len(dataloader)}\")\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(pred.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "        batch_acc = 100 * (predicted == y).sum().item() / y.size(0)\n",
    "        if is_print:\n",
    "            print(f\"  ↳ Batch {batch + 1}/{len(dataloader)} | Loss: {loss.item():.4f} | Batch Acc: {batch_acc:.2f}%\")\n",
    "\n",
    "    training_loss = total_loss / len(dataloader)\n",
    "    training_accuracy = 100 * correct / total\n",
    "    print(f\"Training Loss: {training_loss:.4f}, Training Accuracy: {training_accuracy:.2f}%\")\n",
    "    return training_loss, training_accuracy\n",
    "\n",
    "\n",
    "def train_model(checkpoint_dir, dataloader, loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                num_epochs=10, save_every=None, lr=1e-4, weight_decay=0.04,\n",
    "                model=None, optimizer=None, device=None, print_batch=False):\n",
    "\n",
    "    if not device:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model, optimizer, start_epoch = load_or_create_model(\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "    for epoch in range(start_epoch, num_epochs + 1):\n",
    "        avg_loss, training_accuracy = _train(model, optimizer, dataloader, loss_fn, device, print_batch)\n",
    "        print(f\"📘 Epoch [{epoch}/{num_epochs}] - Avg Loss: {avg_loss:.4f}, Accuracy: {training_accuracy:.2f}%\")\n",
    "\n",
    "        # 5. Save checkpoint\n",
    "        if save_every and epoch % save_every == 0:\n",
    "            save_model(model, optimizer, checkpoint_dir, epoch, prefix_name=\"dino_xcit\")\n",
    "\n"
   ],
   "id": "16b8d159c099dd55",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:32.291853Z",
     "start_time": "2025-04-15T14:36:32.276867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def test_model(model, dataloader, loss_fn,device=None):\n",
    "    # TODO\n",
    "    model.eval()\n",
    "    if not device:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    preds = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "    inputs = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = loss_fn(pred, y)\n",
    "\n",
    "\n",
    "            inputs.extend(X.cpu())\n",
    "            total_loss += loss.item()\n",
    "            original_pre = pred.cpu()\n",
    "            prob, predicted = torch.max(pred.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            preds.extend(predicted.cpu())\n",
    "            labels.extend(y.cpu())\n",
    "            probs.extend(prob.cpu())\n",
    "\n",
    "    test_loss = total_loss / len(dataloader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    preds = torch.tensor(preds)\n",
    "    labels = torch.tensor(labels)\n",
    "    probs = torch.tensor(probs)\n",
    "    return preds, labels, probs, inputs, test_accuracy,test_loss"
   ],
   "id": "bfd423079bc7478d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:32.307863Z",
     "start_time": "2025-04-15T14:36:32.292752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FlowerClient(NumPyClient):\n",
    "    def __init__(self, model, trainloader, valloader,loss_fn=torch.nn.CrossEntropyLoss(),optimizer=None):\n",
    "        self.model = model\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.loss_fn = loss_fn\n",
    "        if not optimizer:\n",
    "            optimizer = torch.optim.AdamW(self.model.parameters(), lr=1e-4, weight_decay=0.04)\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.model)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.model, parameters)\n",
    "        train_model(checkpoint_dir=None,dataloader= self.trainloader, num_epochs=1,save_every=None,model=self.model,optimizer=self.optimizer,loss_fn=self.loss_fn,print_batch=False)\n",
    "        return get_parameters(self.model), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.model, parameters)\n",
    "        preds, labels, probs, inputs, test_accuracy,test_loss = test_model(self.model, self.valloader, self.loss_fn)\n",
    "        return float(test_loss), len(self.valloader), {\"accuracy\": float(test_accuracy)}"
   ],
   "id": "b97170d792fb4ede",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tiny model",
   "id": "3ef53dc011fa9499"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:32.323747Z",
     "start_time": "2025-04-15T14:36:32.309751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TinyCNN(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(TinyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))     # -> [B, 16, 32, 32]\n",
    "        x = F.max_pool2d(x, 2)        # -> [B, 16, 16, 16]\n",
    "        x = F.relu(self.conv2(x))     # -> [B, 32, 16, 16]\n",
    "        x = F.max_pool2d(x, 2)        # -> [B, 32, 8, 8]\n",
    "        x = x.view(x.size(0), -1)     # -> [B, 32*8*8]\n",
    "        x = self.fc1(x)               # -> [B, 100]\n",
    "        return x"
   ],
   "id": "fa219247a8a9d7c9",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## create FlowerClient instances  ",
   "id": "97c881019a2b9e21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:32.339750Z",
     "start_time": "2025-04-15T14:36:32.325748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def client_fn(context: Context) -> Client:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "\n",
    "    # Load model\n",
    "    net = TinyCNN().to(DEVICE)\n",
    "\n",
    "    # Load data (CIFAR-10)\n",
    "    # Note: each client gets a different trainloader/valloader, so each client\n",
    "    # will train and evaluate on their own unique data partition\n",
    "    # Read the node_config to fetch data partition associated to this node\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(clients_dataset_train[partition_id])\n",
    "    valloader = torch.utils.data.DataLoader(clients_dataset_val[partition_id])\n",
    "    # Create a single Flower client representing a single organization\n",
    "    # FlowerClient is a subclass of NumPyClient, so we need to call .to_client()\n",
    "    # to convert it to a subclass of `flwr.client.Client`\n",
    "    return FlowerClient(net, trainloader, valloader).to_client()\n",
    "\n",
    "\n",
    "# Create the ClientApp\n",
    "client = ClientApp(client_fn=client_fn)"
   ],
   "id": "70467a37aa8c09c7",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Define the Flower ServerApp\n",
    "\n",
    "Using a built-in strategy Federated Averaging (FedAvg) of Flower to combine hyperparams in server-side"
   ],
   "id": "7e6751a34788524f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T19:54:00.230777Z",
     "start_time": "2025-04-15T19:53:58.919397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from flwr.common import FitRes, Scalar, Parameters\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from typing import Union, Optional\n",
    "\n",
    "net = TinyCNN().to(DEVICE)\n",
    "class SaveModelStrategy(flwr.server.strategy.FedAvg):\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: list[tuple[flwr.server.client_proxy.ClientProxy, flwr.common.FitRes]],\n",
    "        failures: list[Union[tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> tuple[Optional[Parameters], dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
    "\n",
    "        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
    "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(\n",
    "            server_round, results, failures\n",
    "        )\n",
    "\n",
    "        if aggregated_parameters is not None:\n",
    "            print(f\"Saving round {server_round} aggregated_parameters...\")\n",
    "\n",
    "            # Convert `Parameters` to `list[np.ndarray]`\n",
    "            aggregated_ndarrays: list[np.ndarray] = flwr.common.parameters_to_ndarrays(\n",
    "                aggregated_parameters\n",
    "            )\n",
    "\n",
    "            # Convert `list[np.ndarray]` to PyTorch `state_dict`\n",
    "            params_dict = zip(net.state_dict().keys(), aggregated_ndarrays)\n",
    "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "            net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "            # Save the model to disk\n",
    "            torch.save(net.state_dict(), f\"model_round_{server_round}.pth\")\n",
    "\n",
    "        return aggregated_parameters, aggregated_metrics\n",
    "\n"
   ],
   "id": "16637a84d8039c79",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TinyCNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mflwr\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mserver\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclient_proxy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ClientProxy\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtyping\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Union, Optional\n\u001B[1;32m----> 5\u001B[0m net \u001B[38;5;241m=\u001B[39m \u001B[43mTinyCNN\u001B[49m()\u001B[38;5;241m.\u001B[39mto(DEVICE)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mSaveModelStrategy\u001B[39;00m(flwr\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mFedAvg):\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21maggregate_fit\u001B[39m(\n\u001B[0;32m      8\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m      9\u001B[0m         server_round: \u001B[38;5;28mint\u001B[39m,\n\u001B[0;32m     10\u001B[0m         results: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mtuple\u001B[39m[flwr\u001B[38;5;241m.\u001B[39mserver\u001B[38;5;241m.\u001B[39mclient_proxy\u001B[38;5;241m.\u001B[39mClientProxy, flwr\u001B[38;5;241m.\u001B[39mcommon\u001B[38;5;241m.\u001B[39mFitRes]],\n\u001B[0;32m     11\u001B[0m         failures: \u001B[38;5;28mlist\u001B[39m[Union[\u001B[38;5;28mtuple\u001B[39m[ClientProxy, FitRes], \u001B[38;5;167;01mBaseException\u001B[39;00m]],\n\u001B[0;32m     12\u001B[0m     ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mtuple\u001B[39m[Optional[Parameters], \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Scalar]]:\n",
      "\u001B[1;31mNameError\u001B[0m: name 'TinyCNN' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:32.464067Z",
     "start_time": "2025-04-15T14:36:32.449089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create FedAvg strategy\n",
    "strategy = FedAvg(\n",
    "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
    "    fraction_evaluate=0.5,  # Sample 50% of available clients for evaluation\n",
    "    min_fit_clients=10,  # Never sample less than 10 clients for training\n",
    "    min_evaluate_clients=5,  # Never sample less than 5 clients for evaluation\n",
    "    min_available_clients=10,  # Wait until all 10 clients are available\n",
    ")"
   ],
   "id": "b1838fc99f2fd79",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create instant of ServerApp",
   "id": "6f9276503ee2d47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:32.480070Z",
     "start_time": "2025-04-15T14:36:32.466050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def server_fn(context: Context) -> ServerAppComponents:\n",
    "    \"\"\"Construct components that set the ServerApp behaviour.\n",
    "\n",
    "    You can use the settings in `context.run_config` to parameterize the\n",
    "    construction of all elements (e.g the strategy or the number of rounds)\n",
    "    wrapped in the returned ServerAppComponents object.\n",
    "    \"\"\"\n",
    "\n",
    "    # Configure the server for 5 rounds of training\n",
    "    config = ServerConfig(num_rounds=4)\n",
    "\n",
    "    return ServerAppComponents(strategy=strategy, config=config)\n",
    "\n",
    "\n",
    "# Create the ServerApp\n",
    "server = ServerApp(server_fn=server_fn)"
   ],
   "id": "1cbac220e52a6d00",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run the training\n",
   "id": "1427a966f7544b94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:32.495541Z",
     "start_time": "2025-04-15T14:36:32.481050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if DEVICE == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
    "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
    "    # and how to set up the `backend_config`"
   ],
   "id": "1388e3308f7b212b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9a1db478a3e1221"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:36:32.511562Z",
     "start_time": "2025-04-15T14:36:32.497543Z"
    }
   },
   "cell_type": "code",
   "source": "NUM_CLIENTS =10",
   "id": "23d2a1e147f59ffc",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:45:23.211114Z",
     "start_time": "2025-04-15T14:36:39.468785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ],
   "id": "1451e826d4713ec9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      Starting Flower ServerApp, config: num_rounds=4, no round_timeout\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [INIT]\n",
      "\u001B[92mINFO \u001B[0m:      Requesting initial parameters from one random client\n",
      "\u001B[92mINFO \u001B[0m:      Received initial parameters from one random client\n",
      "\u001B[92mINFO \u001B[0m:      Starting evaluation of initial global parameters\n",
      "\u001B[92mINFO \u001B[0m:      Evaluation returned no results (`None`)\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 1]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.5333, Training Accuracy: 2.55%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.5333, Accuracy: 2.55%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.5018, Training Accuracy: 2.70%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.5018, Accuracy: 2.70%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.5165, Training Accuracy: 3.17%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.5165, Accuracy: 3.17%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.5462, Training Accuracy: 2.08%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.5462, Accuracy: 2.08%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.5004, Training Accuracy: 3.02%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.5004, Accuracy: 3.02%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.5496, Training Accuracy: 1.93%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.5496, Accuracy: 1.93%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.5353, Training Accuracy: 2.62%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.5353, Accuracy: 2.62%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.5140, Training Accuracy: 2.60%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.5140, Accuracy: 2.60%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.5192, Training Accuracy: 2.38%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.5192, Accuracy: 2.38%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001B[93mWARNING \u001B[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.5430, Training Accuracy: 2.73%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.5430, Accuracy: 2.73%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 4.3545, Test Accuracy: 7.90%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 4.3486, Test Accuracy: 7.90%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 4.3284, Test Accuracy: 8.10%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 4.3489, Test Accuracy: 9.10%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001B[93mWARNING \u001B[0m:   No evaluate_metrics_aggregation_fn provided\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 2]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 4.3382, Test Accuracy: 8.80%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.1591, Training Accuracy: 8.20%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.1591, Accuracy: 8.20%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.1663, Training Accuracy: 8.75%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.1663, Accuracy: 8.75%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.1251, Training Accuracy: 8.82%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.1251, Accuracy: 8.82%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.1381, Training Accuracy: 8.30%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.1381, Accuracy: 8.30%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.1422, Training Accuracy: 8.50%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.1422, Accuracy: 8.50%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.1501, Training Accuracy: 8.62%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.1501, Accuracy: 8.62%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.1544, Training Accuracy: 7.47%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.1544, Accuracy: 7.47%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.1447, Training Accuracy: 7.95%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.1447, Accuracy: 7.95%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.1563, Training Accuracy: 8.28%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.1563, Accuracy: 8.28%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 4.1603, Training Accuracy: 7.67%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 4.1603, Accuracy: 7.67%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.9488, Test Accuracy: 12.70%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.8814, Test Accuracy: 11.40%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.9993, Test Accuracy: 11.00%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.9207, Test Accuracy: 13.00%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 3]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.9524, Test Accuracy: 11.60%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.9291, Training Accuracy: 11.57%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.9291, Accuracy: 11.57%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.9304, Training Accuracy: 12.30%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.9304, Accuracy: 12.30%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.8977, Training Accuracy: 12.47%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.8977, Accuracy: 12.47%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.9016, Training Accuracy: 11.93%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.9016, Accuracy: 11.93%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.8953, Training Accuracy: 12.30%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.8953, Accuracy: 12.30%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.9155, Training Accuracy: 12.68%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.9155, Accuracy: 12.68%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.9314, Training Accuracy: 11.28%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.9314, Accuracy: 11.28%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.9078, Training Accuracy: 11.80%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.9078, Accuracy: 11.80%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.9171, Training Accuracy: 12.40%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.9171, Accuracy: 12.40%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.9196, Training Accuracy: 11.53%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.9196, Accuracy: 11.53%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.7910, Test Accuracy: 15.40%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.7225, Test Accuracy: 15.20%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.8142, Test Accuracy: 13.20%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.8335, Test Accuracy: 14.50%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 4]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.7608, Test Accuracy: 15.60%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.7935, Training Accuracy: 14.00%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.7935, Accuracy: 14.00%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.7961, Training Accuracy: 14.93%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.7961, Accuracy: 14.93%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.7637, Training Accuracy: 14.65%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.7637, Accuracy: 14.65%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.7654, Training Accuracy: 14.40%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.7654, Accuracy: 14.40%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.7610, Training Accuracy: 14.60%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.7610, Accuracy: 14.60%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.7728, Training Accuracy: 15.43%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.7728, Accuracy: 15.43%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.8007, Training Accuracy: 14.10%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.8007, Accuracy: 14.10%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.7727, Training Accuracy: 14.10%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.7727, Accuracy: 14.10%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.7817, Training Accuracy: 14.68%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.7817, Accuracy: 14.68%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Training Loss: 3.7820, Training Accuracy: 14.40%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m 📘 Epoch [1/1] - Avg Loss: 3.7820, Accuracy: 14.40%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.6768, Test Accuracy: 17.70%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.7401, Test Accuracy: 16.40%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.6217, Test Accuracy: 19.30%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.7083, Test Accuracy: 15.40%\n",
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [SUMMARY]\n",
      "\u001B[92mINFO \u001B[0m:      Run finished 4 round(s) in 512.72s\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, distributed):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 4.343714739751816\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 3.9405155551075937\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 3: 3.784399951606989\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 4: 3.694976790513098\n",
      "\u001B[92mINFO \u001B[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=3856)\u001B[0m Test Loss: 3.7280, Test Accuracy: 16.10%\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "594f447d230508e6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
