{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:46:42.937617Z",
     "start_time": "2025-05-03T07:46:42.837350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "5767f6b1a63e945b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:46:45.342325Z",
     "start_time": "2025-05-03T07:46:42.940460Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
   "id": "75ca9d6d54c4ce47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:46:53.089375Z",
     "start_time": "2025-05-03T07:46:45.343307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import flwr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from flwr.common import Context\n",
    "from flwr.simulation import run_simulation\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from fl_g13 import dataset as dataset_handler\n",
    "from fl_g13.config import RAW_DATA_DIR\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-05-03 09:46:51.255\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mfl_g13.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:46:53.559697Z",
     "start_time": "2025-05-03T07:46:53.090346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# DEVICE = \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "# disable_progress_bar()"
   ],
   "id": "1a4ec3eb7baf32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Flower 1.17.0 / PyTorch 2.6.0+cu118\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load data",
   "id": "73fb84b164b0def7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:46:55.304550Z",
     "start_time": "2025-05-03T07:46:53.561695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "cifar100_train = datasets.CIFAR100(root=RAW_DATA_DIR, train=True, download=True, transform=transform)\n",
    "cifar100_test = datasets.CIFAR100(root=RAW_DATA_DIR, train=False, download=True, transform=transform)"
   ],
   "id": "6c6449ef9be1e422",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:46:55.685557Z",
     "start_time": "2025-05-03T07:46:55.305421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### train val split\n",
    "train_dataset, val_dataset = dataset_handler.train_test_split(cifar100_train, train_ratio=0.8)"
   ],
   "id": "a218d880822fdfba",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:46:56.110430Z",
     "start_time": "2025-05-03T07:46:55.686540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I.I.D Sharding Split\n",
    "## k client\n",
    "k = 10\n",
    "clients_dataset_train = dataset_handler.iid_sharding(train_dataset, k)\n",
    "clients_dataset_val = dataset_handler.iid_sharding(val_dataset, k)"
   ],
   "id": "1e23159840c6708d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tiny model",
   "id": "3ef53dc011fa9499"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:46:56.488152Z",
     "start_time": "2025-05-03T07:46:56.112430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TinyCNN(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(TinyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))  # -> [B, 16, 32, 32]\n",
    "        x = F.max_pool2d(x, 2)  # -> [B, 16, 16, 16]\n",
    "        x = F.relu(self.conv2(x))  # -> [B, 32, 16, 16]\n",
    "        x = F.max_pool2d(x, 2)  # -> [B, 32, 8, 8]\n",
    "        x = x.view(x.size(0), -1)  # -> [B, 32*8*8]\n",
    "        x = self.fc1(x)  # -> [B, 100]\n",
    "        return x"
   ],
   "id": "fa219247a8a9d7c9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Init model , optimizer and loss function",
   "id": "4c0f23c3615c6d68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:46:56.944334Z",
     "start_time": "2025-05-03T07:46:56.489175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = TinyCNN().to(DEVICE)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=1e-4, weight_decay=0.04)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ],
   "id": "9046d19b28a38ed3",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define the ClientApp",
   "id": "e73656b5d73ac995"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build module local\n",
    "\n",
    "Build module local such that ClientApp can use it"
   ],
   "id": "b5a0319c8e40215a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:47:03.073110Z",
     "start_time": "2025-05-03T07:46:56.945332Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -e ..",
   "id": "8a11402a3317027f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/ADMIN/Desktop/BACKUP/study/Italy/polito/classes/20242/deep%20learning/project/source_code/fl-g13\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: fl_g13\n",
      "  Building editable for fl_g13 (pyproject.toml): started\n",
      "  Building editable for fl_g13 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for fl_g13: filename=fl_g13-0.0.1-py3-none-any.whl size=4649 sha256=a588eeccbccdbea56dbfe92e55bd612babd81e07366f39e361ccc99a5ffdec08\n",
      "  Stored in directory: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-pyw_lbf1\\wheels\\b7\\e0\\6d\\5d22ced2ef400b314cfe74883357cc37e1e1d5275e7ba9175e\n",
      "Successfully built fl_g13\n",
      "Installing collected packages: fl_g13\n",
      "  Attempting uninstall: fl_g13\n",
      "    Found existing installation: fl_g13 0.0.1\n",
      "    Uninstalling fl_g13-0.0.1:\n",
      "      Successfully uninstalled fl_g13-0.0.1\n",
      "Successfully installed fl_g13-0.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## create FlowerClient instances  ",
   "id": "97c881019a2b9e21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:47:03.619126Z",
     "start_time": "2025-05-03T07:47:03.074110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Function load data client is to simulate the distribution data into each client\n",
    "In the real case, each client will have its dataset\n",
    "'''\n",
    "\n",
    "\n",
    "def load_data_client(context: Context,**kwargs):\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    print(f\"Client {partition_id} is ready to train\")\n",
    "    trainloader = DataLoader(clients_dataset_train[partition_id])\n",
    "    valloader = DataLoader(clients_dataset_val[partition_id])\n",
    "    return trainloader, valloader"
   ],
   "id": "f05bbd371d1a87d9",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create instant of ClientApp",
   "id": "babef0c5a1343937"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:47:06.231755Z",
     "start_time": "2025-05-03T07:47:03.620109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fl_g13.fl_pytorch.client_app import get_client_app\n",
    "\n",
    "local_epoches = 2\n",
    "client = get_client_app(load_data_fn=load_data_client, model=net, \n",
    "                        optimizer=optimizer, criterion=criterion, device=DEVICE,\n",
    "                        local_epochs=local_epoches)"
   ],
   "id": "70467a37aa8c09c7",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Define the Flower ServerApp\n",
    "\n",
    "Customize built-in strategy Federated Averaging (FedAvg) of Flower to combine hyperparams in server-side and save model for each k epoch\n",
    "\n",
    "The strategy could also incremental training an"
   ],
   "id": "5ccd8dfd409b0385"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create instant of ServerApp",
   "id": "6f9276503ee2d47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:47:09.871227Z",
     "start_time": "2025-05-03T07:47:06.232754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from fl_g13.fl_pytorch.server_app import get_server_app\n",
    "\n",
    "\n",
    "def get_datatest_fn(context: Context):\n",
    "    return DataLoader(cifar100_test)\n",
    "\n",
    "\n",
    "## checkpoints directory\n",
    "current_path = Path.cwd()\n",
    "model_test_path = current_path / \"../models/model_test\"\n",
    "model_test_path.resolve()\n",
    "\n",
    "num_rounds = 2\n",
    "save_every = 1\n",
    "fraction_fit = 1.0  # Sample 100% of available clients for training\n",
    "fraction_evaluate = 0.5  # Sample 50% of available clients for evaluation\n",
    "min_fit_clients = 10  # Never sample less than 10 clients for training\n",
    "min_evaluate_clients = 5  # Never sample less than 5 clients for evaluation\n",
    "min_available_clients = 10  # Wait until all 10 clients are available\n",
    "device = DEVICE\n",
    "use_wandb = False\n",
    "\n",
    "server = get_server_app(checkpoint_dir=model_test_path.resolve(),\n",
    "                        model_class=TinyCNN,\n",
    "                        optimizer=optimizer, criterion=criterion, get_datatest_fn=get_datatest_fn,\n",
    "                        num_rounds=num_rounds,\n",
    "                        fraction_fit=fraction_fit,\n",
    "                        fraction_evaluate=fraction_evaluate,\n",
    "                        min_fit_clients=min_fit_clients,\n",
    "                        min_evaluate_clients=min_evaluate_clients,\n",
    "                        min_available_clients=min_available_clients,\n",
    "                        device=device,\n",
    "                        use_wandb=use_wandb,\n",
    "                        save_every=save_every\n",
    "                        )"
   ],
   "id": "1cbac220e52a6d00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\model_test\\FL_TinyCNN_epoch_4.pth\n",
      "📦 Model class in checkpoint: TinyCNN\n",
      "✅ Loaded checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\model_test\\FL_TinyCNN_epoch_4.pth, resuming at epoch 5\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run the training\n",
   "id": "1427a966f7544b94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:47:10.790124Z",
     "start_time": "2025-05-03T07:47:09.874227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if DEVICE == \"cuda\":\n",
    "    backend_config[\"client_resources\"] = {\"num_cpus\": 1, \"num_gpus\": 0.25}\n",
    "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
    "    # and how to set up the `backend_config`"
   ],
   "id": "1388e3308f7b212b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9a1db478a3e1221"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:47:11.694641Z",
     "start_time": "2025-05-03T07:47:10.792382Z"
    }
   },
   "cell_type": "code",
   "source": "NUM_CLIENTS = 10",
   "id": "23d2a1e147f59ffc",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:51:02.239892Z",
     "start_time": "2025-05-03T07:47:11.695838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ],
   "id": "1451e826d4713ec9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      Starting Flower ServerApp, config: num_rounds=2, no round_timeout\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [INIT]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue train model from epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      Using initial global parameters provided by strategy\n",
      "\u001B[92mINFO \u001B[0m:      Starting evaluation of initial global parameters\n",
      "Eval progress: 100%|██████████| 10000/10000 [00:14<00:00, 711.77batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      ROUND 0💡 New best global model found: 0.203500\n",
      "\u001B[92mINFO \u001B[0m:      initial parameters (loss, other metrics): 3.4974401091873646, {'centralized_accuracy': 0.2035}\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 1]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round 0 - loss: 3.4974401091873646, metrics: {'centralized_accuracy': 0.2035}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m 2025-05-03 09:47:37.615 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m Client 3 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: dorky_beedrill_65\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m 2025-05-03 09:47:37.677 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\u001B[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001B[0m\n",
      "Training progress:   0%|          | 1/4000 [00:00<41:06,  1.62batch/s]\n",
      "Training progress:   5%|▍         | 183/4000 [00:01<00:16, 231.80batch/s]\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:  32%|███▏      | 1284/4000 [00:05<00:14, 189.39batch/s]\u001B[32m [repeated 156x across cluster]\u001B[0m\n",
      "Training progress:  36%|███▋      | 1459/4000 [00:06<00:10, 242.52batch/s]\u001B[32m [repeated 22x across cluster]\u001B[0m\n",
      "Training progress:  63%|██████▎   | 2530/4000 [00:10<00:05, 255.04batch/s]\u001B[32m [repeated 123x across cluster]\u001B[0m\n",
      "Training progress:  68%|██████▊   | 2729/4000 [00:11<00:04, 259.37batch/s]\u001B[32m [repeated 37x across cluster]\u001B[0m\n",
      "Training progress:  91%|█████████▏| 3659/4000 [00:15<00:01, 260.53batch/s]\n",
      "Training progress:  91%|█████████▏| 3657/4000 [00:15<00:01, 272.43batch/s]\n",
      "Training progress:  92%|█████████▏| 3690/4000 [00:15<00:01, 268.25batch/s]\n",
      "Training progress:  91%|█████████ | 3632/4000 [00:15<00:01, 260.10batch/s]\u001B[32m [repeated 99x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m 🚀 Epoch 1/2 (50.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \t📊 Training Loss: 3.5242\n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \t✅ Training Accuracy: 18.50%\n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \t⏳ Elapsed Time: 16.31s | ETA: 16.31s\n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \t🕒 Completed At: 09:48\n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m Client 0 is ready to train\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: quirky_nidorino_37\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  90%|█████████ | 3605/4000 [00:15<00:01, 257.33batch/s]\u001B[32m [repeated 23x across cluster]\u001B[0m\n",
      "Training progress:   1%|          | 26/4000 [00:00<00:15, 250.32batch/s]\n",
      "Training progress: 100%|██████████| 4000/4000 [00:16<00:00, 240.53batch/s]\u001B[32m [repeated 32x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:16<00:00, 240.16batch/s]\u001B[32m [repeated 9x across cluster]\u001B[0m\n",
      "Training progress:  29%|██▉       | 1161/4000 [00:04<00:10, 276.24batch/s]\u001B[32m [repeated 139x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "Training progress:  30%|██▉       | 1199/4000 [00:04<00:09, 294.95batch/s]\u001B[32m [repeated 13x across cluster]\u001B[0m\n",
      "Training progress:  67%|██████▋   | 2687/4000 [00:09<00:04, 289.29batch/s]\u001B[32m [repeated 166x across cluster]\u001B[0m\n",
      "Training progress:  71%|███████   | 2825/4000 [00:10<00:05, 225.02batch/s]\u001B[32m [repeated 15x across cluster]\u001B[0m\n",
      "Training progress:  92%|█████████▏| 3684/4000 [00:12<00:01, 314.22batch/s]\n",
      "Training progress:  92%|█████████▏| 3663/4000 [00:12<00:01, 307.96batch/s]\n",
      "Training progress:  92%|█████████▏| 3675/4000 [00:13<00:01, 317.28batch/s]\n",
      "Training progress:  93%|█████████▎| 3707/4000 [00:13<00:00, 316.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t📊 Training Loss: 3.2909\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t✅ Training Accuracy: 22.10%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t⏳ Elapsed Time: 13.93s | ETA: 0.00s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t🕒 Completed At: 09:48\u001B[32m [repeated 4x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  91%|█████████ | 3643/4000 [00:13<00:01, 316.18batch/s]\u001B[32m [repeated 107x across cluster]\u001B[0m\n",
      "Training progress:  84%|████████▍ | 3355/4000 [00:12<00:02, 317.70batch/s]\u001B[32m [repeated 5x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m Client 6 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: dorky_sandshrew_92\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Training progress: 100%|██████████| 4000/4000 [00:14<00:00, 281.74batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 288.56batch/s]\u001B[32m [repeated 37x across cluster]\u001B[0m\n",
      "Training progress:  10%|▉         | 390/4000 [00:01<00:14, 255.40batch/s]\u001B[32m [repeated 45x across cluster]\u001B[0m\n",
      "Training progress:  11%|█▏        | 458/4000 [00:02<00:12, 288.52batch/s]\u001B[32m [repeated 6x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:  49%|████▊     | 1946/4000 [00:06<00:06, 307.76batch/s]\u001B[32m [repeated 159x across cluster]\u001B[0m\n",
      "Training progress:  55%|█████▌    | 2211/4000 [00:07<00:05, 315.43batch/s]\u001B[32m [repeated 22x across cluster]\u001B[0m\n",
      "Training progress:  88%|████████▊ | 3516/4000 [00:11<00:01, 312.61batch/s]\u001B[32m [repeated 138x across cluster]\u001B[0m\n",
      "Training progress:  91%|█████████▏| 3653/4000 [00:12<00:01, 320.27batch/s]\n",
      "Training progress:  92%|█████████▏| 3686/4000 [00:12<00:00, 320.05batch/s]\n",
      "Training progress:  92%|█████████▏| 3661/4000 [00:12<00:01, 306.58batch/s]\n",
      "Training progress:  90%|█████████ | 3620/4000 [00:12<00:01, 319.76batch/s]\u001B[32m [repeated 27x across cluster]\u001B[0m\n",
      "Training progress:  99%|█████████▊| 3944/4000 [00:13<00:00, 315.08batch/s]\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 296.38batch/s]\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m 🚀 Epoch 1/2 (50.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t📊 Training Loss: 3.4890\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t✅ Training Accuracy: 19.23%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t⏳ Elapsed Time: 13.50s | ETA: 13.50s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t🕒 Completed At: 09:48\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m Client 5 is ready to train\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: nutty_nidoking_81\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   1%|          | 22/4000 [00:00<00:18, 212.29batch/s]\n",
      "Training progress:  24%|██▍       | 957/4000 [00:03<00:09, 308.58batch/s]\u001B[32m [repeated 110x across cluster]\u001B[0m\n",
      "Training progress:  99%|█████████▉| 3968/4000 [00:13<00:00, 312.09batch/s]\u001B[32m [repeated 36x across cluster]\u001B[0m\n",
      "Training progress:  35%|███▍      | 1391/4000 [00:04<00:07, 327.86batch/s]\u001B[32m [repeated 24x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 292.23batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "Training progress:  63%|██████▎   | 2535/4000 [00:08<00:05, 288.54batch/s]\u001B[32m [repeated 143x across cluster]\u001B[0m\n",
      "Training progress:  70%|███████   | 2805/4000 [00:09<00:04, 295.74batch/s]\u001B[32m [repeated 24x across cluster]\u001B[0m\n",
      "Training progress:  91%|█████████▏| 3654/4000 [00:12<00:01, 292.54batch/s]\n",
      "Training progress:  92%|█████████▏| 3675/4000 [00:12<00:01, 296.68batch/s]\n",
      "Training progress:  92%|█████████▎| 3700/4000 [00:12<00:01, 297.95batch/s]\n",
      "Training progress:  91%|█████████ | 3637/4000 [00:12<00:01, 286.80batch/s]\u001B[32m [repeated 108x across cluster]\u001B[0m\n",
      "Training progress:  91%|█████████ | 3622/4000 [00:12<00:01, 282.65batch/s]\u001B[32m [repeated 11x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t📊 Training Loss: 3.2801\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t✅ Training Accuracy: 23.12%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t⏳ Elapsed Time: 13.73s | ETA: 0.00s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t🕒 Completed At: 09:48\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m Client 8 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: happy_clefairy_56\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 292.63batch/s]\u001B[32m [repeated 32x across cluster]\u001B[0m\n",
      "Training progress:  99%|█████████▉| 3976/4000 [00:13<00:00, 283.29batch/s]\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "Training progress:  32%|███▏      | 1291/4000 [00:03<00:06, 431.74batch/s]\u001B[32m [repeated 45x across cluster]\u001B[0m\n",
      "Training progress:  30%|██▉       | 1199/4000 [00:03<00:06, 413.95batch/s]\u001B[32m [repeated 9x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Training progress:  90%|████████▉ | 3596/4000 [00:08<00:00, 482.21batch/s]\u001B[32m [repeated 80x across cluster]\u001B[0m\n",
      "Training progress:  92%|█████████▏| 3695/4000 [00:08<00:00, 484.34batch/s]\n",
      "Training progress:  92%|█████████▏| 3696/4000 [00:08<00:00, 486.37batch/s]\n",
      "Training progress:  94%|█████████▎| 3745/4000 [00:08<00:00, 476.33batch/s]\n",
      "Training progress: 100%|██████████| 4000/4000 [00:09<00:00, 424.42batch/s]\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Training progress:  89%|████████▊ | 3546/4000 [00:08<00:00, 480.18batch/s]\u001B[32m [repeated 9x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m 🚀 Epoch 1/2 (50.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t📊 Training Loss: 3.5110\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t✅ Training Accuracy: 19.23%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t⏳ Elapsed Time: 9.42s | ETA: 9.42s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t🕒 Completed At: 09:48\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m Client 9 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: sneezy_nidorina_69\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  44%|████▎     | 1741/4000 [00:04<00:04, 453.77batch/s]\u001B[32m [repeated 63x across cluster]\u001B[0m\n",
      "Training progress:  98%|█████████▊| 3936/4000 [00:09<00:00, 469.05batch/s]\u001B[32m [repeated 9x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:09<00:00, 423.72batch/s]\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Training progress:  54%|█████▍    | 2156/4000 [00:05<00:03, 464.18batch/s]\u001B[32m [repeated 9x across cluster]\u001B[0m\n",
      "Training progress:  91%|█████████▏| 3654/4000 [00:08<00:00, 486.85batch/s]\n",
      "Training progress:  97%|█████████▋| 3863/4000 [00:08<00:00, 450.11batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t📊 Training Loss: 3.2931\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t✅ Training Accuracy: 22.70%\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t⏳ Elapsed Time: 8.99s | ETA: 0.00s\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t🕒 Completed At: 09:49\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n",
      "[Round 1] Avg Client Drift: 7.7659\n",
      "[Round 1] Relative Client Drift: 0.1599\n",
      "Saving centralized model epoch 5 aggregated_parameters...\n",
      "💾 Saved checkpoint at: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\model_test\\FL_TinyCNN_epoch_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 10000/10000 [00:08<00:00, 1209.45batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      ROUND 1💡 New best global model found: 0.221900\n",
      "\u001B[92mINFO \u001B[0m:      fit progress: (1, 3.375532430048287, {'centralized_accuracy': 0.2219}, 107.3775332000223)\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round 1 - loss: 3.375532430048287, metrics: {'centralized_accuracy': 0.2219}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1000 [00:00<?, ?batch/s]\n",
      "Training progress:  91%|█████████ | 3625/4000 [00:08<00:00, 467.88batch/s]\u001B[32m [repeated 53x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:09<00:00, 443.28batch/s]\u001B[32m [repeated 10x across cluster]\u001B[0m\n",
      "Training progress:  89%|████████▉ | 3577/4000 [00:08<00:00, 470.75batch/s]\u001B[32m [repeated 10x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:08<00:00, 444.71batch/s]\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "Eval progress:   2%|▎         | 25/1000 [00:00<00:04, 238.39batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m Client 5 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t📊 Training Loss: 3.3120\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t✅ Training Accuracy: 23.20%\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t⏳ Elapsed Time: 9.02s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \t🕒 Completed At: 09:49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   5%|▌         | 52/1000 [00:00<00:03, 271.79batch/s]\n",
      "Eval progress:  95%|█████████▍| 948/1000 [00:01<00:00, 628.18batch/s]\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:01<00:00, 538.92batch/s]\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:01<00:00, 593.43batch/s]\n",
      "Eval progress:   0%|          | 0/1000 [00:00<?, ?batch/s]\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 2]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Eval progress:  73%|███████▎  | 730/1000 [00:00<00:00, 1446.09batch/s]\u001B[32m [repeated 40x across cluster]\u001B[0m\n",
      "Eval progress:  43%|████▎     | 434/1000 [00:00<00:00, 1445.12batch/s]\u001B[32m [repeated 11x across cluster]\u001B[0m\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:00<00:00, 1440.34batch/s]\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:01<00:00, 548.53batch/s]\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:01<00:00, 584.81batch/s]\n",
      "Training progress:   0%|          | 18/4000 [00:00<00:22, 177.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: perky_nidoqueen_12\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m Client 3 is ready to train\u001B[32m [repeated 5x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   1%|          | 41/4000 [00:00<00:19, 205.49batch/s]\n",
      "Training progress:   2%|▏         | 95/4000 [00:00<00:15, 249.87batch/s]\n",
      "Training progress:   3%|▎         | 123/4000 [00:00<00:15, 258.30batch/s]\n",
      "Training progress:   4%|▍         | 157/4000 [00:00<00:13, 285.61batch/s]\n",
      "Training progress:   6%|▌         | 238/4000 [00:00<00:10, 346.73batch/s]\n",
      "Training progress:   7%|▋         | 273/4000 [00:00<00:10, 339.80batch/s]\n",
      "Training progress:   8%|▊         | 310/4000 [00:01<00:10, 347.32batch/s]\n",
      "Training progress:  10%|▉         | 380/4000 [00:01<00:10, 346.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  10%|█         | 415/4000 [00:01<00:12, 276.21batch/s]\n",
      "Training progress:  14%|█▎        | 543/4000 [00:01<00:11, 297.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:  37%|███▋      | 1463/4000 [00:05<00:07, 323.01batch/s]\u001B[32m [repeated 88x across cluster]\u001B[0m\n",
      "Training progress:  21%|██        | 832/4000 [00:02<00:10, 315.32batch/s]\u001B[32m [repeated 15x across cluster]\u001B[0m\n",
      "Training progress:  74%|███████▎  | 2942/4000 [00:10<00:03, 288.75batch/s]\u001B[32m [repeated 150x across cluster]\u001B[0m\n",
      "Training progress:  59%|█████▉    | 2372/4000 [00:07<00:04, 328.69batch/s]\u001B[32m [repeated 22x across cluster]\u001B[0m\n",
      "Training progress:  91%|█████████▏| 3657/4000 [00:12<00:01, 289.09batch/s]\n",
      "Training progress:  92%|█████████▏| 3690/4000 [00:12<00:01, 300.25batch/s]\n",
      "Training progress:  93%|█████████▎| 3723/4000 [00:12<00:00, 308.36batch/s]\n",
      "Training progress:  94%|█████████▍| 3755/4000 [00:13<00:00, 308.58batch/s]\n",
      "Training progress:  95%|█████████▍| 3787/4000 [00:13<00:00, 309.89batch/s]\n",
      "Training progress:  95%|█████████▌| 3819/4000 [00:13<00:00, 311.46batch/s]\n",
      "Training progress:  96%|█████████▋| 3851/4000 [00:13<00:00, 306.28batch/s]\n",
      "Training progress:  97%|█████████▋| 3883/4000 [00:13<00:00, 309.79batch/s]\n",
      "Training progress:  98%|█████████▊| 3917/4000 [00:13<00:00, 317.22batch/s]\n",
      "Training progress:  99%|█████████▊| 3949/4000 [00:13<00:00, 311.36batch/s]\n",
      "Training progress: 100%|█████████▉| 3981/4000 [00:13<00:00, 308.44batch/s]\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 288.86batch/s]\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m 🚀 Epoch 1/2 (50.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t📊 Training Loss: 3.3714\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t✅ Training Accuracy: 21.32%\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t⏳ Elapsed Time: 13.85s | ETA: 13.85s\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t🕒 Completed At: 09:49\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: sleepy_bulbasaur_48\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m Client 0 is ready to train\u001B[32m [repeated 3x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  93%|█████████▎| 3715/4000 [00:12<00:00, 309.63batch/s]\n",
      "Training progress:  96%|█████████▌| 3841/4000 [00:13<00:00, 302.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  11%|█▏        | 453/4000 [00:01<00:11, 319.70batch/s]\u001B[32m [repeated 102x across cluster]\u001B[0m\n",
      "Training progress:   9%|▉         | 355/4000 [00:01<00:11, 305.50batch/s]\u001B[32m [repeated 26x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 296.71batch/s]\u001B[32m [repeated 22x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 300.24batch/s]\u001B[32m [repeated 5x across cluster]\u001B[0m\n",
      "Training progress:  51%|█████     | 2028/4000 [00:06<00:06, 298.55batch/s]\u001B[32m [repeated 142x across cluster]\u001B[0m\n",
      "Training progress:  36%|███▌      | 1447/4000 [00:04<00:08, 308.44batch/s]\u001B[32m [repeated 21x across cluster]\u001B[0m\n",
      "Training progress:  89%|████████▉ | 3550/4000 [00:11<00:01, 302.06batch/s]\u001B[32m [repeated 145x across cluster]\u001B[0m\n",
      "Training progress:  74%|███████▍  | 2970/4000 [00:09<00:03, 302.25batch/s]\u001B[32m [repeated 26x across cluster]\u001B[0m\n",
      "Training progress:  92%|█████████▏| 3677/4000 [00:11<00:01, 302.36batch/s]\n",
      "Training progress:  93%|█████████▎| 3709/4000 [00:12<00:00, 304.93batch/s]\n",
      "Training progress:  94%|█████████▎| 3740/4000 [00:12<00:00, 301.80batch/s]\n",
      "Training progress:  94%|█████████▍| 3771/4000 [00:12<00:00, 298.47batch/s]\n",
      "Training progress:  96%|█████████▌| 3834/4000 [00:12<00:00, 298.91batch/s]\n",
      "Training progress:  97%|█████████▋| 3864/4000 [00:12<00:00, 291.60batch/s]\n",
      "Training progress:  97%|█████████▋| 3894/4000 [00:12<00:00, 289.37batch/s]\n",
      "Training progress:  99%|█████████▉| 3952/4000 [00:12<00:00, 288.76batch/s]\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 306.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t📊 Training Loss: 3.1811\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t✅ Training Accuracy: 24.22%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t⏳ Elapsed Time: 13.04s | ETA: 0.00s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t🕒 Completed At: 09:49\u001B[32m [repeated 4x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m Client 4 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: soggy_fearow_93\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  29%|██▊       | 1141/4000 [00:02<00:05, 535.77batch/s]\u001B[32m [repeated 60x across cluster]\u001B[0m\n",
      "Training progress:  24%|██▍       | 966/4000 [00:02<00:05, 565.54batch/s]\u001B[32m [repeated 12x across cluster]\u001B[0m\n",
      "Training progress:  99%|█████████▊| 3949/4000 [00:12<00:00, 335.30batch/s]\u001B[32m [repeated 20x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 305.42batch/s]\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "Training progress:  90%|█████████ | 3608/4000 [00:07<00:00, 569.55batch/s]\u001B[32m [repeated 36x across cluster]\u001B[0m\n",
      "Training progress:  82%|████████▏ | 3262/4000 [00:06<00:01, 502.97batch/s]\u001B[32m [repeated 5x across cluster]\u001B[0m\n",
      "Training progress:   1%|          | 42/4000 [00:00<00:09, 417.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m 🚀 Epoch 1/2 (50.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t📊 Training Loss: 3.3655\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t✅ Training Accuracy: 21.35%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t⏳ Elapsed Time: 8.08s | ETA: 8.08s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t🕒 Completed At: 09:50\u001B[32m [repeated 4x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress: 100%|██████████| 4000/4000 [00:08<00:00, 495.04batch/s]\u001B[32m [repeated 5x across cluster]\u001B[0m\n",
      "Training progress:  96%|█████████▌| 3847/4000 [00:07<00:00, 570.24batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m Client 5 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: sneezy_clefairy_30\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Training progress:  17%|█▋        | 694/4000 [00:02<00:11, 297.76batch/s]\u001B[32m [repeated 85x across cluster]\u001B[0m\n",
      "Training progress:  43%|████▎     | 1712/4000 [00:04<00:07, 296.93batch/s]\u001B[32m [repeated 14x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "Training progress:  79%|███████▉  | 3157/4000 [00:09<00:02, 311.26batch/s]\u001B[32m [repeated 132x across cluster]\u001B[0m\n",
      "Training progress:  80%|████████  | 3220/4000 [00:09<00:02, 300.23batch/s]\u001B[32m [repeated 31x across cluster]\u001B[0m\n",
      "Training progress:  92%|█████████▏| 3693/4000 [00:11<00:01, 304.89batch/s]\n",
      "Training progress:  93%|█████████▎| 3724/4000 [00:11<00:00, 306.02batch/s]\n",
      "Training progress:  94%|█████████▍| 3755/4000 [00:11<00:00, 303.79batch/s]\n",
      "Training progress:  95%|█████████▍| 3786/4000 [00:11<00:00, 301.87batch/s]\n",
      "Training progress:  95%|█████████▌| 3817/4000 [00:11<00:00, 208.09batch/s]\n",
      "Training progress:  96%|█████████▌| 3847/4000 [00:12<00:00, 228.40batch/s]\n",
      "Training progress:  97%|█████████▋| 3879/4000 [00:12<00:00, 248.97batch/s]\n",
      "Training progress:  98%|█████████▊| 3910/4000 [00:12<00:00, 263.20batch/s]\n",
      "Training progress:  99%|█████████▊| 3941/4000 [00:12<00:00, 274.10batch/s]\n",
      "Training progress:  99%|█████████▉| 3972/4000 [00:12<00:00, 282.28batch/s]\n",
      "Training progress: 100%|██████████| 4000/4000 [00:12<00:00, 319.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t📊 Training Loss: 3.1663\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t✅ Training Accuracy: 25.02%\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t⏳ Elapsed Time: 12.52s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t🕒 Completed At: 09:50\n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m Client 6 is ready to train\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: zesty_metapod_37\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Training progress:  92%|█████████▏| 3668/4000 [00:12<00:01, 316.70batch/s]\n",
      "Training progress:  10%|█         | 416/4000 [00:01<00:11, 303.98batch/s]\u001B[32m [repeated 101x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m 🚀 Epoch 1/2 (50.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t📊 Training Loss: 3.3518\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t✅ Training Accuracy: 22.15%\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t⏳ Elapsed Time: 13.05s | ETA: 13.05s\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t🕒 Completed At: 09:50\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  12%|█▏        | 479/4000 [00:01<00:11, 308.20batch/s]\u001B[32m [repeated 24x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 304.17batch/s]\u001B[32m [repeated 6x across cluster]\u001B[0m\n",
      "Training progress:  99%|█████████▉| 3965/4000 [00:13<00:00, 303.68batch/s]\u001B[32m [repeated 23x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:  52%|█████▏    | 2082/4000 [00:06<00:06, 309.18batch/s]\u001B[32m [repeated 131x across cluster]\u001B[0m\n",
      "Training progress:  38%|███▊      | 1539/4000 [00:04<00:08, 306.59batch/s]\u001B[32m [repeated 26x across cluster]\u001B[0m\n",
      "Training progress:  89%|████████▉ | 3579/4000 [00:11<00:01, 276.32batch/s]\u001B[32m [repeated 142x across cluster]\u001B[0m\n",
      "Training progress:  92%|█████████▏| 3672/4000 [00:11<00:01, 294.18batch/s]\n",
      "Training progress:  74%|███████▍  | 2970/4000 [00:09<00:03, 295.26batch/s]\u001B[32m [repeated 26x across cluster]\u001B[0m\n",
      "Training progress:  93%|█████████▎| 3702/4000 [00:12<00:01, 292.22batch/s]\n",
      "Training progress:  93%|█████████▎| 3734/4000 [00:12<00:00, 298.81batch/s]\n",
      "Training progress:  94%|█████████▍| 3766/4000 [00:12<00:00, 300.78batch/s]\n",
      "Training progress:  95%|█████████▍| 3797/4000 [00:12<00:00, 303.42batch/s]\n",
      "Training progress:  96%|█████████▌| 3828/4000 [00:12<00:00, 302.59batch/s]\n",
      "Training progress:  97%|█████████▋| 3861/4000 [00:12<00:00, 308.02batch/s]\n",
      "Training progress:  97%|█████████▋| 3892/4000 [00:12<00:00, 304.56batch/s]\n",
      "Training progress:  98%|█████████▊| 3925/4000 [00:12<00:00, 311.54batch/s]\n",
      "Training progress:  99%|█████████▉| 3957/4000 [00:12<00:00, 311.25batch/s]\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 306.68batch/s]\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m Client 8 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: bubbly_charizard_12\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m 🚀 Epoch 1/2 (50.00%) Completed\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t📊 Training Loss: 3.3869\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t✅ Training Accuracy: 21.73%\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t⏳ Elapsed Time: 13.04s | ETA: 13.04s\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t🕒 Completed At: 09:50\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=31872)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=22856)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m Client 9 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: dizzy_pikachu_92\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  36%|███▌      | 1435/4000 [00:03<00:05, 442.01batch/s]\u001B[32m [repeated 83x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 305.46batch/s]\u001B[32m [repeated 26x across cluster]\u001B[0m\n",
      "Training progress:  39%|███▉      | 1578/4000 [00:04<00:05, 457.87batch/s]\u001B[32m [repeated 14x across cluster]\u001B[0m\n",
      "Training progress:  99%|█████████▉| 3978/4000 [00:13<00:00, 343.24batch/s]\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Training progress:  72%|███████▏  | 2891/4000 [00:06<00:02, 470.34batch/s]\u001B[32m [repeated 68x across cluster]\u001B[0m\n",
      "Training progress:  98%|█████████▊| 3914/4000 [00:09<00:00, 504.12batch/s]\u001B[32m [repeated 6x across cluster]\u001B[0m\n",
      "Training progress:  67%|██████▋   | 2695/4000 [00:05<00:02, 482.12batch/s]\u001B[32m [repeated 12x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t📊 Training Loss: 3.1973\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t✅ Training Accuracy: 25.30%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t⏳ Elapsed Time: 9.23s | ETA: 0.00s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m \t🕒 Completed At: 09:50\u001B[32m [repeated 4x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress: 100%|██████████| 4000/4000 [00:09<00:00, 433.61batch/s]\n",
      "Training progress:  93%|█████████▎| 3734/4000 [00:07<00:00, 520.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress: 100%|██████████| 4000/4000 [00:08<00:00, 481.32batch/s]\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Training progress:  41%|████▏     | 1657/4000 [00:03<00:04, 524.22batch/s]\u001B[32m [repeated 33x across cluster]\u001B[0m\n",
      "Training progress:  98%|█████████▊| 3903/4000 [00:08<00:00, 547.47batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:  44%|████▍     | 1779/4000 [00:03<00:03, 565.26batch/s]\u001B[32m [repeated 6x across cluster]\u001B[0m\n",
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 2] Avg Client Drift: 7.1010\n",
      "[Round 2] Relative Client Drift: 0.1336\n",
      "Saving centralized model epoch 6 aggregated_parameters...\n",
      "💾 Saved checkpoint at: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\model_test\\FL_TinyCNN_epoch_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   1%|          | 105/10000 [00:00<00:09, 1049.76batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t📊 Training Loss: 3.1768\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t✅ Training Accuracy: 24.45%\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t⏳ Elapsed Time: 7.27s | ETA: 0.00s\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m \t🕒 Completed At: 09:50\u001B[32m [repeated 2x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 10000/10000 [00:07<00:00, 1285.31batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      ROUND 2💡 New best global model found: 0.237200\n",
      "\u001B[92mINFO \u001B[0m:      fit progress: (2, 3.29260735466443, {'centralized_accuracy': 0.2372}, 205.4223714999971)\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round 2 - loss: 3.29260735466443, metrics: {'centralized_accuracy': 0.2372}\n",
      "\u001B[36m(ClientAppActor pid=29780)\u001B[0m Client 0 is ready to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1000 [00:00<?, ?batch/s]\n",
      "Training progress:  91%|█████████ | 3624/4000 [00:06<00:00, 474.24batch/s]\u001B[32m [repeated 29x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:07<00:00, 550.35batch/s]\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "Training progress:  74%|███████▍  | 2965/4000 [00:05<00:01, 528.18batch/s]\n",
      "Eval progress:   1%|          | 11/1000 [00:00<00:09, 109.34batch/s]\n",
      "Eval progress:   1%|          | 11/1000 [00:00<00:09, 104.25batch/s]\n",
      "Eval progress:  32%|███▏      | 317/1000 [00:00<00:01, 593.89batch/s]\n",
      "Eval progress:  52%|█████▏    | 520/1000 [00:00<00:00, 652.15batch/s]\n",
      "Eval progress:  65%|██████▌   | 650/1000 [00:01<00:00, 628.66batch/s]\n",
      "Eval progress:  94%|█████████▎| 936/1000 [00:01<00:00, 617.60batch/s]\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:01<00:00, 580.48batch/s]\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:01<00:00, 576.49batch/s]\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:00<00:00, 1398.03batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [SUMMARY]\n",
      "\u001B[92mINFO \u001B[0m:      Run finished 2 round(s) in 212.57s\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, distributed):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 3.456754108432867\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 3.3951371462062934\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, centralized):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 0: 3.4974401091873646\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 3.375532430048287\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 3.29260735466443\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, distributed, fit):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'avg_drift': [(1, 7.765880012512207), (2, 7.101033878326416)],\n",
      "\u001B[92mINFO \u001B[0m:      \t 'avg_train_loss': [(1, 6.804417191790929), (2, 6.569833140254393)]}\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'federated_evaluate_accuracy': [(1, 0.2018), (2, 0.201)]}\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, centralized):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'centralized_accuracy': [(0, 0.2035), (1, 0.2219), (2, 0.2372)]}\n",
      "\u001B[92mINFO \u001B[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=32524)\u001B[0m Client 9 is ready to train\u001B[32m [repeated 4x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1000 [00:00<?, ?batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Eval progress:  72%|███████▏  | 718/1000 [00:00<00:00, 1392.65batch/s]\u001B[32m [repeated 53x across cluster]\u001B[0m\n",
      "Eval progress:  29%|██▉       | 288/1000 [00:00<00:00, 1441.32batch/s]\n",
      "Eval progress:  94%|█████████▍| 938/1000 [00:01<00:00, 634.38batch/s]\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:01<00:00, 582.17batch/s]\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:01<00:00, 587.67batch/s]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:51:03.221586Z",
     "start_time": "2025-05-03T07:51:02.242889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "server = get_server_app(checkpoint_dir=model_test_path.resolve(),\n",
    "                        model_class=TinyCNN,\n",
    "                        optimizer=optimizer, criterion=criterion, get_datatest_fn=get_datatest_fn,\n",
    "                        num_rounds=num_rounds,\n",
    "                        fraction_fit=fraction_fit,\n",
    "                        fraction_evaluate=fraction_evaluate,\n",
    "                        min_fit_clients=min_fit_clients,\n",
    "                        min_evaluate_clients=min_evaluate_clients,\n",
    "                        min_available_clients=min_available_clients,\n",
    "                        device=device,\n",
    "                        use_wandb=use_wandb,\n",
    "                        save_every=save_every\n",
    "                        )"
   ],
   "id": "44da2c65666a232d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\model_test\\FL_TinyCNN_epoch_6.pth\n",
      "📦 Model class in checkpoint: TinyCNN\n",
      "✅ Loaded checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\model_test\\FL_TinyCNN_epoch_6.pth, resuming at epoch 7\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:54:36.484866Z",
     "start_time": "2025-05-03T07:51:03.222586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run simulation second time\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ],
   "id": "594f447d230508e6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      Starting Flower ServerApp, config: num_rounds=2, no round_timeout\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [INIT]\n",
      "\u001B[92mINFO \u001B[0m:      Using initial global parameters provided by strategy\n",
      "\u001B[92mINFO \u001B[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue train model from epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 10000/10000 [00:12<00:00, 828.87batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      ROUND 0💡 New best global model found: 0.237200\n",
      "\u001B[92mINFO \u001B[0m:      initial parameters (loss, other metrics): 3.29260735466443, {'centralized_accuracy': 0.2372}\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 1]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round 0 - loss: 3.29260735466443, metrics: {'centralized_accuracy': 0.2372}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m 2025-05-03 09:51:25.845 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m Client 0 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: sneezy_ivysaur_50\n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 1/4000 [00:01<1:17:38,  1.16s/batch]\n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m 2025-05-03 09:51:25.846 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:   1%|          | 40/4000 [00:01<01:28, 44.86batch/s] \n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:  32%|███▏      | 1266/4000 [00:06<00:09, 282.77batch/s]\u001B[32m [repeated 139x across cluster]\u001B[0m\n",
      "Training progress:  32%|███▏      | 1286/4000 [00:06<00:09, 276.35batch/s]\u001B[32m [repeated 28x across cluster]\u001B[0m\n",
      "Training progress:  70%|██████▉   | 2795/4000 [00:11<00:03, 306.59batch/s]\u001B[32m [repeated 147x across cluster]\u001B[0m\n",
      "Training progress:  70%|███████   | 2815/4000 [00:11<00:03, 305.36batch/s]\u001B[32m [repeated 23x across cluster]\u001B[0m\n",
      "Training progress:  92%|█████████▏| 3661/4000 [00:14<00:01, 303.77batch/s]\n",
      "Training progress:  94%|█████████▍| 3766/4000 [00:14<00:00, 299.28batch/s]\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m 🚀 Epoch 1/2 (50.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t📊 Training Loss: 3.2803\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t✅ Training Accuracy: 22.80%\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t⏳ Elapsed Time: 15.16s | ETA: 15.16s\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t🕒 Completed At: 09:51\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m Client 2 is ready to train\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: spunky_wartortle_33\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   8%|▊         | 319/4000 [00:01<00:12, 306.06batch/s]\u001B[32m [repeated 95x across cluster]\u001B[0m\n",
      "Training progress:   9%|▉         | 376/4000 [00:01<00:11, 303.34batch/s]\u001B[32m [repeated 28x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:15<00:00, 263.24batch/s]\u001B[32m [repeated 27x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:15<00:00, 262.48batch/s]\u001B[32m [repeated 9x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:  46%|████▌     | 1838/4000 [00:06<00:07, 274.78batch/s]\u001B[32m [repeated 134x across cluster]\u001B[0m\n",
      "Training progress:  47%|████▋     | 1885/4000 [00:06<00:07, 291.05batch/s]\u001B[32m [repeated 29x across cluster]\u001B[0m\n",
      "Training progress:  85%|████████▍ | 3388/4000 [00:11<00:02, 303.73batch/s]\u001B[32m [repeated 140x across cluster]\u001B[0m\n",
      "Training progress:  84%|████████▍ | 3375/4000 [00:11<00:02, 307.21batch/s]\u001B[32m [repeated 27x across cluster]\u001B[0m\n",
      "Training progress:  91%|█████████▏| 3656/4000 [00:12<00:01, 304.51batch/s]\n",
      "Training progress:  92%|█████████▏| 3664/4000 [00:12<00:01, 305.54batch/s]\n",
      "Training progress:  92%|█████████▏| 3691/4000 [00:12<00:01, 298.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \t📊 Training Loss: 3.0842\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \t✅ Training Accuracy: 27.93%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \t⏳ Elapsed Time: 13.21s | ETA: 0.00s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \t🕒 Completed At: 09:51\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m Client 5 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: fluffy_spearow_69\n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 2/4000 [00:00<10:17,  6.48batch/s]\u001B[32m [repeated 18x across cluster]\u001B[0m\n",
      "Training progress:   1%|          | 49/4000 [00:00<00:31, 123.69batch/s]\u001B[32m [repeated 8x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 301.35batch/s]\u001B[32m [repeated 34x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 300.22batch/s]\u001B[32m [repeated 6x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:  37%|███▋      | 1470/4000 [00:05<00:08, 295.16batch/s]\u001B[32m [repeated 152x across cluster]\u001B[0m\n",
      "Training progress:  35%|███▌      | 1405/4000 [00:05<00:09, 275.21batch/s]\u001B[32m [repeated 19x across cluster]\u001B[0m\n",
      "Training progress:  72%|███████▏  | 2871/4000 [00:10<00:03, 286.58batch/s]\u001B[32m [repeated 132x across cluster]\u001B[0m\n",
      "Training progress:  72%|███████▏  | 2877/4000 [00:10<00:04, 276.07batch/s]\u001B[32m [repeated 27x across cluster]\u001B[0m\n",
      "Training progress:  92%|█████████▏| 3677/4000 [00:13<00:01, 307.94batch/s]\n",
      "Training progress:  93%|█████████▎| 3706/4000 [00:13<00:01, 291.29batch/s]\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Training progress:   1%|          | 32/4000 [00:00<00:12, 311.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m 🚀 Epoch 1/2 (50.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t📊 Training Loss: 3.3177\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t✅ Training Accuracy: 23.20%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t⏳ Elapsed Time: 14.23s | ETA: 14.23s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t🕒 Completed At: 09:52\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m Client 4 is ready to train\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: snazzy_metapod_84\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   9%|▉         | 358/4000 [00:01<00:11, 308.72batch/s]\u001B[32m [repeated 105x across cluster]\u001B[0m\n",
      "Training progress:   9%|▉         | 355/4000 [00:01<00:11, 311.45batch/s]\u001B[32m [repeated 22x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:14<00:00, 279.10batch/s]\u001B[32m [repeated 38x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:14<00:00, 277.57batch/s]\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "Training progress:  46%|████▌     | 1834/4000 [00:06<00:07, 288.18batch/s]\u001B[32m [repeated 130x across cluster]\u001B[0m\n",
      "Training progress:  45%|████▍     | 1794/4000 [00:06<00:07, 294.97batch/s]\u001B[32m [repeated 30x across cluster]\u001B[0m\n",
      "Training progress:  82%|████████▏ | 3289/4000 [00:11<00:02, 307.51batch/s]\u001B[32m [repeated 168x across cluster]\u001B[0m\n",
      "Training progress:  84%|████████▎ | 3340/4000 [00:11<00:02, 309.09batch/s]\u001B[32m [repeated 13x across cluster]\u001B[0m\n",
      "Training progress:  91%|█████████▏| 3655/4000 [00:12<00:01, 310.59batch/s]\n",
      "Training progress:  93%|█████████▎| 3725/4000 [00:12<00:00, 309.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t📊 Training Loss: 3.1269\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t✅ Training Accuracy: 27.00%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t⏳ Elapsed Time: 13.53s | ETA: 0.00s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t🕒 Completed At: 09:52\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m Client 9 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: bouncy_wartortle_87\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   6%|▌         | 227/4000 [00:00<00:09, 415.73batch/s]\u001B[32m [repeated 52x across cluster]\u001B[0m\n",
      "Training progress:  90%|████████▉ | 3599/4000 [00:12<00:01, 300.67batch/s]\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 297.21batch/s]\u001B[32m [repeated 39x across cluster]\u001B[0m\n",
      "Training progress: 100%|█████████▉| 3987/4000 [00:13<00:00, 308.79batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Training progress:  65%|██████▌   | 2616/4000 [00:05<00:02, 464.43batch/s]\u001B[32m [repeated 84x across cluster]\u001B[0m\n",
      "Training progress:  69%|██████▉   | 2772/4000 [00:06<00:02, 464.95batch/s]\u001B[32m [repeated 8x across cluster]\u001B[0m\n",
      "Training progress:  92%|█████████▏| 3669/4000 [00:08<00:00, 476.86batch/s]\n",
      "Training progress:  93%|█████████▎| 3717/4000 [00:08<00:00, 475.92batch/s]\n",
      "Training progress:  95%|█████████▌| 3819/4000 [00:08<00:00, 490.64batch/s]\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m 🚀 Epoch 1/2 (50.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t📊 Training Loss: 3.2838\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t✅ Training Accuracy: 22.20%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t⏳ Elapsed Time: 8.68s | ETA: 8.68s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t🕒 Completed At: 09:52\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m Client 8 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: sneezy_squirtle_60\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  23%|██▎       | 919/4000 [00:02<00:06, 475.45batch/s]\u001B[32m [repeated 67x across cluster]\u001B[0m\n",
      "Training progress:  14%|█▍        | 568/4000 [00:01<00:08, 410.92batch/s]\u001B[32m [repeated 6x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:08<00:00, 462.99batch/s]\u001B[32m [repeated 8x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:08<00:00, 460.95batch/s]\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Training progress:  84%|████████▍ | 3370/4000 [00:07<00:01, 465.75batch/s]\u001B[32m [repeated 82x across cluster]\u001B[0m\n",
      "Training progress:  86%|████████▌ | 3433/4000 [00:07<00:01, 463.56batch/s]\u001B[32m [repeated 8x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t📊 Training Loss: 3.0828\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t✅ Training Accuracy: 26.55%\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t⏳ Elapsed Time: 8.39s | ETA: 0.00s\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t🕒 Completed At: 09:52\u001B[32m [repeated 2x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n",
      "[Round 1] Avg Client Drift: 6.7571\n",
      "[Round 1] Relative Client Drift: 0.1177\n",
      "Saving centralized model epoch 7 aggregated_parameters...\n",
      "💾 Saved checkpoint at: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\model_test\\FL_TinyCNN_epoch_7.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 10000/10000 [00:07<00:00, 1266.91batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      ROUND 1💡 New best global model found: 0.248700\n",
      "\u001B[92mINFO \u001B[0m:      fit progress: (1, 3.228033823483065, {'centralized_accuracy': 0.2487}, 100.7594360000221)\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round 1 - loss: 3.228033823483065, metrics: {'centralized_accuracy': 0.2487}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1000 [00:00<?, ?batch/s]\n",
      "Training progress: 100%|██████████| 4000/4000 [00:08<00:00, 476.76batch/s]\u001B[32m [repeated 16x across cluster]\u001B[0m\n",
      "Training progress:  90%|█████████ | 3607/4000 [00:07<00:00, 469.48batch/s]\u001B[32m [repeated 6x across cluster]\u001B[0m\n",
      "Training progress:  88%|████████▊ | 3512/4000 [00:07<00:01, 469.40batch/s]\n",
      "Eval progress:   2%|▏         | 22/1000 [00:00<00:04, 200.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m Client 8 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t📊 Training Loss: 3.1054\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t✅ Training Accuracy: 26.85%\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t⏳ Elapsed Time: 8.39s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t🕒 Completed At: 09:52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:  16%|█▋        | 165/1000 [00:00<00:02, 403.63batch/s]\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:01<00:00, 607.17batch/s]\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:00<00:00, 1434.23batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 2]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m Client 3 is ready to train\u001B[32m [repeated 5x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: cranky_nidorino_52\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Eval progress:   0%|          | 0/1000 [00:00<?, ?batch/s]\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "Eval progress:  86%|████████▌ | 856/1000 [00:00<00:00, 1429.11batch/s]\u001B[32m [repeated 45x across cluster]\u001B[0m\n",
      "Eval progress:  71%|███████   | 710/1000 [00:01<00:00, 677.57batch/s]\u001B[32m [repeated 6x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 2/4000 [00:00<04:13, 15.80batch/s]\n",
      "Training progress:   1%|▏         | 55/4000 [00:00<00:22, 172.35batch/s]\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:01<00:00, 747.94batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:  39%|███▉      | 1578/4000 [00:05<00:07, 305.47batch/s]\u001B[32m [repeated 176x across cluster]\u001B[0m\n",
      "Training progress:  37%|███▋      | 1490/4000 [00:05<00:08, 308.61batch/s]\u001B[32m [repeated 13x across cluster]\u001B[0m\n",
      "Training progress:  76%|███████▌  | 3049/4000 [00:10<00:03, 275.79batch/s]\u001B[32m [repeated 155x across cluster]\u001B[0m\n",
      "Training progress:  73%|███████▎  | 2906/4000 [00:09<00:03, 301.88batch/s]\u001B[32m [repeated 16x across cluster]\u001B[0m\n",
      "Training progress:  92%|█████████▏| 3661/4000 [00:12<00:01, 315.62batch/s]\n",
      "Training progress:  93%|█████████▎| 3730/4000 [00:12<00:00, 318.18batch/s]\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m 🚀 Epoch 1/2 (50.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \t📊 Training Loss: 3.2398\n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \t✅ Training Accuracy: 23.97%\n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \t⏳ Elapsed Time: 13.33s | ETA: 13.33s\n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \t🕒 Completed At: 09:53\n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m Client 0 is ready to train\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: chirpy_nidoking_59\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  16%|█▌        | 638/4000 [00:02<00:10, 308.19batch/s]\u001B[32m [repeated 115x across cluster]\u001B[0m\n",
      "Training progress:  18%|█▊        | 703/4000 [00:02<00:10, 313.18batch/s]\u001B[32m [repeated 19x across cluster]\u001B[0m\n",
      "Training progress:  99%|█████████▉| 3956/4000 [00:13<00:00, 315.29batch/s]\u001B[32m [repeated 39x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 294.72batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:  56%|█████▌    | 2224/4000 [00:07<00:05, 301.39batch/s]\u001B[32m [repeated 151x across cluster]\u001B[0m\n",
      "Training progress:  58%|█████▊    | 2309/4000 [00:07<00:05, 330.59batch/s]\u001B[32m [repeated 22x across cluster]\u001B[0m\n",
      "Training progress:  92%|█████████▏| 3675/4000 [00:11<00:01, 319.68batch/s]\n",
      "Training progress:  91%|█████████▏| 3651/4000 [00:11<00:01, 313.54batch/s]\n",
      "Training progress:  94%|█████████▎| 3745/4000 [00:12<00:00, 321.08batch/s]\n",
      "Training progress:  91%|█████████ | 3632/4000 [00:11<00:01, 307.86batch/s]\u001B[32m [repeated 127x across cluster]\u001B[0m\n",
      "Training progress:  90%|█████████ | 3600/4000 [00:11<00:01, 305.07batch/s]\u001B[32m [repeated 23x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t📊 Training Loss: 3.0073\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t✅ Training Accuracy: 29.75%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t⏳ Elapsed Time: 12.80s | ETA: 0.00s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t🕒 Completed At: 09:53\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m Client 6 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: perky_charizard_12\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress: 100%|██████████| 4000/4000 [00:12<00:00, 312.73batch/s]\u001B[32m [repeated 28x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:12<00:00, 315.20batch/s]\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "Training progress:  17%|█▋        | 680/4000 [00:02<00:10, 310.60batch/s]\u001B[32m [repeated 68x across cluster]\u001B[0m\n",
      "Training progress:  18%|█▊        | 713/4000 [00:02<00:11, 294.19batch/s]\u001B[32m [repeated 12x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:  55%|█████▌    | 2212/4000 [00:07<00:05, 310.83batch/s]\u001B[32m [repeated 137x across cluster]\u001B[0m\n",
      "Training progress:  55%|█████▌    | 2219/4000 [00:07<00:05, 304.14batch/s]\u001B[32m [repeated 29x across cluster]\u001B[0m\n",
      "Training progress:  92%|█████████▏| 3674/4000 [00:12<00:01, 290.13batch/s]\n",
      "Training progress:  92%|█████████▏| 3686/4000 [00:12<00:01, 313.09batch/s]\n",
      "Training progress:  93%|█████████▎| 3705/4000 [00:12<00:01, 293.72batch/s]\n",
      "Training progress:  92%|█████████▏| 3664/4000 [00:12<00:01, 299.06batch/s]\n",
      "Training progress:  91%|█████████ | 3622/4000 [00:12<00:01, 298.86batch/s]\u001B[32m [repeated 127x across cluster]\u001B[0m\n",
      "Training progress:  90%|████████▉ | 3591/4000 [00:12<00:01, 299.80batch/s]\u001B[32m [repeated 24x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m 🚀 Epoch 1/2 (50.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t📊 Training Loss: 3.2425\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t✅ Training Accuracy: 24.62%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t⏳ Elapsed Time: 13.26s | ETA: 13.26s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t🕒 Completed At: 09:53\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m Client 5 is ready to train\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: jolly_nidorina_77\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  99%|█████████▉| 3954/4000 [00:13<00:00, 290.36batch/s]\u001B[32m [repeated 29x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 297.60batch/s]\u001B[32m [repeated 9x across cluster]\u001B[0m\n",
      "Training progress:  31%|███       | 1222/4000 [00:04<00:09, 305.25batch/s]\u001B[32m [repeated 132x across cluster]\u001B[0m\n",
      "Training progress:  32%|███▏      | 1287/4000 [00:04<00:08, 311.38batch/s]\u001B[32m [repeated 15x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:  69%|██████▉   | 2750/4000 [00:09<00:04, 312.15batch/s]\u001B[32m [repeated 138x across cluster]\u001B[0m\n",
      "Training progress:  69%|██████▉   | 2767/4000 [00:09<00:03, 318.57batch/s]\u001B[32m [repeated 26x across cluster]\u001B[0m\n",
      "Training progress:  92%|█████████▏| 3666/4000 [00:12<00:01, 264.49batch/s]\n",
      "Training progress:  92%|█████████▏| 3693/4000 [00:12<00:01, 263.77batch/s]\n",
      "Training progress:  94%|█████████▎| 3748/4000 [00:12<00:00, 256.37batch/s]\n",
      "Training progress:  91%|█████████ | 3634/4000 [00:12<00:01, 268.89batch/s]\u001B[32m [repeated 87x across cluster]\u001B[0m\n",
      "Training progress:  89%|████████▊ | 3549/4000 [00:12<00:01, 275.97batch/s]\u001B[32m [repeated 17x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t📊 Training Loss: 3.0517\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t✅ Training Accuracy: 28.35%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t⏳ Elapsed Time: 13.84s | ETA: 0.00s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t🕒 Completed At: 09:54\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=26596)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Training progress:   1%|          | 41/4000 [00:00<00:09, 399.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m Client 8 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: witty_raichu_66\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  99%|█████████▉| 3965/4000 [00:13<00:00, 281.89batch/s]\u001B[32m [repeated 26x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:13<00:00, 288.01batch/s]\u001B[32m [repeated 12x across cluster]\u001B[0m\n",
      "Training progress:  46%|████▋     | 1850/4000 [00:04<00:05, 400.76batch/s]\u001B[32m [repeated 57x across cluster]\u001B[0m\n",
      "Training progress:  48%|████▊     | 1928/4000 [00:04<00:05, 405.99batch/s]\u001B[32m [repeated 15x across cluster]\u001B[0m\n",
      "Training progress:  92%|█████████▏| 3661/4000 [00:08<00:00, 440.65batch/s]\n",
      "Training progress:  94%|█████████▎| 3743/4000 [00:09<00:00, 429.34batch/s]\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Training progress:  90%|█████████ | 3610/4000 [00:08<00:00, 440.70batch/s]\u001B[32m [repeated 62x across cluster]\u001B[0m\n",
      "Training progress:  89%|████████▉ | 3565/4000 [00:08<00:00, 438.78batch/s]\u001B[32m [repeated 9x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m 🚀 Epoch 1/2 (50.00%) Completed\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t📊 Training Loss: 3.2164\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t✅ Training Accuracy: 24.50%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t⏳ Elapsed Time: 9.76s | ETA: 9.76s\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t🕒 Completed At: 09:54\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m Client 9 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m No prefix/name for the model was provided, choosen prefix/name: perky_nidorina_35\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress: 100%|██████████| 4000/4000 [00:09<00:00, 409.77batch/s]\u001B[32m [repeated 10x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:09<00:00, 408.35batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Training progress:   0%|          | 0/4000 [00:00<?, ?batch/s]\n",
      "Training progress:  54%|█████▍    | 2172/4000 [00:05<00:04, 432.57batch/s]\u001B[32m [repeated 71x across cluster]\u001B[0m\n",
      "Training progress:  52%|█████▏    | 2082/4000 [00:05<00:04, 416.15batch/s]\u001B[32m [repeated 13x across cluster]\u001B[0m\n",
      "Training progress:  92%|█████████▏| 3671/4000 [00:08<00:00, 400.08batch/s]\n",
      "Training progress:  98%|█████████▊| 3908/4000 [00:09<00:00, 410.01batch/s]\u001B[32m [repeated 5x across cluster]\u001B[0m\n",
      "Training progress:  96%|█████████▌| 3838/4000 [00:09<00:00, 410.21batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t📊 Training Loss: 3.0275\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t✅ Training Accuracy: 28.23%\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t⏳ Elapsed Time: 9.50s | ETA: 0.00s\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13168)\u001B[0m \t🕒 Completed At: 09:54\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \n",
      "[Round 2] Avg Client Drift: 6.5355\n",
      "[Round 2] Relative Client Drift: 0.1064\n",
      "Saving centralized model epoch 8 aggregated_parameters...\n",
      "💾 Saved checkpoint at: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\model_test\\FL_TinyCNN_epoch_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 10000/10000 [00:08<00:00, 1219.26batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      ROUND 2💡 New best global model found: 0.257100\n",
      "\u001B[92mINFO \u001B[0m:      fit progress: (2, 3.17438264849931, {'centralized_accuracy': 0.2571}, 193.33538380003301)\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server round 2 - loss: 3.17438264849931, metrics: {'centralized_accuracy': 0.2571}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1000 [00:00<?, ?batch/s]\n",
      "Training progress:  90%|████████▉ | 3588/4000 [00:08<00:01, 388.71batch/s]\u001B[32m [repeated 53x across cluster]\u001B[0m\n",
      "Training progress:  82%|████████▏ | 3299/4000 [00:07<00:01, 478.53batch/s]\u001B[32m [repeated 5x across cluster]\u001B[0m\n",
      "Training progress: 100%|██████████| 4000/4000 [00:09<00:00, 421.68batch/s]\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "Eval progress:   3%|▎         | 31/1000 [00:00<00:03, 309.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m Client 4 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m 🚀 Epoch 2/2 (100.00%) Completed\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t📊 Training Loss: 3.0032\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t✅ Training Accuracy: 28.05%\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t⏳ Elapsed Time: 9.49s | ETA: 0.00s\n",
      "\u001B[36m(ClientAppActor pid=13348)\u001B[0m \t🕒 Completed At: 09:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:  17%|█▋        | 168/1000 [00:00<00:01, 485.16batch/s]\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:01<00:00, 613.58batch/s]\n",
      "Eval progress:  93%|█████████▎| 926/1000 [00:01<00:00, 650.91batch/s]\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:01<00:00, 610.13batch/s]\n",
      "Eval progress:  15%|█▌        | 151/1000 [00:00<00:00, 1502.86batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [SUMMARY]\n",
      "\u001B[92mINFO \u001B[0m:      Run finished 2 round(s) in 198.27s\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, distributed):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 3.35031576801748\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 3.2764338486138733\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, centralized):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 0: 3.29260735466443\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 3.228033823483065\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 3.17438264849931\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, distributed, fit):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'avg_drift': [(1, 6.757137107849121), (2, 6.53552565574646)],\n",
      "\u001B[92mINFO \u001B[0m:      \t 'avg_train_loss': [(1, 6.387376895500929), (2, 6.2342362486633585)]}\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'federated_evaluate_accuracy': [(1, 0.2202), (2, 0.231)]}\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, centralized):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'centralized_accuracy': [(0, 0.2372), (1, 0.2487), (2, 0.2571)]}\n",
      "\u001B[92mINFO \u001B[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=4136)\u001B[0m Client 8 is ready to train\u001B[32m [repeated 4x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1000 [00:00<?, ?batch/s]\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "Eval progress:  90%|████████▉ | 896/1000 [00:00<00:00, 1455.22batch/s]\u001B[32m [repeated 47x across cluster]\u001B[0m\n",
      "Eval progress:  75%|███████▍  | 747/1000 [00:00<00:00, 1438.15batch/s]\u001B[32m [repeated 6x across cluster]\u001B[0m\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:01<00:00, 608.87batch/s]\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "Eval progress: 100%|██████████| 1000/1000 [00:00<00:00, 1455.75batch/s]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3256a71857baf080"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
