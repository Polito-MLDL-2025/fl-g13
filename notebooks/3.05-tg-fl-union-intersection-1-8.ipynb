{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed3f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28738f6",
   "metadata": {},
   "source": [
    "# Import cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239c7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr\n",
    "import torch\n",
    "import dotenv\n",
    "import wandb\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from fl_g13.architectures import BaseDino\n",
    "from fl_g13.editing import SparseSGDM\n",
    "\n",
    "from fl_g13.fl_pytorch import build_fl_dependencies\n",
    "\n",
    "from fl_g13.fl_pytorch.datasets import reset_partition\n",
    "from fl_g13.modeling import load_or_create\n",
    "from fl_g13.editing import SparseSGDM, mask_dict_to_list, compute_mask_stats, format_mask_stats\n",
    "from torch.optim import SGD\n",
    "\n",
    "from fl_g13.fl_pytorch.editing import load_mask\n",
    "\n",
    "from fl_g13.fl_pytorch import get_client_app, get_server_app\n",
    "from flwr.simulation import run_simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53f2347",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e263b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "build_fl_dependencies()\n",
    "\n",
    "if DEVICE == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
    "else:\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4be89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# login by key in .env file\n",
    "WANDB_API_KEY = dotenv.dotenv_values()[\"WANDB_API_KEY\"]\n",
    "wandb.login(key=WANDB_API_KEY)\n",
    "\n",
    "# Load checkpoint from .env file\n",
    "CHECKPOINT_DIR = dotenv.dotenv_values()[\"CHECKPOINT_DIR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb218089",
   "metadata": {},
   "source": [
    "# Training parameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9668493",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Hyper-parameters\n",
    "head_layers = 3\n",
    "head_hidden_size = 512\n",
    "dropout_rate = 0.0\n",
    "unfreeze_blocks = 12\n",
    "\n",
    "dino_config = {\n",
    "    'head_layers': head_layers,\n",
    "    'head_hidden_size': head_hidden_size,\n",
    "    'dropout_rate': dropout_rate,\n",
    "    'unfreeze_blocks': unfreeze_blocks\n",
    "}\n",
    "\n",
    "## Training Hyper-parameters\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-5\n",
    "\n",
    "# FL config\n",
    "K = 100\n",
    "C = 0.1\n",
    "J = 8\n",
    "num_shards_per_partition = 1 # Nc\n",
    "partition_type = 'shard'\n",
    "\n",
    "num_rounds = 100\n",
    "\n",
    "## Server App config\n",
    "save_every = 5\n",
    "evaluate_each = 5\n",
    "fraction_fit = C        # 0.1\n",
    "fraction_evaluate = C   # 0.1\n",
    "min_fit_clients = 10\n",
    "min_evaluate_clients = 5\n",
    "min_available_clients = 10\n",
    "\n",
    "# model editing config\n",
    "model_editing = True\n",
    "mask_type = 'local'\n",
    "sparsity = 0.7\n",
    "calibration_rounds = 3\n",
    "model_editing_batch_size = 1\n",
    "\n",
    "## simulation run config\n",
    "NUM_CLIENTS = 100\n",
    "MAX_PARALLEL_CLIENTS = 10\n",
    "\n",
    "## Base model location\n",
    "model_save_path = CHECKPOINT_DIR + f\"/fl/non-iid/{num_shards_per_partition}_{J}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e635978",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42254b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, start_epoch = load_or_create(\n",
    "    path=model_save_path,\n",
    "    model_class=BaseDino,\n",
    "    model_config=dino_config,\n",
    "    optimizer=None,\n",
    "    scheduler=None,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "model.to(DEVICE)\n",
    "\n",
    "if model_editing:\n",
    "    # Create a dummy mask for SparseSGDM\n",
    "    dummy_mask = [torch.ones_like(p, device=p.device) for p in model.parameters()]  \n",
    "    \n",
    "    optimizer = SparseSGDM(\n",
    "        model.parameters(),\n",
    "        mask=dummy_mask,\n",
    "        lr=lr,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "else:\n",
    "    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = None\n",
    "\n",
    "# Unfreeze entire model for model_editing\n",
    "model.unfreeze_blocks(unfreeze_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1592c53",
   "metadata": {},
   "source": [
    "# Load masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "union_mask_file_name = CHECKPOINT_DIR + f'/masks/union_{num_shards_per_partition}_{J}_{mask_type}_{sparsity}_{calibration_rounds}.pth'\n",
    "\n",
    "union_mask = load_mask(union_mask_file_name)\n",
    "print(format_mask_stats(compute_mask_stats(union_mask)))\n",
    "union_mask = mask_dict_to_list(model, union_mask) # converts for SparseSGDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e1b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_mask_file_name = CHECKPOINT_DIR + f'/masks/intersection_{num_shards_per_partition}_{J}_{mask_type}_{sparsity}_{calibration_rounds}.pth'\n",
    "\n",
    "intersection_mask = load_mask(intersection_mask_file_name)\n",
    "print(format_mask_stats(compute_mask_stats(intersection_mask)))\n",
    "intersection_mask = mask_dict_to_list(model, intersection_mask) # converts for SparseSGDM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193ea4de",
   "metadata": {},
   "source": [
    "# Union simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8d9cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_partition()\n",
    "\n",
    "model_checkpoint = CHECKPOINT_DIR + f\"/fl/non-iid/Union/{num_shards_per_partition}_{J}_{mask_type}_{sparsity}_{calibration_rounds}\"\n",
    "\n",
    "# Wandb settings\n",
    "use_wandb = False\n",
    "run_name = f\"fl_union_{num_shards_per_partition}_{J}_{mask_type}_{sparsity}_{calibration_rounds}\"\n",
    "wandb_config = {\n",
    "    # wandb param\n",
    "    'name': run_name,\n",
    "    'project_name': f\"fl_v5_{num_shards_per_partition}_{J}_centralized_masks\",\n",
    "    'run_id': run_name,\n",
    "    \n",
    "    # fl config\n",
    "    \"fraction_fit\": fraction_fit,\n",
    "    \"lr\": lr,\n",
    "    \"momentum\": momentum,\n",
    "    'weight_decay': weight_decay,\n",
    "    'partition_type': partition_type,\n",
    "    'K': K,\n",
    "    'C': C,\n",
    "    'J': J,\n",
    "    'Nc': num_shards_per_partition,\n",
    "    \n",
    "    # model config\n",
    "    'head_layers': head_layers,\n",
    "    'head_hidden_size': head_hidden_size,\n",
    "    'dropout_rate': dropout_rate,\n",
    "    'unfreeze_blocks': unfreeze_blocks,\n",
    "    \n",
    "    # model editing config\n",
    "    'model_editing_batch_size': model_editing_batch_size,\n",
    "    'mask_calibration_round': calibration_rounds,\n",
    "    'mask_type': mask_type,\n",
    "    'sparsity': sparsity,\n",
    "}\n",
    "\n",
    "client = get_client_app(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    "    partition_type=partition_type,\n",
    "    local_epochs=1,\n",
    "    local_steps=J,\n",
    "    batch_size=batch_size,\n",
    "    num_shards_per_partition=num_shards_per_partition,\n",
    "    scheduler=scheduler,\n",
    "    model_editing=model_editing,\n",
    "    mask_type=mask_type,\n",
    "    sparsity=sparsity,\n",
    "    mask=union_mask,  # Give starting centralized mask to all the clients \n",
    "    model_editing_batch_size=model_editing_batch_size,\n",
    "    mask_func=None,\n",
    "    mask_calibration_round=calibration_rounds\n",
    ")\n",
    "\n",
    "server = get_server_app(\n",
    "    checkpoint_dir=model_checkpoint,\n",
    "    model_class=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_rounds=num_rounds,\n",
    "    fraction_fit=fraction_fit,\n",
    "    fraction_evaluate=fraction_evaluate,\n",
    "    min_fit_clients=min_fit_clients,\n",
    "    min_evaluate_clients=min_evaluate_clients,\n",
    "    min_available_clients=min_available_clients,\n",
    "    device=DEVICE,\n",
    "    use_wandb=use_wandb,\n",
    "    wandb_config=wandb_config,\n",
    "    save_every=save_every,\n",
    "    prefix='Union',\n",
    "    evaluate_each=evaluate_each,\n",
    "    model= model,\n",
    "    start_epoch= start_epoch\n",
    ")\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config\n",
    ")\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44390b1a",
   "metadata": {},
   "source": [
    "# Intersection Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937cbb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_partition()\n",
    "\n",
    "model_checkpoint = CHECKPOINT_DIR + f\"/fl/non-iid/Intersection/{num_shards_per_partition}_{J}_{mask_type}_{sparsity}_{calibration_rounds}\"\n",
    "\n",
    "# Wandb settings\n",
    "use_wandb = True\n",
    "run_name = f\"fl_intersection_{num_shards_per_partition}_{J}_{mask_type}_{sparsity}_{calibration_rounds}\"\n",
    "wandb_config = {\n",
    "    # wandb param\n",
    "    'name': run_name,\n",
    "    'project_name': f\"fl_v5_{num_shards_per_partition}_{J}_centralized_masks\",\n",
    "    'run_id': run_name,\n",
    "    \n",
    "    # fl config\n",
    "    \"fraction_fit\": fraction_fit,\n",
    "    \"lr\": lr,\n",
    "    \"momentum\": momentum,\n",
    "    'weight_decay': weight_decay,\n",
    "    'partition_type': partition_type,\n",
    "    'K': K,\n",
    "    'C': C,\n",
    "    'J': J,\n",
    "    'Nc': num_shards_per_partition,\n",
    "    \n",
    "    # model config\n",
    "    'head_layers': head_layers,\n",
    "    'head_hidden_size': head_hidden_size,\n",
    "    'dropout_rate': dropout_rate,\n",
    "    'unfreeze_blocks': unfreeze_blocks,\n",
    "    \n",
    "    # model editing config\n",
    "    'model_editing_batch_size': model_editing_batch_size,\n",
    "    'mask_calibration_round': calibration_rounds,\n",
    "    'mask_type': mask_type,\n",
    "    'sparsity': sparsity,\n",
    "}\n",
    "\n",
    "client = get_client_app(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    "    partition_type=partition_type,\n",
    "    local_epochs=1,\n",
    "    local_steps=J,\n",
    "    batch_size=batch_size,\n",
    "    num_shards_per_partition=num_shards_per_partition,\n",
    "    scheduler=scheduler,\n",
    "    model_editing=model_editing,\n",
    "    mask_type=mask_type,\n",
    "    sparsity=sparsity,\n",
    "    mask=intersection_mask,  # Give starting centralized mask to all the clients \n",
    "    model_editing_batch_size=model_editing_batch_size,\n",
    "    mask_func=None,\n",
    "    mask_calibration_round=calibration_rounds\n",
    ")\n",
    "\n",
    "server = get_server_app(\n",
    "    checkpoint_dir=model_checkpoint,\n",
    "    model_class=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_rounds=num_rounds,\n",
    "    fraction_fit=fraction_fit,\n",
    "    fraction_evaluate=fraction_evaluate,\n",
    "    min_fit_clients=min_fit_clients,\n",
    "    min_evaluate_clients=min_evaluate_clients,\n",
    "    min_available_clients=min_available_clients,\n",
    "    device=DEVICE,\n",
    "    use_wandb=use_wandb,\n",
    "    wandb_config=wandb_config,\n",
    "    save_every=save_every,\n",
    "    prefix='Intersection',\n",
    "    evaluate_each=evaluate_each,\n",
    "    model= model,\n",
    "    start_epoch= start_epoch,\n",
    ")\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config\n",
    ")\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
