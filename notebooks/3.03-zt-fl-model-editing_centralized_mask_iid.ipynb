{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:27:11.750709Z",
     "start_time": "2025-06-03T18:27:11.609217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "5767f6b1a63e945b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:27:11.890661Z",
     "start_time": "2025-06-03T18:27:11.752666Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
   "id": "75ca9d6d54c4ce47",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:27:30.967984Z",
     "start_time": "2025-06-03T18:27:11.892605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import flwr\n",
    "import torch\n",
    "from flwr.simulation import run_simulation\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from fl_g13.architectures import BaseDino\n",
    "from fl_g13.editing import SparseSGDM\n",
    "from fl_g13.fl_pytorch.client_app import get_client_app\n",
    "from fl_g13.fl_pytorch.server_app import get_server_app\n",
    "from fl_g13.fl_pytorch.editing.centralized_mask import save_mask\n",
    "from fl_g13.fl_pytorch.editing.centralized_mask import load_mask"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-06-03 20:27:19.321\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mfl_g13.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:27:32.059921Z",
     "start_time": "2025-06-03T18:27:30.969985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# DEVICE = \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "# disable_progress_bar()"
   ],
   "id": "1a4ec3eb7baf32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Flower 1.17.0 / PyTorch 2.6.0+cu118\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Login wandb",
   "id": "73fb84b164b0def7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:27:35.812991Z",
     "start_time": "2025-06-03T18:27:32.061921Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install wandb",
   "id": "6c6449ef9be1e422",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (0.19.9)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (68.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (4.13.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:27:37.134424Z",
     "start_time": "2025-06-03T18:27:35.815797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## read .env file\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n"
   ],
   "id": "5f279490dd7a970f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:27:39.449634Z",
     "start_time": "2025-06-03T18:27:37.136373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "# login by key in .env file\n",
    "WANDB_API_KEY = dotenv.dotenv_values()[\"WANDB_API_KEY\"]\n",
    "wandb.login(key=WANDB_API_KEY)"
   ],
   "id": "a218d880822fdfba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\notebook\\utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  return LooseVersion(v) >= LooseVersion(check)\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\ADMIN\\_netrc\n",
      "wandb: Currently logged in as: thanhnv-it23 (stefano-gamba-social-politecnico-di-torino) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build module local\n",
    "\n",
    "Build module local such that ClientApp can use it"
   ],
   "id": "b5a0319c8e40215a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:27:49.945717Z",
     "start_time": "2025-06-03T18:27:39.451236Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -e ..",
   "id": "8a11402a3317027f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/ADMIN/Desktop/BACKUP/study/Italy/polito/classes/20242/deep%20learning/project/source_code/fl-g13"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies: started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies: finished with status 'done'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Checking if build backend supports build_editable: started"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checking if build backend supports build_editable: finished with status 'done'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Getting requirements to build editable: started"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[notice] To update, run: python.exe -m pip install --upgrade pip"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Download missing module for clients\n",
    "\n",
    "Dino model,that is serialized and sent to client by server, require some modules that have to download from source code of dino model\n"
   ],
   "id": "9399f1a9cedc8cc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:27:51.253588Z",
     "start_time": "2025-06-03T18:27:49.950711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def download_if_not_exists(file_path: str, file_url: str):\n",
    "    \"\"\"\n",
    "    Checks if a file exists at the given path. If it does not, downloads it from the specified URL.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The local path to check and save the file.\n",
    "    - file_url (str): The URL from which to download the file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"'{file_path}' not found. Downloading from {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "            print(\"Download complete.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download file: {e}\")\n",
    "    else:\n",
    "        print(f\"'{file_path}' already exists.\")"
   ],
   "id": "beb2c855fcd8933c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:27:52.209912Z",
     "start_time": "2025-06-03T18:27:51.255631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "download_if_not_exists(\"vision_transformer.py\",\n",
    "                       \"https://raw.githubusercontent.com/facebookresearch/dino/refs/heads/main/vision_transformer.py\")\n",
    "download_if_not_exists(\"utils.py\",\n",
    "                       \"https://raw.githubusercontent.com/facebookresearch/dino/refs/heads/main/utils.py\")\n"
   ],
   "id": "d93caca63a33c71f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'vision_transformer.py' already exists.\n",
      "'utils.py' already exists.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FL",
   "id": "ee82432353abfbe2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configs",
   "id": "cdb05316b163821b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:27:53.417259Z",
     "start_time": "2025-06-03T18:27:52.213774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import flwr\n",
    "import torch\n",
    "from flwr.simulation import run_simulation\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "from fl_g13.architectures import BaseDino\n",
    "from fl_g13.config import RAW_DATA_DIR\n",
    "from fl_g13.editing import SparseSGDM\n",
    "from fl_g13.fl_pytorch.client_app import get_client_app\n",
    "from fl_g13.fl_pytorch.datasets import get_eval_transforms\n",
    "from fl_g13.fl_pytorch.server_app import get_server_app\n",
    "from fl_g13.modeling.eval import eval"
   ],
   "id": "f412342fdd69962f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:27:54.490881Z",
     "start_time": "2025-06-03T18:27:53.419258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# DEVICE = \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")"
   ],
   "id": "e8f0a429e7c37ca9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Flower 1.17.0 / PyTorch 2.6.0+cu118\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:27:55.501152Z",
     "start_time": "2025-06-03T18:27:54.492877Z"
    }
   },
   "cell_type": "code",
   "source": "DEBUG = False",
   "id": "6ba4f53af219c423",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model config",
   "id": "9dfdb97735c00ba0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## checkpoints directory\n",
    "current_path = Path.cwd()\n",
    "model_save_path = current_path / f\"../models/fl_dino_baseline/iid\""
   ],
   "id": "11834a21a0d56dd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:28:00.593997Z",
     "start_time": "2025-06-03T18:27:59.660584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model config\n",
    "\n",
    "## Model Hyper-parameters\n",
    "head_layers = 3\n",
    "head_hidden_size = 512\n",
    "dropout_rate = 0.0\n",
    "unfreeze_blocks = 12\n",
    "\n",
    "## Training Hyper-parameters\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-5\n",
    "T_max = 8\n",
    "eta_min = 1e-5\n",
    "\n",
    "# FL config\n",
    "K = 100\n",
    "C = 0.1\n",
    "J = 4\n",
    "num_rounds = 30\n",
    "partition_type = 'iid'\n",
    "\n",
    "## only for partition_type = 'shard'\n",
    "num_shards_per_partition = 10\n",
    "\n",
    "## Server App config\n",
    "save_every = 1\n",
    "fraction_fit = C  # Sample of available clients for training\n",
    "fraction_evaluate = 0.1  # Sample 50% of available clients for evaluation\n",
    "min_fit_clients = 10  # Never sample less than 10 clients for training\n",
    "min_evaluate_clients = 5  # Never sample less than 5 clients for evaluation\n",
    "min_available_clients = 10  # Wait until all 10 clients are available\n",
    "device = 'cuda'\n",
    "\n",
    "checkpoint_dir = model_save_path.resolve()\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "## Wandb config\n",
    "use_wandb = True\n",
    "wandb_config = {\n",
    "    # wandb param\n",
    "    'name': 'FL_Dino_Baseline_iid',\n",
    "    'project_name': \"FL_test_chart\",\n",
    "    # model config param\n",
    "    \"fraction_fit\": fraction_fit,\n",
    "    \"lr\": lr,\n",
    "    \"momentum\": momentum,\n",
    "    'partition_type': partition_type,\n",
    "    'K': K,\n",
    "    'C': C,\n",
    "    'J': J,\n",
    "}\n",
    "\n",
    "# model editing config\n",
    "model_editing = True\n",
    "mask_type = 'global'\n",
    "sparsity = 0.2\n",
    "mask = None\n",
    "\n",
    "## simulation run config\n",
    "NUM_CLIENTS = 100\n",
    "MAX_PARALLEL_CLIENTS = 10\n",
    "\n",
    "if DEBUG:\n",
    "    use_wandb = False\n",
    "    num_rounds = 2\n",
    "    J = 4\n"
   ],
   "id": "d63bb533ec30809b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define model , optimizer and loss function",
   "id": "4c0f23c3615c6d68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:28:02.449698Z",
     "start_time": "2025-06-03T18:28:00.596337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fl_g13.modeling import load_or_create\n",
    "\n",
    "# Model\n",
    "model, start_epoch = load_or_create(\n",
    "    path=checkpoint_dir,\n",
    "    model_class=BaseDino,\n",
    "    model_config=None,\n",
    "    optimizer=None,\n",
    "    scheduler=None,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    ")\n",
    "model.unfreeze_blocks(unfreeze_blocks)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# Create a dummy mask for SparseSGDM\n",
    "init_mask = [torch.ones_like(p, device=p.device) for p in\n",
    "             model.parameters()]  # Must be done AFTER the model is moved to the device\n",
    "# Optimizer, scheduler, and loss function\n",
    "optimizer = SparseSGDM(\n",
    "    model.parameters(),\n",
    "    mask=init_mask,\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer=optimizer,\n",
    "    T_max=T_max,\n",
    "    eta_min=eta_min\n",
    ")"
   ],
   "id": "9046d19b28a38ed3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Loading checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_200_iid.pth\n",
      "ðŸ“¦ Model class in checkpoint: BaseDino\n",
      "ðŸ”§ Model configuration: {'variant': 'dino_vits16', 'dropout_rate': 0.0, 'head_hidden_size': 512, 'head_layers': 3, 'num_classes': 100, 'unfreeze_blocks': 0, 'activation_fn': 'GELU', 'pretrained': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n",
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âž¡ï¸ Moved model to device: cuda\n",
      "âœ… Loaded checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_200_iid.pth, resuming at epoch 201\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compute stats for mask",
   "id": "261196813ced5c7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:30:19.296552Z",
     "start_time": "2025-06-03T18:30:18.196503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "def compute_mask_stats(mask_dict: Dict[str, torch.Tensor]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Computes various statistics for a mask represented as a dictionary\n",
    "    mapping parameter names to mask tensors.\n",
    "\n",
    "    Args:\n",
    "        mask_dict: A dictionary where keys are parameter names (str)\n",
    "                   and values are mask tensors (torch.Tensor) containing 0s and 1s.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing overall and layer-wise mask statistics.\n",
    "    \"\"\"\n",
    "    stats = {}\n",
    "\n",
    "    # --- Overall Statistics ---\n",
    "    total_elements = 0\n",
    "    kept_elements_overall = 0 # Elements with value 1\n",
    "    masked_elements_overall = 0 # Elements with value 0\n",
    "\n",
    "    for name, mask_tensor in mask_dict.items():\n",
    "        num_elements = mask_tensor.numel()\n",
    "        kept_in_layer = torch.sum(mask_tensor == 1).item()\n",
    "        masked_in_layer = num_elements - kept_in_layer\n",
    "\n",
    "        total_elements += num_elements\n",
    "        kept_elements_overall += kept_in_layer\n",
    "        masked_elements_overall += masked_in_layer\n",
    "\n",
    "        # --- Layer-wise Statistics ---\n",
    "        layer_stats = {\n",
    "            'num_elements': num_elements,\n",
    "            'kept_elements': kept_in_layer,\n",
    "            'masked_elements': masked_in_layer,\n",
    "            'density': kept_in_layer / num_elements if num_elements > 0 else 0.0,\n",
    "            'sparsity': masked_in_layer / num_elements if num_elements > 0 else 0.0\n",
    "        }\n",
    "        stats[name] = layer_stats\n",
    "\n",
    "    # --- Add Overall Statistics to the result dictionary ---\n",
    "    stats['overall'] = {\n",
    "        'total_elements': total_elements,\n",
    "        'kept_elements': kept_elements_overall,\n",
    "        'masked_elements': masked_elements_overall,\n",
    "        'density': kept_elements_overall / total_elements if total_elements > 0 else 0.0,\n",
    "        'sparsity': masked_elements_overall / total_elements if total_elements > 0 else 0.0\n",
    "    }\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def print_mask_stats(stats: Dict[str, Any], layer = False):\n",
    "    \"\"\"\n",
    "    Prints the mask statistics in a readable format.\n",
    "\n",
    "    Args:\n",
    "        stats: The dictionary returned by compute_mask_stats.\n",
    "    \"\"\"\n",
    "    if 'overall' not in stats:\n",
    "        print(\"Invalid stats dictionary format.\")\n",
    "        return\n",
    "\n",
    "    overall_stats = stats['overall']\n",
    "    print(\"--- Overall Mask Statistics ---\")\n",
    "    print(f\"Total Elements: {overall_stats['total_elements']}\")\n",
    "    print(f\"Kept Elements (1s): {overall_stats['kept_elements']}\")\n",
    "    print(f\"Masked Elements (0s): {overall_stats['masked_elements']}\")\n",
    "    print(f\"Overall Density: {overall_stats['density']:.4f}\")\n",
    "    print(f\"Overall Sparsity: {overall_stats['sparsity']:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    if not layer:\n",
    "      return\n",
    "\n",
    "    print(\"--- Layer-wise Mask Statistics ---\")\n",
    "    # Sort layer names for consistent output\n",
    "    layer_names = sorted([name for name in stats if name != 'overall'])\n",
    "    for name in layer_names:\n",
    "        layer_stats = stats[name]\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"  Num Elements: {layer_stats['num_elements']}\")\n",
    "        print(f\"  Kept Elements: {layer_stats['kept_elements']}\")\n",
    "        print(f\"  Masked Elements: {layer_stats['masked_elements']}\")\n",
    "        print(f\"  Density: {layer_stats['density']:.4f}\")\n",
    "        print(f\"  Sparsity: {layer_stats['sparsity']:.4f}\")\n",
    "        print(\"-\" * 20)"
   ],
   "id": "53da86048504a92d",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate the centralized mask",
   "id": "89bcbe951f4c5307"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 19,
   "source": [
    "from fl_g13.fl_pytorch.editing.centralized_mask import get_centralized_mask\n",
    "\n",
    "## config client data set params\n",
    "client_partition_type = 'iid'  # 'iid' or 'shard' for non-iid dataset\n",
    "client_num_partitions = 100  # equal to number of client\n",
    "client_num_shards_per_partition = 10\n",
    "client_batch_size = 16\n",
    "client_train_test_split_ratio = 0.2\n",
    "client_dataset = \"cifar100\"\n",
    "client_seed = 42,\n",
    "client_return_dataset = False,\n",
    "\n",
    "## config get mask params\n",
    "mask_model = model\n",
    "mask_sparsity = 0.8\n",
    "mask_type = 'global'\n",
    "mask_rounds = 1\n",
    "mask_func = None\n",
    "\n",
    "## aggregate\n",
    "agg_strategy = 'union'\n",
    "agg_func = None\n",
    "\n",
    "if DEBUG:\n",
    "    client_num_partitions = 10\n",
    "    client_batch_size = 128\n",
    "    client_train_test_split_ratio = 0.9\n"
   ],
   "id": "cd32c4d605d88ffb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "centralized_mask = get_centralized_mask(\n",
    "    client_partition_type=client_partition_type,\n",
    "    client_num_partitions=client_num_partitions,\n",
    "    client_num_shards_per_partition=client_num_shards_per_partition,\n",
    "    client_batch_size=client_batch_size,\n",
    "    client_dataset=client_dataset,\n",
    "    client_seed=client_seed,\n",
    "    client_return_dataset=client_return_dataset,\n",
    "    mask_model=mask_model,\n",
    "    mask_sparsity=mask_sparsity,\n",
    "    mask_type=mask_type,\n",
    "    mask_rounds=mask_rounds,\n",
    "    mask_func=mask_func,\n",
    "    agg_strategy=agg_strategy,\n",
    "    agg_func=agg_func\n",
    ")\n"
   ],
   "id": "fe6b7dd9c469b68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "agg_strategy = 'intersection'\n",
    "centralized_mask_intersection = get_centralized_mask(\n",
    "    client_partition_type=client_partition_type,\n",
    "    client_num_partitions=client_num_partitions,\n",
    "    client_num_shards_per_partition=client_num_shards_per_partition,\n",
    "    client_batch_size=client_batch_size,\n",
    "    client_dataset=client_dataset,\n",
    "    client_seed=client_seed,\n",
    "    client_return_dataset=client_return_dataset,\n",
    "    mask_model=mask_model,\n",
    "    mask_sparsity=mask_sparsity,\n",
    "    mask_type=mask_type,\n",
    "    mask_rounds=mask_rounds,\n",
    "    mask_func=mask_func,\n",
    "    agg_strategy=agg_strategy,\n",
    "    agg_func=agg_func\n",
    ")"
   ],
   "id": "23c1d82018d34585",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:50:21.069552Z",
     "start_time": "2025-06-03T18:50:12.339164Z"
    }
   },
   "cell_type": "code",
   "source": "compute_mask_stats(centralized_mask[1])",
   "id": "c7cd59644b4f1cdd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head.0.weight': {'num_elements': 196608,\n",
       "  'kept_elements': 32195,\n",
       "  'masked_elements': 164413,\n",
       "  'density': 0.16375223795572916,\n",
       "  'sparsity': 0.8362477620442709},\n",
       " 'head.0.bias': {'num_elements': 512,\n",
       "  'kept_elements': 166,\n",
       "  'masked_elements': 346,\n",
       "  'density': 0.32421875,\n",
       "  'sparsity': 0.67578125},\n",
       " 'head.3.weight': {'num_elements': 262144,\n",
       "  'kept_elements': 98877,\n",
       "  'masked_elements': 163267,\n",
       "  'density': 0.3771858215332031,\n",
       "  'sparsity': 0.6228141784667969},\n",
       " 'head.3.bias': {'num_elements': 512,\n",
       "  'kept_elements': 144,\n",
       "  'masked_elements': 368,\n",
       "  'density': 0.28125,\n",
       "  'sparsity': 0.71875},\n",
       " 'head.6.weight': {'num_elements': 262144,\n",
       "  'kept_elements': 102082,\n",
       "  'masked_elements': 160062,\n",
       "  'density': 0.38941192626953125,\n",
       "  'sparsity': 0.6105880737304688},\n",
       " 'head.6.bias': {'num_elements': 512,\n",
       "  'kept_elements': 133,\n",
       "  'masked_elements': 379,\n",
       "  'density': 0.259765625,\n",
       "  'sparsity': 0.740234375},\n",
       " 'head.9.weight': {'num_elements': 51200,\n",
       "  'kept_elements': 26942,\n",
       "  'masked_elements': 24258,\n",
       "  'density': 0.5262109375,\n",
       "  'sparsity': 0.4737890625},\n",
       " 'head.9.bias': {'num_elements': 100,\n",
       "  'kept_elements': 38,\n",
       "  'masked_elements': 62,\n",
       "  'density': 0.38,\n",
       "  'sparsity': 0.62},\n",
       " 'overall': {'total_elements': 773732,\n",
       "  'kept_elements': 260577,\n",
       "  'masked_elements': 513155,\n",
       "  'density': 0.3367794016532856,\n",
       "  'sparsity': 0.6632205983467143}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T18:32:21.344818Z",
     "start_time": "2025-06-03T18:32:20.399034Z"
    }
   },
   "cell_type": "code",
   "source": "compute_mask_stats(centralized_mask_intersection[1])",
   "id": "60fc9108f9d486ef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head.0.weight': {'num_elements': 196608,\n",
       "  'kept_elements': 78,\n",
       "  'masked_elements': 196530,\n",
       "  'density': 0.000396728515625,\n",
       "  'sparsity': 0.999603271484375},\n",
       " 'head.0.bias': {'num_elements': 512,\n",
       "  'kept_elements': 36,\n",
       "  'masked_elements': 476,\n",
       "  'density': 0.0703125,\n",
       "  'sparsity': 0.9296875},\n",
       " 'head.3.weight': {'num_elements': 262144,\n",
       "  'kept_elements': 8769,\n",
       "  'masked_elements': 253375,\n",
       "  'density': 0.033451080322265625,\n",
       "  'sparsity': 0.9665489196777344},\n",
       " 'head.3.bias': {'num_elements': 512,\n",
       "  'kept_elements': 45,\n",
       "  'masked_elements': 467,\n",
       "  'density': 0.087890625,\n",
       "  'sparsity': 0.912109375},\n",
       " 'head.6.weight': {'num_elements': 262144,\n",
       "  'kept_elements': 23378,\n",
       "  'masked_elements': 238766,\n",
       "  'density': 0.08917999267578125,\n",
       "  'sparsity': 0.9108200073242188},\n",
       " 'head.6.bias': {'num_elements': 512,\n",
       "  'kept_elements': 37,\n",
       "  'masked_elements': 475,\n",
       "  'density': 0.072265625,\n",
       "  'sparsity': 0.927734375},\n",
       " 'head.9.weight': {'num_elements': 51200,\n",
       "  'kept_elements': 3853,\n",
       "  'masked_elements': 47347,\n",
       "  'density': 0.07525390625,\n",
       "  'sparsity': 0.92474609375},\n",
       " 'head.9.bias': {'num_elements': 100,\n",
       "  'kept_elements': 0,\n",
       "  'masked_elements': 100,\n",
       "  'density': 0.0,\n",
       "  'sparsity': 1.0},\n",
       " 'overall': {'total_elements': 773732,\n",
       "  'kept_elements': 36196,\n",
       "  'masked_elements': 737536,\n",
       "  'density': 0.04678105597286916,\n",
       "  'sparsity': 0.9532189440271308}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:57:34.871825Z",
     "start_time": "2025-05-15T14:57:34.859935Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "36857bb14d6fe5f1",
   "outputs": [],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
