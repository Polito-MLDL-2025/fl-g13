{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4ad2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed9d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr\n",
    "import torch\n",
    "import dotenv\n",
    "import wandb\n",
    "from itertools import product\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from fl_g13.architectures import BaseDino\n",
    "from fl_g13.editing import SparseSGDM\n",
    "\n",
    "from fl_g13.fl_pytorch import build_fl_dependencies\n",
    "\n",
    "from fl_g13.fl_pytorch.datasets import reset_partition\n",
    "from fl_g13.modeling import load_or_create\n",
    "from fl_g13.editing import SparseSGDM\n",
    "from torch.optim import SGD\n",
    "\n",
    "from fl_g13.fl_pytorch import get_client_app, get_server_app\n",
    "from flwr.simulation import run_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a546bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "build_fl_dependencies()\n",
    "\n",
    "if DEVICE == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
    "else:\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ab994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# login by key in .env file\n",
    "WANDB_API_KEY = dotenv.dotenv_values()[\"WANDB_API_KEY\"]\n",
    "wandb.login(key=WANDB_API_KEY)\n",
    "\n",
    "# Load checkpoint from .env file\n",
    "CHECKPOINT_DIR = dotenv.dotenv_values()[\"CHECKPOINT_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fb2492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model config\n",
    "## Model Hyper-parameters\n",
    "head_layers = 3\n",
    "head_hidden_size = 512\n",
    "dropout_rate = 0.0\n",
    "unfreeze_blocks = 12\n",
    "\n",
    "## Training Hyper-parameters\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-5\n",
    "T_max = 8\n",
    "eta_min = 1e-5\n",
    "\n",
    "# FL config\n",
    "K = 100\n",
    "C = 0.1\n",
    "J = 8\n",
    "num_shards_per_partition = 50 # Nc\n",
    "partition_type = 'shard'\n",
    "\n",
    "num_rounds = 5\n",
    "\n",
    "## Server App config\n",
    "save_every = num_rounds # only save last checkpoint\n",
    "evaluate_each = 1\n",
    "fraction_fit = C        # 0.1\n",
    "fraction_evaluate = C   # 0.1\n",
    "min_fit_clients = 10\n",
    "min_evaluate_clients = 5\n",
    "min_available_clients = 10\n",
    "\n",
    "# model editing config\n",
    "model_editing = True\n",
    "mask_types = ['local', 'global']\n",
    "sparsities = [0.7, 0.8, 0.9]\n",
    "calibration_rounds = [1, 3]\n",
    "model_editing_batch_size = 1\n",
    "mask = None\n",
    "\n",
    "## simulation run config\n",
    "NUM_CLIENTS = 100\n",
    "MAX_PARALLEL_CLIENTS = 10\n",
    "\n",
    "## Base model location\n",
    "# The 200-epoch model folder\n",
    "# Ensure that the most recent file is the correct one\n",
    "model_save_path = CHECKPOINT_DIR + f\"/fl/non-iid/{num_shards_per_partition}_{J}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6933e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulations\n",
    "for m_calibration_rounds, m_type, m_sparsity in product(calibration_rounds, mask_types, sparsities):\n",
    "    reset_partition()\n",
    "    \n",
    "    print('-' * 200)\n",
    "    print(f\" Nc={num_shards_per_partition}, J={J}, mask_type={m_type}, sparsity={m_sparsity}, mask_calibration_round={m_calibration_rounds}\\n\")\n",
    "    \n",
    "    model_checkpoint = CHECKPOINT_DIR + f\"/fl/non-iid/GS/{num_shards_per_partition}_{J}_{m_type}_{m_sparsity}_{m_calibration_rounds}\"\n",
    "    \n",
    "    # Load Base model\n",
    "    model, start_epoch = load_or_create(\n",
    "        path=model_save_path,\n",
    "        model_class=BaseDino,\n",
    "        model_config=None,\n",
    "        optimizer=None,\n",
    "        scheduler=None,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    if model_editing:\n",
    "        # Create a dummy mask for SparseSGDM\n",
    "        dummy_mask = [torch.ones_like(p, device=p.device) for p in model.parameters()]\n",
    "        \n",
    "        optimizer = SparseSGDM(\n",
    "            model.parameters(),\n",
    "            mask=dummy_mask,\n",
    "            lr=lr,\n",
    "            momentum=momentum,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "    else:\n",
    "        optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "        \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    scheduler = CosineAnnealingLR(\n",
    "        optimizer=optimizer,\n",
    "        T_max=T_max,\n",
    "        eta_min=eta_min\n",
    "    )\n",
    "    \n",
    "    # Unfreeze entire model for model_editing\n",
    "    model.unfreeze_blocks(unfreeze_blocks)\n",
    "\n",
    "    # Wandb settings\n",
    "    use_wandb = False\n",
    "    run_name = f\"fl_gs_{num_shards_per_partition}_{J}_{m_type}_{m_sparsity}_{m_calibration_rounds}\"\n",
    "    wandb_config = {\n",
    "        # wandb param\n",
    "        'name': run_name,\n",
    "        'project_name': f\"fl_v5_{num_shards_per_partition}_{J}_grid_search\",\n",
    "        'run_id': run_name,\n",
    "        \n",
    "        # fl config\n",
    "        \"fraction_fit\": fraction_fit,\n",
    "        \"lr\": lr,\n",
    "        \"momentum\": momentum,\n",
    "        'weight_decay': weight_decay,\n",
    "        'partition_type': partition_type,\n",
    "        'K': K,\n",
    "        'C': C,\n",
    "        'J': J,\n",
    "        'Nc': num_shards_per_partition,\n",
    "        \n",
    "        # model config\n",
    "        'head_layers': head_layers,\n",
    "        'head_hidden_size': head_hidden_size,\n",
    "        'dropout_rate': dropout_rate,\n",
    "        'unfreeze_blocks': unfreeze_blocks,\n",
    "        \n",
    "        # model editing config\n",
    "        'model_editing_batch_size': model_editing_batch_size,\n",
    "        'mask_calibration_round': m_calibration_rounds,\n",
    "        'mask_type': m_type,\n",
    "        'sparsity': m_sparsity\n",
    "    }\n",
    "\n",
    "    client = get_client_app(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=DEVICE,\n",
    "        partition_type=partition_type,\n",
    "        local_epochs=1,\n",
    "        local_steps=J,\n",
    "        batch_size=batch_size,\n",
    "        num_shards_per_partition=num_shards_per_partition,\n",
    "        scheduler=scheduler,\n",
    "        model_editing=model_editing,\n",
    "        mask_type=m_type,\n",
    "        sparsity=m_sparsity,\n",
    "        mask=mask,\n",
    "        model_editing_batch_size=model_editing_batch_size,\n",
    "        mask_func=None,\n",
    "        mask_calibration_round=m_calibration_rounds\n",
    "    )\n",
    "    \n",
    "    server = get_server_app(\n",
    "        checkpoint_dir=model_checkpoint,\n",
    "        model_class=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        scheduler=scheduler,\n",
    "        num_rounds=num_rounds,\n",
    "        fraction_fit=fraction_fit,\n",
    "        fraction_evaluate=fraction_evaluate,\n",
    "        min_fit_clients=min_fit_clients,\n",
    "        min_evaluate_clients=min_evaluate_clients,\n",
    "        min_available_clients=min_available_clients,\n",
    "        device=DEVICE,\n",
    "        use_wandb=use_wandb,\n",
    "        wandb_config=wandb_config,\n",
    "        save_every=save_every,\n",
    "        prefix='grid_search',\n",
    "        evaluate_each=evaluate_each,\n",
    "        model= model,\n",
    "        start_epoch= start_epoch\n",
    "    )\n",
    "    \n",
    "    # Run simulation\n",
    "    run_simulation(\n",
    "        server_app=server,\n",
    "        client_app=client,\n",
    "        num_supernodes=NUM_CLIENTS,\n",
    "        backend_config=backend_config\n",
    "    )\n",
    "\n",
    "    if use_wandb:\n",
    "        wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
