{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T19:42:42.133497Z",
     "start_time": "2025-06-27T19:42:42.010356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "5767f6b1a63e945b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T19:42:55.738403Z",
     "start_time": "2025-06-27T19:42:42.291808Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "import urllib.request\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from flwr.simulation import run_simulation\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from fl_g13.architectures import BaseDino\n",
    "from fl_g13.editing import SparseSGDM\n",
    "from fl_g13.fl_pytorch.client_app import get_client_app\n",
    "from fl_g13.fl_pytorch.datasets import reset_partition\n",
    "from fl_g13.fl_pytorch.server_app import get_server_app\n",
    "from fl_g13.modeling import load_or_create"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-06-27 21:42:46.899\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mfl_g13.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Login wandb",
   "id": "73fb84b164b0def7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T19:24:02.233143Z",
     "start_time": "2025-06-27T19:23:58.656769Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install wandb --quiet",
   "id": "6c6449ef9be1e422",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T19:24:03.162525Z",
     "start_time": "2025-06-27T19:24:02.235142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## read .env file\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n"
   ],
   "id": "5f279490dd7a970f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T19:24:05.118729Z",
     "start_time": "2025-06-27T19:24:03.164425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "# login by key in .env file\n",
    "WANDB_API_KEY = dotenv.dotenv_values()[\"WANDB_API_KEY\"]\n",
    "# WANDB_API_KEY = 'd8a0d7bc0ada694ba9c7f26bd159620f0326a74f'\n",
    "wandb.login(key=WANDB_API_KEY)"
   ],
   "id": "a218d880822fdfba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\notebook\\utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  return LooseVersion(v) >= LooseVersion(check)\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\ADMIN\\_netrc\n",
      "wandb: Currently logged in as: thanhnv-it23 (stefano-gamba-social-politecnico-di-torino) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build module local\n",
    "\n",
    "Build module local such that ClientApp can use it"
   ],
   "id": "b5a0319c8e40215a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T19:24:15.233626Z",
     "start_time": "2025-06-27T19:24:05.121142Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -e .. --quiet",
   "id": "8a11402a3317027f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Download missing module for clients\n",
    "\n",
    "Dino model,that is serialized and sent to client by server, require some modules that have to download from source code of dino model\n"
   ],
   "id": "9399f1a9cedc8cc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T20:50:45.820861Z",
     "start_time": "2025-06-03T20:50:44.881897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def download_if_not_exists(file_path: str, file_url: str):\n",
    "    \"\"\"\n",
    "    Checks if a file exists at the given path. If it does not, downloads it from the specified URL.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The local path to check and save the file.\n",
    "    - file_url (str): The URL from which to download the file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"'{file_path}' not found. Downloading from {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "            print(\"Download complete.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download file: {e}\")\n",
    "    else:\n",
    "        print(f\"'{file_path}' already exists.\")"
   ],
   "id": "beb2c855fcd8933c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T20:50:46.816413Z",
     "start_time": "2025-06-03T20:50:45.822862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "download_if_not_exists(\"vision_transformer.py\",\n",
    "                       \"https://raw.githubusercontent.com/facebookresearch/dino/refs/heads/main/vision_transformer.py\")\n",
    "download_if_not_exists(\"utils.py\",\n",
    "                       \"https://raw.githubusercontent.com/facebookresearch/dino/refs/heads/main/utils.py\")\n"
   ],
   "id": "d93caca63a33c71f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'vision_transformer.py' already exists.\n",
      "'utils.py' already exists.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FL",
   "id": "ee82432353abfbe2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configs",
   "id": "cdb05316b163821b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T19:42:56.524363Z",
     "start_time": "2025-06-27T19:42:55.740582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ----------------------------------------\n",
    "# Device Setup\n",
    "# ----------------------------------------\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Client Resource Configuration\n",
    "# ----------------------------------------\n",
    "backend_config = {\n",
    "    \"client_resources\": {\n",
    "        \"num_cpus\": 1,\n",
    "        \"num_gpus\": 1 if DEVICE == \"cuda\" else 0.0\n",
    "    }\n",
    "}\n",
    "\n",
    "# ----------------------------------------\n",
    "# Experiment Metadata\n",
    "# ----------------------------------------\n",
    "project_name = \"FL_Dino_CIFAR100_masking_grid_search_v4\"\n",
    "partition_type = 'shard'  # 'iid' or 'shard'\n",
    "partition_name = 'iid' if partition_type == 'iid' else 'non-iid'\n",
    "model_editing = True\n",
    "use_wandb = True\n",
    "\n",
    "# ----------------------------------------\n",
    "# Paths and Checkpoints\n",
    "# ----------------------------------------\n",
    "previous_model_path = '../models/fl_baseline/fl_baseline_model/fl_fl_baseline_BaseDino_epoch_200_noniid_1_8.pth'\n",
    "current_path = Path.cwd()\n",
    "model_save_path = current_path / \"../models/fl_dino_v4/non_iid\"\n",
    "\n",
    "# ----------------------------------------\n",
    "# Global Experiment Settings\n",
    "# ----------------------------------------\n",
    "K = 100  # Total clients\n",
    "C = 0.1  # Client sampling fraction\n",
    "NUM_CLIENTS = K\n",
    "num_rounds = 55\n",
    "evaluate_each = 2\n",
    "\n",
    "# Evaluation thresholds\n",
    "fraction_fit = C\n",
    "fraction_evaluate = 0.1\n",
    "min_fit_clients = 10\n",
    "min_evaluate_clients = 5\n",
    "min_available_clients = 10\n",
    "\n",
    "# ----------------------------------------\n",
    "# Model & Training Hyperparameters\n",
    "# ----------------------------------------\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-5\n",
    "T_max = 8\n",
    "eta_min = 1e-5\n",
    "save_every = 5\n",
    "num_blocks = 12\n",
    "device = DEVICE\n",
    "\n",
    "model_config = {\n",
    "    \"head_layers\": 3,\n",
    "    \"head_hidden_size\": 512,\n",
    "    \"dropout_rate\": 0.0,\n",
    "    \"unfreeze_blocks\": 0\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# Main Experiment Loop\n",
    "# --------------------------\n",
    "Js = [8]\n",
    "Ncs = [1, 5, 10, 50]\n",
    "mask_calibration_round_s = [1]  # E.g. [1, 3]\n",
    "mask_types = ['local']  # E.g. ['global', 'local']\n",
    "sparsitys = [0.8, 0.7]\n",
    "model_editing_batch_size = 1\n",
    "mask = None  # Default mask placeholder\n",
    "\n",
    "# ----------------------------------------\n",
    "# Grid Search Execution Loop\n",
    "# ---------------------------------------"
   ],
   "id": "d63bb533ec30809b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run the training\n",
   "id": "1427a966f7544b94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9a1db478a3e1221"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-27T19:42:59.836434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for J, Nc, mask_calibration_round, mask_type, sparsity in product(Js, Ncs, mask_calibration_round_s, mask_types,\n",
    "                                                                  sparsitys):\n",
    "    reset_partition()\n",
    "    print('-' * 100)\n",
    "    print(\n",
    "        f\"Training configuration: J={J}, Nc={Nc}, mask_round={mask_calibration_round}, type={mask_type}, sparsity={sparsity}\")\n",
    "\n",
    "    checkpoint_dir = f\"{model_save_path}/{Nc}_{J}_{mask_type}_{mask_calibration_round}_{sparsity}\"\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    # Load or create model\n",
    "    model, start_epoch = load_or_create(\n",
    "        path=previous_model_path,\n",
    "        model_class=BaseDino,\n",
    "        model_config=model_config,\n",
    "        optimizer=None,\n",
    "        scheduler=None,\n",
    "        device=DEVICE,\n",
    "        verbose=True\n",
    "    )\n",
    "    model.to(DEVICE)\n",
    "    model.unfreeze_blocks(num_blocks)\n",
    "\n",
    "    # Set up optimizer and scheduler\n",
    "    if model_editing:\n",
    "        init_mask = [torch.ones_like(p, device=p.device) for p in model.parameters()]\n",
    "        optimizer = SparseSGDM(\n",
    "            model.parameters(),\n",
    "            mask=init_mask,\n",
    "            lr=lr,\n",
    "            momentum=momentum,\n",
    "            weight_decay=weight_decay\n",
    "        )\n",
    "    else:\n",
    "        optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=T_max, eta_min=eta_min)\n",
    "    criterion = CrossEntropyLoss()\n",
    "\n",
    "    # Construct WandB run config\n",
    "    run_name = f\"FL_Dino_Baseline_model_{partition_name}_{J}_{mask_type}_{mask_calibration_round}_{sparsity}\"\n",
    "    wandb_config = {\n",
    "        'name': run_name,\n",
    "        'project_name': project_name,\n",
    "        'run_id': run_name,\n",
    "        'fraction_fit': fraction_fit,\n",
    "        'lr': lr,\n",
    "        'momentum': momentum,\n",
    "        'weight_decay': weight_decay,\n",
    "        'partition_type': partition_type,\n",
    "        'K': K,\n",
    "        'C': C,\n",
    "        'J': J,\n",
    "        'Nc': Nc,\n",
    "        'mask_calibration_round': mask_calibration_round,\n",
    "        'mask_type': mask_type,\n",
    "        'sparsity': sparsity,\n",
    "        'T_max': T_max,\n",
    "        'eta_min': eta_min,\n",
    "        'unfreeze_blocks': num_blocks\n",
    "    }\n",
    "\n",
    "    # Client Setup\n",
    "    client = get_client_app(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=DEVICE,\n",
    "        partition_type=partition_type,\n",
    "        local_epochs=1,\n",
    "        local_steps=J,\n",
    "        batch_size=batch_size,\n",
    "        num_shards_per_partition=Nc,\n",
    "        scheduler=scheduler,\n",
    "        verbose=0,\n",
    "        model_editing=model_editing,\n",
    "        mask_type=mask_type,\n",
    "        sparsity=sparsity,\n",
    "        mask=mask,\n",
    "        model_editing_batch_size=model_editing_batch_size,\n",
    "        mask_func=None,\n",
    "        mask_calibration_round=mask_calibration_round\n",
    "    )\n",
    "\n",
    "    # Server Setup\n",
    "    compute_rounds = num_rounds + 1 - start_epoch\n",
    "    server = get_server_app(\n",
    "        checkpoint_dir=checkpoint_dir,\n",
    "        model_class=model,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        scheduler=scheduler,\n",
    "        num_rounds=compute_rounds,\n",
    "        fraction_fit=fraction_fit,\n",
    "        fraction_evaluate=fraction_evaluate,\n",
    "        min_fit_clients=min_fit_clients,\n",
    "        min_evaluate_clients=min_evaluate_clients,\n",
    "        min_available_clients=min_available_clients,\n",
    "        device=DEVICE,\n",
    "        use_wandb=use_wandb,\n",
    "        wandb_config=wandb_config,\n",
    "        save_every=save_every,\n",
    "        prefix='fl_baseline',\n",
    "        evaluate_each=evaluate_each,\n",
    "        model=model,\n",
    "        start_epoch=start_epoch\n",
    "    )\n",
    "\n",
    "    # Run Simulation\n",
    "    run_simulation(\n",
    "        server_app=server,\n",
    "        client_app=client,\n",
    "        num_supernodes=NUM_CLIENTS,\n",
    "        backend_config=backend_config\n",
    "    )\n",
    "\n",
    "    wandb.finish()"
   ],
   "id": "1451e826d4713ec9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Training configuration: J=8, Nc=1, mask_round=1, type=local, sparsity=0.8\n",
      "🔍 Loading checkpoint from ../models/fl_baseline/fl_baseline_model/fl_fl_baseline_BaseDino_epoch_200_noniid_1_8.pth\n",
      "📦 Model class in checkpoint: BaseDino\n",
      "🔧 Model configuration: {'variant': 'dino_vits16', 'dropout_rate': 0.0, 'head_hidden_size': 512, 'head_layers': 3, 'num_classes': 100, 'unfreeze_blocks': 0, 'activation_fn': 'GELU', 'pretrained': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n",
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️ Moved model to device: cuda\n",
      "✅ Loaded checkpoint from ../models/fl_baseline/fl_baseline_model/fl_fl_baseline_BaseDino_epoch_200_noniid_1_8.pth, resuming at epoch 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      Starting Flower ServerApp, config: num_rounds=-145, no round_timeout\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [INIT]\n",
      "\u001B[92mINFO \u001B[0m:      Using initial global parameters provided by strategy\n",
      "\u001B[92mINFO \u001B[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using strategy 'CustomFedAvg' (default option)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:  29%|██▉       | 91/313 [00:13<00:26,  8.48batch/s]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "39ae4073863566bd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
