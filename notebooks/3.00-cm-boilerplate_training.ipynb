{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JlrgkvwTt0n"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn64tJDBPe0g"
      },
      "outputs": [],
      "source": [
        "from fl_g13.config import RAW_DATA_DIR\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from fl_g13.modeling import train, train_one_epoch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myBP16BjQ5LY"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbOYONBtQ4Fb",
        "outputId": "593ba79f-5226-4f3f-e1bd-d41c2edcb813"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "cifar100_train = datasets.CIFAR100(root=RAW_DATA_DIR, train=True, download=True, transform=transform)\n",
        "cifar100_test = datasets.CIFAR100(root=RAW_DATA_DIR, train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAa_Qx6VQnR4"
      },
      "source": [
        "### Train and save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TinyCNN(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(TinyCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))     # -> [B, 16, 32, 32]\n",
        "        x = F.max_pool2d(x, 2)        # -> [B, 16, 16, 16]\n",
        "        x = F.relu(self.conv2(x))     # -> [B, 32, 16, 16]\n",
        "        x = F.max_pool2d(x, 2)        # -> [B, 32, 8, 8]\n",
        "        x = x.view(x.size(0), -1)     # -> [B, 32*8*8]\n",
        "        x = self.fc1(x)               # -> [B, 100]\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vBLzL_iQEQq"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = \"/home/massimiliano/Projects/fl-g13/checkpoints\"\n",
        "\n",
        "# Parameters\n",
        "batch_size  = 32\n",
        "start_epoch = 1\n",
        "num_epochs  = 2\n",
        "save_every  = 1\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(cifar100_train, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = torch.utils.data.DataLoader(cifar100_test, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model = TinyCNN(100)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.04)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr6KJ-inSYkn",
        "outputId": "fae74572-4196-4bd9-da19-b0d483eb9165"
      },
      "outputs": [],
      "source": [
        "train(checkpoint_dir, train_dataloader, loss_fn, start_epoch, num_epochs, save_every, model, optimizer, scheduler=None, prefix=None, verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train(checkpoint_dir, train_dataloader, loss_fn, start_epoch, num_epochs, save_every, model, optimizer, scheduler=None, prefix=\"TinyCNN\", verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DjHHflVSyZZ"
      },
      "source": [
        "**Resume training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fl_g13.modeling import load\n",
        "\n",
        "# Load the model from the latest checkpoint\n",
        "model2 = TinyCNN(num_classes=100)\n",
        "optimizer2 = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.04)\n",
        "loss_fn2 = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "start_epoch = load(checkpoint_dir, model=model2, optimizer=optimizer2, filename=\"TinyCNN_epoch_3.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QClLYHcSrIS"
      },
      "outputs": [],
      "source": [
        "num_epochs = 4\n",
        "save_every = 2\n",
        "\n",
        "train(checkpoint_dir, train_dataloader, loss_fn2, start_epoch, num_epochs, save_every, model2, optimizer2, scheduler=None, prefix=\"TinyCNN\", verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fl-g13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
