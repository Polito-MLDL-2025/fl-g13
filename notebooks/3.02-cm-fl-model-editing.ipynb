{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d326f5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f626291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:24:24.400308Z",
     "start_time": "2025-05-03T07:24:14.251033Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-20 19:03:49.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfl_g13.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: /home/massimiliano/Projects/fl-g13\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flower 1.17.0 / PyTorch 2.6.0+cu124\n",
      "'vision_transformer.py' already exists.\n",
      "'utils.py' already exists.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fl_g13.editing.sparseSGDM import SparseSGDM\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import flwr\n",
    "from flwr.simulation import run_simulation\n",
    "from fl_g13.architectures import BaseDino\n",
    "from fl_g13.fl_pytorch import get_client_app, get_server_app\n",
    "from fl_g13.fl_pytorch import build_fl_dependencies\n",
    "from fl_g13.fl_pytorch import FullyCentralizedMaskedFedAvg, CustomFedAvg\n",
    "\n",
    "\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "\n",
    "build_fl_dependencies() #! Remind to always put this, it will download Dino dependencies for client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e9d3ca8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:24:24.415306Z",
     "start_time": "2025-05-03T07:24:24.401288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint saving settings\n",
    "CHECKPOINT_DIR = \"/home/massimiliano/Projects/fl-g13/checkpoints\"\n",
    "name = 'aron'\n",
    "save_with_model_dir = False\n",
    "save_every = 1\n",
    "\n",
    "# Model hyper-parameters\n",
    "head_layers=3\n",
    "head_hidden_size=512\n",
    "dropout_rate=0.0\n",
    "unfreeze_blocks=1\n",
    "\n",
    "# Training hyper-parameters\n",
    "starting_lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay=1e-5\n",
    "T_max=8\n",
    "eta_min=1e-5\n",
    "\n",
    "# Federated Training settings\n",
    "batch_size = 64 # Batch size for training #! Let's stick to 64 to make training fit also on RTX 3070\n",
    "local_epochs = 1 # Number of local epochs per client\n",
    "number_of_rounds = 5 # Total number of federated learning rounds\n",
    "fraction_fit = 1 # Fraction of clients participating in training per round\n",
    "fraction_evaluate = 0.1 # Fraction of clients participating in evaluation per round\n",
    "number_of_clients = 2 # Total number of clients in the simulation\n",
    "min_num_clients = 2 # Minimum number of clients required for training and evaluation\n",
    "partition_type = \"iid\" # Partitioning strategy for the dataset (e.g., \"iid\" or \"shard\")\n",
    "num_shards_per_partition = 6 # Number of shards per partition (used when partition_type is \"shard\")\n",
    "use_wandb = False # Whether to use Weights & Biases (wandb) for experiment tracking\n",
    "wandb_config = None\n",
    "\n",
    "# Device settings\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "backend_config = {\n",
    "    \"client_resources\": {\n",
    "        \"num_cpus\": 1, \n",
    "        \"num_gpus\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "# Refer to Flower framework documentation for more details about Flower simulations\n",
    "# and how to set up the `backend_config`\n",
    "if device == \"cuda\":\n",
    "    backend_config[\"client_resources\"] = {\n",
    "        \"num_cpus\": 1, \n",
    "        \"num_gpus\": 1\n",
    "    }\n",
    "\n",
    "print(f\"Training on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aebfcdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-03T07:24:34.527814Z",
     "start_time": "2025-05-03T07:24:32.944367Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/massimiliano/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No checkpoint found at /home/massimiliano/Projects/fl-g13/checkpoints. Creating a new model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/massimiliano/.cache/torch/hub/facebookresearch_dino_main\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "model = BaseDino(\n",
    "    head_layers=head_layers, \n",
    "    head_hidden_size=head_hidden_size, \n",
    "    dropout_rate=dropout_rate, \n",
    "    unfreeze_blocks=unfreeze_blocks\n",
    "    )\n",
    "model.to(device)\n",
    "\n",
    "mask = [torch.ones_like(p, device=p.device) for p in model.parameters()] # Must be done AFTER the model is moved to CUDA\n",
    "optimizer = SparseSGDM(\n",
    "    params=model.parameters(),\n",
    "    mask=mask,\n",
    "    lr=starting_lr,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay\n",
    "    )\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer=optimizer, \n",
    "    T_max=T_max, \n",
    "    eta_min=eta_min\n",
    "    )\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "client_app = get_client_app(\n",
    "    model=model, \n",
    "    criterion=criterion, \n",
    "    optimizer=optimizer, \n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    strategy='standard',\n",
    "    partition_type=partition_type, \n",
    "    batch_size=batch_size,\n",
    "    num_shards_per_partition=num_shards_per_partition,\n",
    "    local_epochs=local_epochs,\n",
    "    model_editing=True,\n",
    "    mask_type= 'global',\n",
    "    sparsity = 0.1,\n",
    ")\n",
    "\n",
    "server_app = get_server_app(\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    "    prefix=name,\n",
    "    model_class=model.__class__,\n",
    "    model_config=model.get_config(), \n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    device=device, \n",
    "    save_every=save_every,\n",
    "    save_with_model_dir=save_with_model_dir,\n",
    "    strategy='standard',\n",
    "    num_rounds=number_of_rounds, \n",
    "    fraction_fit=fraction_fit,\n",
    "    fraction_evaluate=fraction_evaluate,\n",
    "    min_fit_clients=min_num_clients,\n",
    "    min_evaluate_clients=min_num_clients,\n",
    "    min_available_clients=number_of_clients,\n",
    "    use_wandb=use_wandb,\n",
    "    wandb_config=wandb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cac28",
   "metadata": {},
   "source": [
    "### Pre-train the model (head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ecad4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Server on device: cuda:0\n",
      "[Server] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=5, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using strategy 'CustomFedAvg' (default option)\n",
      "[Server Eval Round 0] Model device: cuda:0\n",
      "[Server Eval Round 0] CUDA available in server eval: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 313/313 [00:23<00:00, 13.45batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 0] Centralized Evaluation - Loss: 7.0210, Metrics: {'centralized_accuracy': 0.0108}\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 7.020998756725567, {'centralized_accuracy': 0.0108}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
      "\u001b[36m(ClientAppActor pid=80987)\u001b[0m 2025-05-20 19:04:18.224 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: /home/massimiliano/Projects/fl-g13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=80987)\u001b[0m [Client] Client on device: cuda:0\n",
      "\u001b[36m(ClientAppActor pid=80987)\u001b[0m [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/79 [00:00<?, ?batch/s]\n",
      "Fisher Score:   1%|▏         | 1/79 [00:00<00:23,  3.29batch/s]\n",
      "Fisher Score:   4%|▍         | 3/79 [00:00<00:11,  6.57batch/s]\n",
      "Fisher Score:   5%|▌         | 4/79 [00:00<00:10,  7.09batch/s]\n",
      "Fisher Score:   6%|▋         | 5/79 [00:00<00:09,  7.43batch/s]\n",
      "Fisher Score:   8%|▊         | 6/79 [00:00<00:09,  7.72batch/s]\n",
      "Fisher Score:   9%|▉         | 7/79 [00:00<00:09,  7.90batch/s]\n",
      "Fisher Score:  10%|█         | 8/79 [00:01<00:08,  8.01batch/s]\n",
      "Fisher Score:  11%|█▏        | 9/79 [00:01<00:08,  8.14batch/s]\n",
      "Fisher Score:  13%|█▎        | 10/79 [00:01<00:08,  8.20batch/s]\n",
      "Fisher Score:  14%|█▍        | 11/79 [00:01<00:08,  8.24batch/s]\n",
      "Fisher Score:  15%|█▌        | 12/79 [00:01<00:08,  8.26batch/s]\n",
      "Fisher Score:  16%|█▋        | 13/79 [00:01<00:07,  8.28batch/s]\n",
      "Fisher Score:  18%|█▊        | 14/79 [00:01<00:07,  8.30batch/s]\n",
      "Fisher Score:  19%|█▉        | 15/79 [00:01<00:07,  8.30batch/s]\n",
      "Fisher Score:  20%|██        | 16/79 [00:02<00:07,  8.30batch/s]\n",
      "Fisher Score:  22%|██▏       | 17/79 [00:02<00:07,  8.32batch/s]\n",
      "Fisher Score:  23%|██▎       | 18/79 [00:02<00:07,  8.36batch/s]\n",
      "Fisher Score:  24%|██▍       | 19/79 [00:02<00:07,  8.37batch/s]\n",
      "Fisher Score:  25%|██▌       | 20/79 [00:02<00:07,  8.36batch/s]\n",
      "Fisher Score:  27%|██▋       | 21/79 [00:02<00:06,  8.36batch/s]\n",
      "Fisher Score:  28%|██▊       | 22/79 [00:02<00:06,  8.37batch/s]\n",
      "Fisher Score:  29%|██▉       | 23/79 [00:02<00:06,  8.35batch/s]\n",
      "Fisher Score:  30%|███       | 24/79 [00:03<00:06,  8.35batch/s]\n",
      "Fisher Score:  32%|███▏      | 25/79 [00:03<00:06,  8.35batch/s]\n",
      "Fisher Score:  33%|███▎      | 26/79 [00:03<00:06,  8.36batch/s]\n",
      "Fisher Score:  34%|███▍      | 27/79 [00:03<00:06,  8.37batch/s]\n",
      "Fisher Score:  35%|███▌      | 28/79 [00:03<00:06,  8.39batch/s]\n",
      "Fisher Score:  37%|███▋      | 29/79 [00:03<00:05,  8.38batch/s]\n",
      "Fisher Score:  38%|███▊      | 30/79 [00:03<00:05,  8.40batch/s]\n",
      "Fisher Score:  39%|███▉      | 31/79 [00:03<00:05,  8.40batch/s]\n",
      "Fisher Score:  41%|████      | 32/79 [00:03<00:05,  8.38batch/s]\n",
      "Fisher Score:  42%|████▏     | 33/79 [00:04<00:05,  8.38batch/s]\n",
      "Fisher Score:  43%|████▎     | 34/79 [00:04<00:05,  8.36batch/s]\n",
      "Fisher Score:  44%|████▍     | 35/79 [00:04<00:05,  8.37batch/s]\n",
      "Fisher Score:  46%|████▌     | 36/79 [00:04<00:05,  8.37batch/s]\n",
      "Fisher Score:  47%|████▋     | 37/79 [00:04<00:05,  8.37batch/s]\n",
      "Fisher Score:  48%|████▊     | 38/79 [00:04<00:04,  8.37batch/s]\n",
      "Fisher Score:  49%|████▉     | 39/79 [00:04<00:04,  8.36batch/s]\n",
      "Fisher Score:  51%|█████     | 40/79 [00:04<00:04,  8.35batch/s]\n",
      "Fisher Score:  52%|█████▏    | 41/79 [00:05<00:04,  8.35batch/s]\n",
      "Fisher Score:  53%|█████▎    | 42/79 [00:05<00:04,  8.35batch/s]\n",
      "Fisher Score:  54%|█████▍    | 43/79 [00:05<00:04,  8.35batch/s]\n",
      "Fisher Score:  56%|█████▌    | 44/79 [00:05<00:04,  8.35batch/s]\n",
      "Fisher Score:  57%|█████▋    | 45/79 [00:05<00:04,  8.36batch/s]\n",
      "Fisher Score:  58%|█████▊    | 46/79 [00:05<00:03,  8.34batch/s]\n",
      "Fisher Score:  59%|█████▉    | 47/79 [00:05<00:03,  8.36batch/s]\n",
      "Fisher Score:  61%|██████    | 48/79 [00:05<00:03,  8.36batch/s]\n",
      "Fisher Score:  62%|██████▏   | 49/79 [00:06<00:03,  8.35batch/s]\n",
      "Fisher Score:  63%|██████▎   | 50/79 [00:06<00:03,  8.34batch/s]\n",
      "Fisher Score:  65%|██████▍   | 51/79 [00:06<00:03,  8.35batch/s]\n",
      "Fisher Score:  66%|██████▌   | 52/79 [00:06<00:03,  8.36batch/s]\n",
      "Fisher Score:  67%|██████▋   | 53/79 [00:06<00:03,  8.35batch/s]\n",
      "Fisher Score:  68%|██████▊   | 54/79 [00:06<00:02,  8.36batch/s]\n",
      "Fisher Score:  70%|██████▉   | 55/79 [00:06<00:02,  8.35batch/s]\n",
      "Fisher Score:  71%|███████   | 56/79 [00:06<00:02,  8.35batch/s]\n",
      "Fisher Score:  72%|███████▏  | 57/79 [00:06<00:02,  8.34batch/s]\n",
      "Fisher Score:  73%|███████▎  | 58/79 [00:07<00:02,  8.37batch/s]\n",
      "Fisher Score:  75%|███████▍  | 59/79 [00:07<00:02,  8.37batch/s]\n",
      "Fisher Score:  76%|███████▌  | 60/79 [00:07<00:02,  8.37batch/s]\n",
      "Fisher Score:  77%|███████▋  | 61/79 [00:07<00:02,  8.37batch/s]\n",
      "Fisher Score:  78%|███████▊  | 62/79 [00:07<00:02,  8.37batch/s]\n",
      "Fisher Score:  80%|███████▉  | 63/79 [00:07<00:01,  8.35batch/s]\n",
      "Fisher Score:  81%|████████  | 64/79 [00:07<00:01,  8.35batch/s]\n",
      "Fisher Score:  82%|████████▏ | 65/79 [00:07<00:01,  8.35batch/s]\n",
      "Fisher Score:  84%|████████▎ | 66/79 [00:08<00:01,  8.36batch/s]\n",
      "Fisher Score:  85%|████████▍ | 67/79 [00:08<00:01,  8.35batch/s]\n",
      "Fisher Score:  86%|████████▌ | 68/79 [00:08<00:01,  8.37batch/s]\n",
      "Fisher Score:  87%|████████▋ | 69/79 [00:08<00:01,  8.37batch/s]\n",
      "Fisher Score:  89%|████████▊ | 70/79 [00:08<00:01,  8.35batch/s]\n",
      "Fisher Score:  90%|████████▉ | 71/79 [00:08<00:00,  8.34batch/s]\n",
      "Fisher Score:  91%|█████████ | 72/79 [00:08<00:00,  8.36batch/s]\n",
      "Fisher Score:  92%|█████████▏| 73/79 [00:08<00:00,  8.36batch/s]\n",
      "Fisher Score:  94%|█████████▎| 74/79 [00:08<00:00,  8.35batch/s]\n",
      "Fisher Score:  95%|█████████▍| 75/79 [00:09<00:00,  8.37batch/s]\n",
      "Fisher Score:  96%|█████████▌| 76/79 [00:09<00:00,  8.37batch/s]\n",
      "Fisher Score:  97%|█████████▋| 77/79 [00:09<00:00,  8.37batch/s]\n",
      "Fisher Score:  99%|█████████▊| 78/79 [00:09<00:00,  8.37batch/s]\n",
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=80987, ip=192.168.1.119, actor_id=580836d74913c89821ed116a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7271f0271950>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/client_app.py\", line 144, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/client_app.py\", line 128, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client_app.py\", line 75, in client_fn\n",
      "    return CustomNumpyClient(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client.py\", line 62, in __init__\n",
      "    self._compute_mask(sparsity=sparsity, mask_type=mask_type)\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client.py\", line 73, in _compute_mask\n",
      "    mask = create_mask(class_score=scores, sparsity=sparsity, mask_type=mask_type)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: create_mask() got an unexpected keyword argument 'class_score'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=80987, ip=192.168.1.119, actor_id=580836d74913c89821ed116a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7271f0271950>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: create_mask() got an unexpected keyword argument 'class_score'\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
      "    raise ex\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/ray/_private/worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=80987, ip=192.168.1.119, actor_id=580836d74913c89821ed116a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7271f0271950>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/client_app.py\", line 144, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/client_app.py\", line 128, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client_app.py\", line 75, in client_fn\n",
      "    return CustomNumpyClient(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client.py\", line 62, in __init__\n",
      "    self._compute_mask(sparsity=sparsity, mask_type=mask_type)\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client.py\", line 73, in _compute_mask\n",
      "    mask = create_mask(class_score=scores, sparsity=sparsity, mask_type=mask_type)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: create_mask() got an unexpected keyword argument 'class_score'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=80987, ip=192.168.1.119, actor_id=580836d74913c89821ed116a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7271f0271950>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: create_mask() got an unexpected keyword argument 'class_score'\n",
      "\n",
      "Fisher Score: 100%|██████████| 79/79 [00:09<00:00,  8.22batch/s]\n",
      "Fisher Score:   0%|          | 0/79 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=80987)\u001b[0m [Client] Client on device: cuda:0\n",
      "\u001b[36m(ClientAppActor pid=80987)\u001b[0m [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   3%|▎         | 2/79 [00:00<00:06, 11.62batch/s]\n",
      "Fisher Score:   5%|▌         | 4/79 [00:00<00:07,  9.43batch/s]\n",
      "Fisher Score:   6%|▋         | 5/79 [00:00<00:08,  9.09batch/s]\n",
      "Fisher Score:   8%|▊         | 6/79 [00:00<00:08,  8.88batch/s]\n",
      "Fisher Score:   9%|▉         | 7/79 [00:00<00:08,  8.71batch/s]\n",
      "Fisher Score:  10%|█         | 8/79 [00:00<00:08,  8.61batch/s]\n",
      "Fisher Score:  11%|█▏        | 9/79 [00:01<00:08,  8.51batch/s]\n",
      "Fisher Score:  13%|█▎        | 10/79 [00:01<00:08,  8.46batch/s]\n",
      "Fisher Score:  14%|█▍        | 11/79 [00:01<00:08,  8.43batch/s]\n",
      "Fisher Score:  15%|█▌        | 12/79 [00:01<00:07,  8.42batch/s]\n",
      "Fisher Score:  16%|█▋        | 13/79 [00:01<00:07,  8.40batch/s]\n",
      "Fisher Score:  18%|█▊        | 14/79 [00:01<00:07,  8.39batch/s]\n",
      "Fisher Score:  19%|█▉        | 15/79 [00:01<00:07,  8.38batch/s]\n",
      "Fisher Score:  20%|██        | 16/79 [00:01<00:07,  8.37batch/s]\n",
      "Fisher Score:  22%|██▏       | 17/79 [00:01<00:07,  8.34batch/s]\n",
      "Fisher Score:  23%|██▎       | 18/79 [00:02<00:07,  8.31batch/s]\n",
      "Fisher Score:  24%|██▍       | 19/79 [00:02<00:07,  8.28batch/s]\n",
      "Fisher Score:  25%|██▌       | 20/79 [00:02<00:07,  8.28batch/s]\n",
      "Fisher Score:  27%|██▋       | 21/79 [00:02<00:06,  8.29batch/s]\n",
      "Fisher Score:  28%|██▊       | 22/79 [00:02<00:06,  8.29batch/s]\n",
      "Fisher Score:  29%|██▉       | 23/79 [00:02<00:06,  8.29batch/s]\n",
      "Fisher Score:  30%|███       | 24/79 [00:02<00:06,  8.33batch/s]\n",
      "Fisher Score:  32%|███▏      | 25/79 [00:02<00:06,  8.29batch/s]\n",
      "Fisher Score:  33%|███▎      | 26/79 [00:03<00:06,  8.29batch/s]\n",
      "Fisher Score:  34%|███▍      | 27/79 [00:03<00:06,  8.29batch/s]\n",
      "Fisher Score:  35%|███▌      | 28/79 [00:03<00:06,  8.29batch/s]\n",
      "Fisher Score:  37%|███▋      | 29/79 [00:03<00:06,  8.30batch/s]\n",
      "Fisher Score:  38%|███▊      | 30/79 [00:03<00:05,  8.31batch/s]\n",
      "Fisher Score:  39%|███▉      | 31/79 [00:03<00:05,  8.31batch/s]\n",
      "Fisher Score:  41%|████      | 32/79 [00:03<00:05,  8.30batch/s]\n",
      "Fisher Score:  42%|████▏     | 33/79 [00:03<00:05,  8.30batch/s]\n",
      "Fisher Score:  43%|████▎     | 34/79 [00:04<00:05,  8.30batch/s]\n",
      "Fisher Score:  44%|████▍     | 35/79 [00:04<00:05,  8.30batch/s]\n",
      "Fisher Score:  46%|████▌     | 36/79 [00:04<00:05,  8.31batch/s]\n",
      "Fisher Score:  47%|████▋     | 37/79 [00:04<00:05,  8.32batch/s]\n",
      "Fisher Score:  48%|████▊     | 38/79 [00:04<00:04,  8.31batch/s]\n",
      "Fisher Score:  49%|████▉     | 39/79 [00:04<00:04,  8.31batch/s]\n",
      "Fisher Score:  51%|█████     | 40/79 [00:04<00:04,  8.24batch/s]\n",
      "Fisher Score:  52%|█████▏    | 41/79 [00:04<00:04,  8.24batch/s]\n",
      "Fisher Score:  53%|█████▎    | 42/79 [00:04<00:04,  8.25batch/s]\n",
      "Fisher Score:  54%|█████▍    | 43/79 [00:05<00:04,  8.27batch/s]\n",
      "Fisher Score:  56%|█████▌    | 44/79 [00:05<00:04,  8.27batch/s]\n",
      "Fisher Score:  57%|█████▋    | 45/79 [00:05<00:04,  8.28batch/s]\n",
      "Fisher Score:  58%|█████▊    | 46/79 [00:05<00:03,  8.30batch/s]\n",
      "Fisher Score:  59%|█████▉    | 47/79 [00:05<00:03,  8.30batch/s]\n",
      "Fisher Score:  61%|██████    | 48/79 [00:05<00:03,  8.30batch/s]\n",
      "Fisher Score:  62%|██████▏   | 49/79 [00:05<00:03,  8.27batch/s]\n",
      "Fisher Score:  63%|██████▎   | 50/79 [00:05<00:03,  8.29batch/s]\n",
      "Fisher Score:  65%|██████▍   | 51/79 [00:06<00:03,  8.28batch/s]\n",
      "Fisher Score:  66%|██████▌   | 52/79 [00:06<00:03,  8.29batch/s]\n",
      "Fisher Score:  67%|██████▋   | 53/79 [00:06<00:03,  8.30batch/s]\n",
      "Fisher Score:  68%|██████▊   | 54/79 [00:06<00:03,  8.29batch/s]\n",
      "Fisher Score:  70%|██████▉   | 55/79 [00:06<00:02,  8.29batch/s]\n",
      "Fisher Score:  71%|███████   | 56/79 [00:06<00:02,  8.29batch/s]\n",
      "Fisher Score:  72%|███████▏  | 57/79 [00:06<00:02,  8.29batch/s]\n",
      "Fisher Score:  73%|███████▎  | 58/79 [00:06<00:02,  8.29batch/s]\n",
      "Fisher Score:  75%|███████▍  | 59/79 [00:07<00:02,  8.28batch/s]\n",
      "Fisher Score:  76%|███████▌  | 60/79 [00:07<00:02,  8.28batch/s]\n",
      "Fisher Score:  77%|███████▋  | 61/79 [00:07<00:02,  8.29batch/s]\n",
      "Fisher Score:  78%|███████▊  | 62/79 [00:07<00:02,  8.29batch/s]\n",
      "Fisher Score:  80%|███████▉  | 63/79 [00:07<00:01,  8.29batch/s]\n",
      "Fisher Score:  81%|████████  | 64/79 [00:07<00:01,  8.27batch/s]\n",
      "Fisher Score:  82%|████████▏ | 65/79 [00:07<00:01,  8.28batch/s]\n",
      "Fisher Score:  84%|████████▎ | 66/79 [00:07<00:01,  8.28batch/s]\n",
      "Fisher Score:  85%|████████▍ | 67/79 [00:08<00:01,  8.27batch/s]\n",
      "Fisher Score:  86%|████████▌ | 68/79 [00:08<00:01,  8.28batch/s]\n",
      "Fisher Score:  87%|████████▋ | 69/79 [00:08<00:01,  8.28batch/s]\n",
      "Fisher Score:  89%|████████▊ | 70/79 [00:08<00:01,  8.28batch/s]\n",
      "Fisher Score:  90%|████████▉ | 71/79 [00:08<00:00,  8.29batch/s]\n",
      "Fisher Score:  91%|█████████ | 72/79 [00:08<00:00,  8.32batch/s]\n",
      "Fisher Score:  92%|█████████▏| 73/79 [00:08<00:00,  8.32batch/s]\n",
      "Fisher Score:  94%|█████████▎| 74/79 [00:08<00:00,  8.31batch/s]\n",
      "Fisher Score:  95%|█████████▍| 75/79 [00:08<00:00,  8.30batch/s]\n",
      "Fisher Score:  96%|█████████▌| 76/79 [00:09<00:00,  8.30batch/s]\n",
      "Fisher Score:  97%|█████████▋| 77/79 [00:09<00:00,  8.28batch/s]\n",
      "Fisher Score:  99%|█████████▊| 78/79 [00:09<00:00,  8.31batch/s]\n",
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=80987, ip=192.168.1.119, actor_id=580836d74913c89821ed116a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7271f0271950>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/client_app.py\", line 144, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/client_app.py\", line 128, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client_app.py\", line 75, in client_fn\n",
      "    return CustomNumpyClient(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client.py\", line 62, in __init__\n",
      "    self._compute_mask(sparsity=sparsity, mask_type=mask_type)\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client.py\", line 73, in _compute_mask\n",
      "    mask = create_mask(class_score=scores, sparsity=sparsity, mask_type=mask_type)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: create_mask() got an unexpected keyword argument 'class_score'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=80987, ip=192.168.1.119, actor_id=580836d74913c89821ed116a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7271f0271950>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: create_mask() got an unexpected keyword argument 'class_score'\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
      "    raise ex\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/ray/_private/worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=80987, ip=192.168.1.119, actor_id=580836d74913c89821ed116a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7271f0271950>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/client_app.py\", line 144, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/client_app.py\", line 128, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client_app.py\", line 75, in client_fn\n",
      "    return CustomNumpyClient(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client.py\", line 62, in __init__\n",
      "    self._compute_mask(sparsity=sparsity, mask_type=mask_type)\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client.py\", line 73, in _compute_mask\n",
      "    mask = create_mask(class_score=scores, sparsity=sparsity, mask_type=mask_type)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: create_mask() got an unexpected keyword argument 'class_score'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=80987, ip=192.168.1.119, actor_id=580836d74913c89821ed116a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7271f0271950>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: create_mask() got an unexpected keyword argument 'class_score'\n",
      "\n",
      "Fisher Score: 100%|██████████| 79/79 [00:09<00:00,  8.37batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 0 results and 2 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 1] No aggregated parameters (possibly all clients failed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server Eval Round 1] Model device: cuda:0\n",
      "[Server Eval Round 1] CUDA available in server eval: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 313/313 [00:22<00:00, 13.67batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 1] Centralized Evaluation - Loss: 7.0210, Metrics: {'centralized_accuracy': 0.0108}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 7.020998756725567, {'centralized_accuracy': 0.0108}, 60.76018893699802)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
      "Fisher Score:   0%|          | 0/79 [00:00<?, ?batch/s]\n",
      "Fisher Score:   3%|▎         | 2/79 [00:00<00:06, 11.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=80987)\u001b[0m [Client] Client on device: cuda:0\n",
      "\u001b[36m(ClientAppActor pid=80987)\u001b[0m [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   5%|▌         | 4/79 [00:00<00:08,  9.33batch/s]\n",
      "Fisher Score:   6%|▋         | 5/79 [00:00<00:08,  8.99batch/s]\n",
      "Fisher Score:   8%|▊         | 6/79 [00:00<00:08,  8.76batch/s]\n",
      "Fisher Score:   9%|▉         | 7/79 [00:00<00:08,  8.61batch/s]\n",
      "Fisher Score:  10%|█         | 8/79 [00:00<00:08,  8.52batch/s]\n",
      "Fisher Score:  11%|█▏        | 9/79 [00:01<00:08,  8.45batch/s]\n",
      "Fisher Score:  13%|█▎        | 10/79 [00:01<00:08,  8.39batch/s]\n",
      "Fisher Score:  14%|█▍        | 11/79 [00:01<00:08,  8.36batch/s]\n",
      "Fisher Score:  15%|█▌        | 12/79 [00:01<00:08,  8.32batch/s]\n",
      "Fisher Score:  16%|█▋        | 13/79 [00:01<00:07,  8.30batch/s]\n",
      "Fisher Score:  18%|█▊        | 14/79 [00:01<00:07,  8.28batch/s]\n",
      "Fisher Score:  19%|█▉        | 15/79 [00:01<00:07,  8.28batch/s]\n",
      "Fisher Score:  20%|██        | 16/79 [00:01<00:07,  8.28batch/s]\n",
      "Fisher Score:  22%|██▏       | 17/79 [00:01<00:07,  8.27batch/s]\n",
      "Fisher Score:  23%|██▎       | 18/79 [00:02<00:07,  8.26batch/s]\n",
      "Fisher Score:  24%|██▍       | 19/79 [00:02<00:07,  8.26batch/s]\n",
      "Fisher Score:  25%|██▌       | 20/79 [00:02<00:07,  8.26batch/s]\n",
      "Fisher Score:  27%|██▋       | 21/79 [00:02<00:07,  8.21batch/s]\n",
      "Fisher Score:  28%|██▊       | 22/79 [00:02<00:07,  8.12batch/s]\n",
      "Fisher Score:  29%|██▉       | 23/79 [00:02<00:06,  8.17batch/s]\n",
      "Fisher Score:  30%|███       | 24/79 [00:02<00:06,  8.21batch/s]\n",
      "Fisher Score:  32%|███▏      | 25/79 [00:02<00:06,  8.18batch/s]\n",
      "Fisher Score:  33%|███▎      | 26/79 [00:03<00:06,  8.20batch/s]\n",
      "Fisher Score:  34%|███▍      | 27/79 [00:03<00:06,  8.20batch/s]\n",
      "Fisher Score:  35%|███▌      | 28/79 [00:03<00:06,  8.23batch/s]\n",
      "Fisher Score:  37%|███▋      | 29/79 [00:03<00:06,  8.24batch/s]\n",
      "Fisher Score:  38%|███▊      | 30/79 [00:03<00:05,  8.24batch/s]\n",
      "Fisher Score:  39%|███▉      | 31/79 [00:03<00:05,  8.25batch/s]\n",
      "Fisher Score:  41%|████      | 32/79 [00:03<00:05,  8.26batch/s]\n",
      "Fisher Score:  42%|████▏     | 33/79 [00:03<00:05,  8.22batch/s]\n",
      "Fisher Score:  43%|████▎     | 34/79 [00:04<00:05,  8.22batch/s]\n",
      "Fisher Score:  44%|████▍     | 35/79 [00:04<00:05,  8.23batch/s]\n",
      "Fisher Score:  46%|████▌     | 36/79 [00:04<00:05,  8.24batch/s]\n",
      "Fisher Score:  47%|████▋     | 37/79 [00:04<00:05,  8.26batch/s]\n",
      "Fisher Score:  48%|████▊     | 38/79 [00:04<00:04,  8.26batch/s]\n",
      "Fisher Score:  49%|████▉     | 39/79 [00:04<00:04,  8.27batch/s]\n",
      "Fisher Score:  51%|█████     | 40/79 [00:04<00:04,  8.29batch/s]\n",
      "Fisher Score:  52%|█████▏    | 41/79 [00:04<00:04,  8.27batch/s]\n",
      "Fisher Score:  53%|█████▎    | 42/79 [00:05<00:04,  8.27batch/s]\n",
      "Fisher Score:  54%|█████▍    | 43/79 [00:05<00:04,  8.28batch/s]\n",
      "Fisher Score:  56%|█████▌    | 44/79 [00:05<00:04,  8.27batch/s]\n",
      "Fisher Score:  57%|█████▋    | 45/79 [00:05<00:04,  8.28batch/s]\n",
      "Fisher Score:  58%|█████▊    | 46/79 [00:05<00:03,  8.26batch/s]\n",
      "Fisher Score:  59%|█████▉    | 47/79 [00:05<00:03,  8.26batch/s]\n",
      "Fisher Score:  61%|██████    | 48/79 [00:05<00:03,  8.26batch/s]\n",
      "Fisher Score:  62%|██████▏   | 49/79 [00:05<00:03,  8.25batch/s]\n",
      "Fisher Score:  63%|██████▎   | 50/79 [00:05<00:03,  8.25batch/s]\n",
      "Fisher Score:  65%|██████▍   | 51/79 [00:06<00:03,  8.27batch/s]\n",
      "Fisher Score:  66%|██████▌   | 52/79 [00:06<00:03,  8.27batch/s]\n",
      "Fisher Score:  67%|██████▋   | 53/79 [00:06<00:03,  8.27batch/s]\n",
      "Fisher Score:  68%|██████▊   | 54/79 [00:06<00:03,  8.27batch/s]\n",
      "Fisher Score:  70%|██████▉   | 55/79 [00:06<00:02,  8.28batch/s]\n",
      "Fisher Score:  71%|███████   | 56/79 [00:06<00:02,  8.28batch/s]\n",
      "Fisher Score:  72%|███████▏  | 57/79 [00:06<00:02,  8.27batch/s]\n",
      "Fisher Score:  73%|███████▎  | 58/79 [00:06<00:02,  8.28batch/s]\n",
      "Fisher Score:  75%|███████▍  | 59/79 [00:07<00:02,  8.28batch/s]\n",
      "Fisher Score:  76%|███████▌  | 60/79 [00:07<00:02,  8.27batch/s]\n",
      "Fisher Score:  77%|███████▋  | 61/79 [00:07<00:02,  8.28batch/s]\n",
      "Fisher Score:  78%|███████▊  | 62/79 [00:07<00:02,  8.29batch/s]\n",
      "Fisher Score:  80%|███████▉  | 63/79 [00:07<00:01,  8.27batch/s]\n",
      "Fisher Score:  81%|████████  | 64/79 [00:07<00:01,  8.25batch/s]\n",
      "Fisher Score:  82%|████████▏ | 65/79 [00:07<00:01,  8.24batch/s]\n",
      "Fisher Score:  84%|████████▎ | 66/79 [00:07<00:01,  8.23batch/s]\n",
      "Fisher Score:  85%|████████▍ | 67/79 [00:08<00:01,  8.20batch/s]\n",
      "Fisher Score:  86%|████████▌ | 68/79 [00:08<00:01,  8.20batch/s]\n",
      "Fisher Score:  87%|████████▋ | 69/79 [00:08<00:01,  8.21batch/s]\n",
      "Fisher Score:  89%|████████▊ | 70/79 [00:08<00:01,  8.24batch/s]\n",
      "Fisher Score:  90%|████████▉ | 71/79 [00:08<00:00,  8.25batch/s]\n",
      "Fisher Score:  91%|█████████ | 72/79 [00:08<00:00,  8.24batch/s]\n",
      "Fisher Score:  92%|█████████▏| 73/79 [00:08<00:00,  8.25batch/s]\n",
      "Fisher Score:  94%|█████████▎| 74/79 [00:08<00:00,  8.23batch/s]\n",
      "Fisher Score:  95%|█████████▍| 75/79 [00:09<00:00,  8.24batch/s]\n",
      "Fisher Score:  96%|█████████▌| 76/79 [00:09<00:00,  8.25batch/s]\n",
      "Fisher Score:  97%|█████████▋| 77/79 [00:09<00:00,  8.25batch/s]\n",
      "Fisher Score:  99%|█████████▊| 78/79 [00:09<00:00,  8.26batch/s]\n",
      "\u001b[91mERROR \u001b[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001b[91mERROR \u001b[0m:     \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=80987, ip=192.168.1.119, actor_id=580836d74913c89821ed116a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7271f0271950>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/client_app.py\", line 144, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/client_app.py\", line 128, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client_app.py\", line 75, in client_fn\n",
      "    return CustomNumpyClient(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client.py\", line 62, in __init__\n",
      "    self._compute_mask(sparsity=sparsity, mask_type=mask_type)\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client.py\", line 73, in _compute_mask\n",
      "    mask = create_mask(class_score=scores, sparsity=sparsity, mask_type=mask_type)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: create_mask() got an unexpected keyword argument 'class_score'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=80987, ip=192.168.1.119, actor_id=580836d74913c89821ed116a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7271f0271950>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: create_mask() got an unexpected keyword argument 'class_score'\n",
      "Fisher Score: 100%|██████████| 79/79 [00:09<00:00,  8.31batch/s]\n",
      "\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/vce_api.py\", line 111, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 187, in process_message\n",
      "    raise ex\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/server/superlink/fleet/vce/backend/raybackend.py\", line 175, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "                                   ^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/ray/_private/worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/ray/_private/worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001b[36mray::ClientAppActor.run()\u001b[39m (pid=80987, ip=192.168.1.119, actor_id=580836d74913c89821ed116a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7271f0271950>)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/client_app.py\", line 144, in __call__\n",
      "    return self._call(message, context)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/client_app.py\", line 128, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/client/message_handler/message_handler.py\", line 96, in handle_legacy_message_from_msgtype\n",
      "    client = client_fn(context)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client_app.py\", line 75, in client_fn\n",
      "    return CustomNumpyClient(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client.py\", line 62, in __init__\n",
      "    self._compute_mask(sparsity=sparsity, mask_type=mask_type)\n",
      "  File \"/home/massimiliano/Projects/fl-g13/fl_g13/fl_pytorch/client.py\", line 73, in _compute_mask\n",
      "    mask = create_mask(class_score=scores, sparsity=sparsity, mask_type=mask_type)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: create_mask() got an unexpected keyword argument 'class_score'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[36mray::ClientAppActor.run()\u001b[39m (pid=80987, ip=192.168.1.119, actor_id=580836d74913c89821ed116a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x7271f0271950>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/massimiliano/miniconda3/envs/fl-g13/lib/python3.11/site-packages/flwr/simulation/ray_transport/ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: create_mask() got an unexpected keyword argument 'class_score'\n",
      "\n",
      "Fisher Score:   0%|          | 0/79 [00:00<?, ?batch/s]\n",
      "Fisher Score:   3%|▎         | 2/79 [00:00<00:06, 11.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=80987)\u001b[0m [Client] Client on device: cuda:0\n",
      "\u001b[36m(ClientAppActor pid=80987)\u001b[0m [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   5%|▌         | 4/79 [00:00<00:08,  9.29batch/s]\n",
      "Fisher Score:   6%|▋         | 5/79 [00:00<00:08,  8.95batch/s]\n",
      "Fisher Score:   8%|▊         | 6/79 [00:00<00:08,  8.70batch/s]\n",
      "Fisher Score:   9%|▉         | 7/79 [00:00<00:08,  8.57batch/s]\n",
      "Fisher Score:  10%|█         | 8/79 [00:00<00:08,  8.48batch/s]\n",
      "Fisher Score:  11%|█▏        | 9/79 [00:01<00:08,  8.43batch/s]\n",
      "Fisher Score:  13%|█▎        | 10/79 [00:01<00:08,  8.38batch/s]\n",
      "Fisher Score:  14%|█▍        | 11/79 [00:01<00:08,  8.35batch/s]\n",
      "Fisher Score:  15%|█▌        | 12/79 [00:01<00:08,  8.33batch/s]\n",
      "Fisher Score:  16%|█▋        | 13/79 [00:01<00:07,  8.30batch/s]\n",
      "Fisher Score:  18%|█▊        | 14/79 [00:01<00:07,  8.30batch/s]\n",
      "Fisher Score:  19%|█▉        | 15/79 [00:01<00:07,  8.31batch/s]\n",
      "Fisher Score:  20%|██        | 16/79 [00:01<00:07,  8.28batch/s]\n",
      "Fisher Score:  22%|██▏       | 17/79 [00:01<00:07,  8.25batch/s]\n",
      "Fisher Score:  23%|██▎       | 18/79 [00:02<00:07,  8.24batch/s]\n",
      "Fisher Score:  24%|██▍       | 19/79 [00:02<00:07,  8.20batch/s]\n",
      "Fisher Score:  25%|██▌       | 20/79 [00:02<00:07,  8.22batch/s]\n",
      "Fisher Score:  27%|██▋       | 21/79 [00:02<00:07,  8.22batch/s]\n",
      "Fisher Score:  28%|██▊       | 22/79 [00:02<00:06,  8.23batch/s]\n",
      "Fisher Score:  29%|██▉       | 23/79 [00:02<00:06,  8.23batch/s]\n",
      "Fisher Score:  30%|███       | 24/79 [00:02<00:06,  8.25batch/s]\n",
      "Fisher Score:  32%|███▏      | 25/79 [00:02<00:06,  8.26batch/s]\n",
      "Fisher Score:  33%|███▎      | 26/79 [00:03<00:06,  8.26batch/s]\n",
      "Fisher Score:  34%|███▍      | 27/79 [00:03<00:06,  8.28batch/s]\n",
      "Fisher Score:  35%|███▌      | 28/79 [00:03<00:06,  8.26batch/s]\n",
      "Fisher Score:  37%|███▋      | 29/79 [00:03<00:06,  8.26batch/s]\n",
      "Fisher Score:  38%|███▊      | 30/79 [00:03<00:05,  8.25batch/s]\n",
      "Fisher Score:  39%|███▉      | 31/79 [00:03<00:05,  8.24batch/s]\n",
      "Fisher Score:  41%|████      | 32/79 [00:03<00:05,  8.24batch/s]\n",
      "Fisher Score:  42%|████▏     | 33/79 [00:03<00:05,  8.21batch/s]\n",
      "Fisher Score:  43%|████▎     | 34/79 [00:04<00:05,  8.23batch/s]\n",
      "Fisher Score:  44%|████▍     | 35/79 [00:04<00:05,  8.22batch/s]\n",
      "Fisher Score:  46%|████▌     | 36/79 [00:04<00:05,  8.24batch/s]\n",
      "Fisher Score:  47%|████▋     | 37/79 [00:04<00:05,  8.25batch/s]\n",
      "Fisher Score:  48%|████▊     | 38/79 [00:04<00:04,  8.25batch/s]\n",
      "Fisher Score:  49%|████▉     | 39/79 [00:04<00:04,  8.26batch/s]\n",
      "Fisher Score:  51%|█████     | 40/79 [00:04<00:04,  8.26batch/s]\n",
      "Fisher Score:  52%|█████▏    | 41/79 [00:04<00:04,  8.27batch/s]\n",
      "Fisher Score:  53%|█████▎    | 42/79 [00:05<00:04,  8.28batch/s]\n",
      "Fisher Score:  54%|█████▍    | 43/79 [00:05<00:04,  8.27batch/s]\n",
      "Fisher Score:  56%|█████▌    | 44/79 [00:05<00:04,  8.26batch/s]\n",
      "Fisher Score:  57%|█████▋    | 45/79 [00:05<00:04,  8.28batch/s]\n",
      "Fisher Score:  58%|█████▊    | 46/79 [00:05<00:03,  8.28batch/s]\n",
      "Fisher Score:  59%|█████▉    | 47/79 [00:05<00:03,  8.28batch/s]\n",
      "Fisher Score:  61%|██████    | 48/79 [00:05<00:03,  8.27batch/s]\n",
      "Fisher Score:  62%|██████▏   | 49/79 [00:05<00:03,  8.27batch/s]\n",
      "Fisher Score:  63%|██████▎   | 50/79 [00:05<00:03,  8.26batch/s]\n",
      "Fisher Score:  65%|██████▍   | 51/79 [00:06<00:03,  8.26batch/s]\n",
      "Fisher Score:  66%|██████▌   | 52/79 [00:06<00:03,  8.24batch/s]\n",
      "Fisher Score:  67%|██████▋   | 53/79 [00:06<00:03,  8.24batch/s]\n",
      "Fisher Score:  68%|██████▊   | 54/79 [00:06<00:03,  8.24batch/s]\n",
      "Fisher Score:  70%|██████▉   | 55/79 [00:06<00:02,  8.23batch/s]\n",
      "Fisher Score:  71%|███████   | 56/79 [00:06<00:02,  8.24batch/s]\n",
      "Fisher Score:  72%|███████▏  | 57/79 [00:06<00:02,  8.23batch/s]\n",
      "Fisher Score:  73%|███████▎  | 58/79 [00:06<00:02,  8.23batch/s]\n",
      "Fisher Score:  75%|███████▍  | 59/79 [00:07<00:02,  8.21batch/s]\n",
      "Fisher Score:  76%|███████▌  | 60/79 [00:07<00:02,  8.22batch/s]\n",
      "Fisher Score:  77%|███████▋  | 61/79 [00:07<00:02,  8.24batch/s]\n",
      "Fisher Score:  78%|███████▊  | 62/79 [00:07<00:02,  8.25batch/s]\n",
      "Fisher Score:  80%|███████▉  | 63/79 [00:07<00:01,  8.26batch/s]\n",
      "Fisher Score:  81%|████████  | 64/79 [00:07<00:01,  8.24batch/s]\n",
      "Fisher Score:  82%|████████▏ | 65/79 [00:07<00:01,  8.21batch/s]\n",
      "Fisher Score:  84%|████████▎ | 66/79 [00:07<00:01,  8.23batch/s]\n",
      "Fisher Score:  85%|████████▍ | 67/79 [00:08<00:01,  8.23batch/s]\n",
      "Fisher Score:  86%|████████▌ | 68/79 [00:08<00:01,  8.21batch/s]\n",
      "Fisher Score:  87%|████████▋ | 69/79 [00:08<00:01,  8.20batch/s]\n",
      "Fisher Score:  89%|████████▊ | 70/79 [00:08<00:01,  8.21batch/s]\n",
      "Fisher Score:  90%|████████▉ | 71/79 [00:08<00:00,  8.18batch/s]\n",
      "Fisher Score:  91%|█████████ | 72/79 [00:08<00:00,  8.18batch/s]\n",
      "Fisher Score:  92%|█████████▏| 73/79 [00:08<00:00,  8.18batch/s]\n",
      "Fisher Score:  94%|█████████▎| 74/79 [00:08<00:00,  8.21batch/s]\n",
      "Fisher Score:  95%|█████████▍| 75/79 [00:09<00:00,  8.21batch/s]\n",
      "Fisher Score:  96%|█████████▌| 76/79 [00:09<00:00,  8.24batch/s]\n"
     ]
    }
   ],
   "source": [
    "run_simulation(\n",
    "    client_app=client_app,\n",
    "    server_app=server_app,\n",
    "    num_supernodes=number_of_clients,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-g13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
