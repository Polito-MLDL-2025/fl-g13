{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5767f6b1a63e945b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T20:50:03.075515Z",
     "start_time": "2025-06-03T20:50:02.926852Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9be9ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a218d880822fdfba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T20:50:35.686200Z",
     "start_time": "2025-06-03T20:50:33.570880Z"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv() # Load API Key\n",
    "WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")\n",
    "\n",
    "wandb.login(key=WANDB_API_KEY)\n",
    "from pathlib import Path\n",
    "\n",
    "import flwr\n",
    "import torch\n",
    "from flwr.simulation import run_simulation\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from fl_g13.architectures import BaseDino\n",
    "from fl_g13.fl_pytorch.client_app import get_client_app\n",
    "from fl_g13.fl_pytorch.server_app import get_server_app\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on {device}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "\n",
    "from fl_g13.fl_pytorch import build_fl_dependencies\n",
    "build_fl_dependencies()\n",
    "\n",
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if device == \"cuda\":\n",
    "    backend_config[\"client_resources\"] = {\"num_cpus\": 1, \"num_gpus\": 1}\n",
    "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
    "    # and how to set up the `backend_config`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377ae17b",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63bb533ec30809b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-03T20:50:48.494786Z",
     "start_time": "2025-06-03T20:50:47.673652Z"
    }
   },
   "outputs": [],
   "source": [
    "from fl_g13.modeling import load_or_create\n",
    "from fl_g13.editing import SparseSGDM\n",
    "from torch.optim import SGD\n",
    "\n",
    "# Model Hyper-parameters\n",
    "model_config={\n",
    "    \"head_layers\": 3,\n",
    "    \"head_hidden_size\": 512,\n",
    "    \"dropout_rate\": 0.0,\n",
    "    \"unfreeze_blocks\": 0,\n",
    "}\n",
    "\n",
    "# Training Hyper-parameters\n",
    "batch_size = 64\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-5\n",
    "T_max = 8\n",
    "eta_min = 1e-5\n",
    "\n",
    "# Model editing Hyper-parameters\n",
    "model_editing = False\n",
    "mask_type = 'global'\n",
    "sparsity = 0.8\n",
    "mask = None\n",
    "model_editing_batch_size = 16\n",
    "\n",
    "# Federated Hyper-parameters\n",
    "K = 100\n",
    "C = 0.1\n",
    "Js = [8]\n",
    "Ncs = [1, 5, 10, 50]\n",
    "\n",
    "save_every = 5\n",
    "fraction_fit = C  # Sample of available clients for training\n",
    "fraction_evaluate = 0.1  # Sample 50% of available clients for evaluation\n",
    "min_fit_clients = 10  # Never sample less than 10 clients for training\n",
    "min_evaluate_clients = 5  # Never sample less than 5 clients for evaluation\n",
    "min_available_clients = 10  # Wait until all 10 clients are available\n",
    "\n",
    "num_rounds = 200\n",
    "evaluate_each = 5\n",
    "partition_type = 'shard'\n",
    "NUM_CLIENTS = K\n",
    "\n",
    "# Wandb config\n",
    "use_wandb = True\n",
    "project_name = \"FL_Dino_CIFAR100_baseline_v4\"\n",
    "\n",
    "current_path = Path.cwd()\n",
    "model_save_path = current_path / f\"../models/fl_dino_v4/non_iid\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1427a966f7544b94",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d7c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Nc in Ncs:\n",
    "    for J in Js:\n",
    "        print('-' * 200)\n",
    "        print(f\"Training Non IId model\")\n",
    "        print(f\"Nc: {Nc}, J: {J}\")\n",
    "        checkpoint_dir = f\"{model_save_path}/{Nc}_{J}/editing\"\n",
    "        print(f'checkpoint_dir:{checkpoint_dir}')\n",
    "        \n",
    "        # Model\n",
    "        model, start_epoch = load_or_create(\n",
    "            path=checkpoint_dir,\n",
    "            model_class=BaseDino,\n",
    "            model_config=model_config,\n",
    "            optimizer=None,\n",
    "            scheduler=None,\n",
    "            device=device,\n",
    "            verbose=True,\n",
    "        )\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        scheduler = CosineAnnealingLR(\n",
    "            optimizer=optimizer,\n",
    "            T_max=T_max,\n",
    "            eta_min=eta_min\n",
    "        )\n",
    "\n",
    "        ## Unfreeze blocks\n",
    "        num_blocks = 0\n",
    "        model.unfreeze_blocks(num_blocks)\n",
    "        num_shards_per_partition = Nc\n",
    "\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        name = f\"FL_Dino_Baseline_model_non_iid_{Nc}_{J}\"\n",
    "        \n",
    "        wandb_config = {\n",
    "            # Wandb Params\n",
    "            'name': name,\n",
    "            'project_name': project_name,\n",
    "            'run_id': f\"{name}\",\n",
    "            # Federated Learning param\n",
    "            \"fraction_fit\": fraction_fit,\n",
    "            'partition_type': partition_type,\n",
    "            'K': K,\n",
    "            'C': C,\n",
    "            'J': J,\n",
    "            'Nc': Nc,\n",
    "            # Model editing params\n",
    "            'model_editing': model_editing,\n",
    "            'mask_type': mask_type,\n",
    "            'sparsity': sparsity,\n",
    "            'model_editing_batch_size': model_editing_batch_size,\n",
    "            # Training params\n",
    "            'lr': lr,\n",
    "            'momentum': momentum,\n",
    "        }\n",
    "\n",
    "        if model_editing:\n",
    "            # Create a dummy mask for SparseSGDM\n",
    "            init_mask = [torch.ones_like(p, device=p.device) for p in\n",
    "                         model.parameters()]  # Must be done AFTER the model is moved to the device\n",
    "            # Optimizer, scheduler, and loss function\n",
    "            optimizer = SparseSGDM(\n",
    "                model.parameters(),\n",
    "                mask=init_mask,\n",
    "                lr=lr,\n",
    "                momentum=0.9,\n",
    "                weight_decay=1e-5\n",
    "            )\n",
    "\n",
    "        client = get_client_app(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            device=device,\n",
    "            partition_type=partition_type,\n",
    "            local_epochs=1,\n",
    "            local_steps=J,\n",
    "            batch_size=batch_size,\n",
    "            num_shards_per_partition=num_shards_per_partition,\n",
    "            scheduler=None, #! Clients wont use scheduler, as it doesnt make sense here\n",
    "            verbose=0,\n",
    "            model_editing=model_editing,\n",
    "            mask_type=mask_type,\n",
    "            sparsity=sparsity,\n",
    "            mask=mask,\n",
    "            model_editing_batch_size=model_editing_batch_size,\n",
    "            mask_func=None\n",
    "        )\n",
    "\n",
    "        compute_round = num_rounds + 1 - start_epoch\n",
    "        server = get_server_app(\n",
    "            checkpoint_dir=checkpoint_dir,\n",
    "            model_class=model,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            scheduler=scheduler,\n",
    "            num_rounds=compute_round,\n",
    "            fraction_fit=fraction_fit,\n",
    "            fraction_evaluate=fraction_evaluate,\n",
    "            min_fit_clients=min_fit_clients,\n",
    "            min_evaluate_clients=min_evaluate_clients,\n",
    "            min_available_clients=min_available_clients,\n",
    "            device=device,\n",
    "            use_wandb=use_wandb,\n",
    "            wandb_config=wandb_config,\n",
    "            save_every=save_every,\n",
    "            prefix='fl_baseline',\n",
    "            evaluate_each=evaluate_each\n",
    "        )\n",
    "        \n",
    "        # Run simulation\n",
    "        run_simulation(\n",
    "            server_app=server,\n",
    "            client_app=client,\n",
    "            num_supernodes=NUM_CLIENTS,\n",
    "            backend_config=backend_config\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl-g13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
