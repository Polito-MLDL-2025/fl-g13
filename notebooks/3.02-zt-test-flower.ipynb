{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:15:23.244665Z",
     "start_time": "2025-04-17T14:15:23.065139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "5767f6b1a63e945b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:15:27.512725Z",
     "start_time": "2025-04-17T14:15:23.246672Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
   "id": "75ca9d6d54c4ce47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:15:42.883474Z",
     "start_time": "2025-04-17T14:15:27.516620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fl_g13.config import RAW_DATA_DIR\n",
    "\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from fl_g13.base_experimentation import dataset_handler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import flwr\n",
    "from flwr.common import Context\n",
    "\n",
    "from flwr.simulation import run_simulation\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-04-17 16:15:27.766\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mfl_g13.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:15:43.657647Z",
     "start_time": "2025-04-17T14:15:42.887474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# DEVICE = \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "# disable_progress_bar()"
   ],
   "id": "1a4ec3eb7baf32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Flower 1.17.0 / PyTorch 2.6.0+cu118\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load data",
   "id": "73fb84b164b0def7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:15:46.831579Z",
     "start_time": "2025-04-17T14:15:43.659546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "cifar100_train = datasets.CIFAR100(root=RAW_DATA_DIR, train=True, download=True, transform=transform)\n",
    "cifar100_test = datasets.CIFAR100(root=RAW_DATA_DIR, train=False, download=True, transform=transform)"
   ],
   "id": "6c6449ef9be1e422",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:15:47.654823Z",
     "start_time": "2025-04-17T14:15:46.834570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### train val split\n",
    "train_dataset,val_dataset = dataset_handler.train_test_split(cifar100_train,train_ratio=0.8)"
   ],
   "id": "a218d880822fdfba",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:15:48.349670Z",
     "start_time": "2025-04-17T14:15:47.656830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# I.I.D Sharding Split\n",
    "## k client\n",
    "k =10\n",
    "clients_dataset_train= dataset_handler.iid_sharding(train_dataset,k)\n",
    "clients_dataset_val= dataset_handler.iid_sharding(val_dataset,k)"
   ],
   "id": "1e23159840c6708d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tiny model",
   "id": "3ef53dc011fa9499"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:15:49.077908Z",
     "start_time": "2025-04-17T14:15:48.351675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TinyCNN(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(TinyCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))     # -> [B, 16, 32, 32]\n",
    "        x = F.max_pool2d(x, 2)        # -> [B, 16, 16, 16]\n",
    "        x = F.relu(self.conv2(x))     # -> [B, 32, 16, 16]\n",
    "        x = F.max_pool2d(x, 2)        # -> [B, 32, 8, 8]\n",
    "        x = x.view(x.size(0), -1)     # -> [B, 32*8*8]\n",
    "        x = self.fc1(x)               # -> [B, 100]\n",
    "        return x"
   ],
   "id": "fa219247a8a9d7c9",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Init model , optimizer and loss function",
   "id": "4c0f23c3615c6d68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:15:49.839096Z",
     "start_time": "2025-04-17T14:15:49.081797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = TinyCNN().to(DEVICE)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=1e-4, weight_decay=0.04)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ],
   "id": "9046d19b28a38ed3",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define the ClientApp",
   "id": "e73656b5d73ac995"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build module local\n",
    "\n",
    "Build module local such that ClientApp can use it"
   ],
   "id": "b5a0319c8e40215a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:16:03.434641Z",
     "start_time": "2025-04-17T14:15:49.844979Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -e ..",
   "id": "8a11402a3317027f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/ADMIN/Desktop/BACKUP/study/Italy/polito/classes/20242/deep%20learning/project/source_code/fl-g13\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: fl_g13\n",
      "  Building editable for fl_g13 (pyproject.toml): started\n",
      "  Building editable for fl_g13 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for fl_g13: filename=fl_g13-0.0.1-py3-none-any.whl size=2920 sha256=58cad1ba858085057c04f166298cea48e57db9492fa24b427227ecd360d31dcf\n",
      "  Stored in directory: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-e07qggtn\\wheels\\b7\\e0\\6d\\5d22ced2ef400b314cfe74883357cc37e1e1d5275e7ba9175e\n",
      "Successfully built fl_g13\n",
      "Installing collected packages: fl_g13\n",
      "  Attempting uninstall: fl_g13\n",
      "    Found existing installation: fl_g13 0.0.1\n",
      "    Uninstalling fl_g13-0.0.1:\n",
      "      Successfully uninstalled fl_g13-0.0.1\n",
      "Successfully installed fl_g13-0.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## create FlowerClient instances  ",
   "id": "97c881019a2b9e21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:16:04.292839Z",
     "start_time": "2025-04-17T14:16:03.436578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "'''\n",
    "Function load data client is to simulate the distribution data into each client\n",
    "In the real case, each client will have its dataset\n",
    "'''\n",
    "def load_data_client(context: Context):\n",
    "    partition_id = context.node_config[\"partition-id\"] \n",
    "    print(f\"Client {partition_id} is ready to train\")\n",
    "    trainloader = DataLoader(clients_dataset_train[partition_id])\n",
    "    valloader = DataLoader(clients_dataset_val[partition_id])\n",
    "    return trainloader, valloader"
   ],
   "id": "f05bbd371d1a87d9",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create instant of ClientApp",
   "id": "babef0c5a1343937"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:16:06.478133Z",
     "start_time": "2025-04-17T14:16:04.294840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fl_g13.fl_pytorch.client_app import get_client_app\n",
    "\n",
    "config={'local-epochs':1}\n",
    "client = get_client_app(load_data_client,model=net,optimizer=optimizer,criterion=criterion,device=DEVICE,config=config)"
   ],
   "id": "70467a37aa8c09c7",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Define the Flower ServerApp\n",
    "\n",
    "Customize built-in strategy Federated Averaging (FedAvg) of Flower to combine hyperparams in server-side and save model for each k epoch\n",
    "\n",
    "The strategy could also incremental training an"
   ],
   "id": "5ccd8dfd409b0385"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Create instant of ServerApp",
   "id": "6f9276503ee2d47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:16:11.742129Z",
     "start_time": "2025-04-17T14:16:06.480136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from fl_g13.fl_pytorch.server_app import get_server_app\n",
    "\n",
    "def get_datatest_fn(context: Context):\n",
    "    return DataLoader(cifar100_test)\n",
    "\n",
    "## checkpoints directory\n",
    "current_path = Path.cwd()\n",
    "model_test_path = current_path / \"../models/model_test\"\n",
    "model_test_path.resolve()\n",
    "\n",
    "\n",
    "num_rounds=2\n",
    "save_every =2\n",
    "fraction_fit=1.0  # Sample 100% of available clients for training\n",
    "fraction_evaluate=0.5  # Sample 50% of available clients for evaluation\n",
    "min_fit_clients=10  # Never sample less than 10 clients for training\n",
    "min_evaluate_clients=5  # Never sample less than 5 clients for evaluation\n",
    "min_available_clients=10  # Wait until all 10 clients are available\n",
    "device=DEVICE\n",
    "use_wandb=False\n",
    "\n",
    "\n",
    "server = get_server_app(checkpoint_dir=model_test_path.resolve(),\n",
    "                        model=net,optimizer=optimizer,criterion=criterion, get_datatest_fn=get_datatest_fn,\n",
    "                        num_rounds=num_rounds,\n",
    "                        fraction_fit=fraction_fit, \n",
    "                        fraction_evaluate=fraction_evaluate,  \n",
    "                        min_fit_clients=min_fit_clients,  \n",
    "                        min_evaluate_clients=min_evaluate_clients, \n",
    "                        min_available_clients=min_available_clients, \n",
    "                        device=device,\n",
    "                        use_wandb=use_wandb,\n",
    "                        save_every=save_every\n",
    "                        )"
   ],
   "id": "1cbac220e52a6d00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found, initializing new model from scratch.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Run the training\n",
   "id": "1427a966f7544b94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:16:12.687436Z",
     "start_time": "2025-04-17T14:16:11.744011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if DEVICE == \"cuda\":\n",
    "    backend_config[\"client_resources\"]= {\"num_cpus\": 1, \"num_gpus\": 0.25}\n",
    "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
    "    # and how to set up the `backend_config`"
   ],
   "id": "1388e3308f7b212b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9a1db478a3e1221"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:16:13.702131Z",
     "start_time": "2025-04-17T14:16:12.689420Z"
    }
   },
   "cell_type": "code",
   "source": "NUM_CLIENTS =10",
   "id": "23d2a1e147f59ffc",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:22:20.008542Z",
     "start_time": "2025-04-17T14:19:37.285451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ],
   "id": "1451e826d4713ec9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      Starting Flower ServerApp, config: num_rounds=2, no round_timeout\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [INIT]\n",
      "\u001B[92mINFO \u001B[0m:      Using initial global parameters provided by strategy\n",
      "\u001B[92mINFO \u001B[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continue train model from epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      ðŸ’¡ New best global model found: 0.090300\n",
      "\u001B[92mINFO \u001B[0m:      initial parameters (loss, other metrics): 4.152868543231487, {'centralized_accuracy': 0.0903}\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 1]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4.1529, Test Accuracy: 9.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=19896)\u001B[0m 2025-04-17 16:20:25.814 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=20364)\u001B[0m Client 7 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=22276)\u001B[0m Training Loss: 4.0446, Training Accuracy: 9.93%\n",
      "\u001B[36m(ClientAppActor pid=22276)\u001B[0m ðŸ“˜ Epoch [1/1] - Avg Loss: 4.0446, Accuracy: 9.93%\n",
      "\u001B[36m(ClientAppActor pid=25344)\u001B[0m Client 8 is ready to train\u001B[32m [repeated 9x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001B[93mWARNING \u001B[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001B[92mINFO \u001B[0m:      ðŸ’¡ New best global model found: 0.138600\n",
      "\u001B[92mINFO \u001B[0m:      fit progress: (1, 3.897378060948849, {'centralized_accuracy': 0.1386}, 73.15738400000009)\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.8974, Test Accuracy: 13.86%\n",
      "\u001B[36m(ClientAppActor pid=23668)\u001B[0m Training Loss: 4.0704, Training Accuracy: 9.12%\u001B[32m [repeated 9x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=23668)\u001B[0m ðŸ“˜ Epoch [1/1] - Avg Loss: 4.0704, Accuracy: 9.12%\u001B[32m [repeated 9x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=20364)\u001B[0m Client 5 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=25356)\u001B[0m Client 7 is ready to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 2]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=4160)\u001B[0m Test Loss: 3.9103, Test Accuracy: 13.10%\n",
      "\u001B[36m(ClientAppActor pid=23668)\u001B[0m Client 2 is ready to train\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=25344)\u001B[0m Test Loss: 3.9039, Test Accuracy: 12.10%\u001B[32m [repeated 4x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=25356)\u001B[0m Training Loss: 3.8980, Training Accuracy: 13.15%\n",
      "\u001B[36m(ClientAppActor pid=25356)\u001B[0m ðŸ“˜ Epoch [1/1] - Avg Loss: 3.8980, Accuracy: 13.15%\n",
      "\u001B[36m(ClientAppActor pid=19896)\u001B[0m Client 8 is ready to train\u001B[32m [repeated 9x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving centralized model epoch 2 aggregated_parameters...\n",
      "ðŸ’¾ Saved checkpoint at: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\model_test\\TinyCNN_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      ðŸ’¡ New best global model found: 0.162600\n",
      "\u001B[92mINFO \u001B[0m:      fit progress: (2, 3.7512905917793513, {'centralized_accuracy': 0.1626}, 124.51516420000007)\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 5 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.7513, Test Accuracy: 16.26%\n",
      "\u001B[36m(ClientAppActor pid=4160)\u001B[0m Training Loss: 3.8647, Training Accuracy: 12.97%\u001B[32m [repeated 9x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=4160)\u001B[0m ðŸ“˜ Epoch [1/1] - Avg Loss: 3.8647, Accuracy: 12.97%\u001B[32m [repeated 9x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=18356)\u001B[0m Client 3 is ready to train\n",
      "\u001B[36m(ClientAppActor pid=4160)\u001B[0m Client 1 is ready to train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 5 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [SUMMARY]\n",
      "\u001B[92mINFO \u001B[0m:      Run finished 2 round(s) in 131.92s\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, distributed):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 3.9517598749428986\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 3.823694650053978\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, centralized):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 0: 4.152868543231487\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 3.897378060948849\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 3.7512905917793513\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'federated_evaluate_accuracy': [(1, 0.1154), (2, 0.1378)]}\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, centralized):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'centralized_accuracy': [(0, 0.0903), (1, 0.1386), (2, 0.1626)]}\n",
      "\u001B[92mINFO \u001B[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=4160)\u001B[0m Test Loss: 3.7862, Test Accuracy: 14.20%\n",
      "\u001B[36m(ClientAppActor pid=18456)\u001B[0m Client 7 is ready to train\u001B[32m [repeated 3x across cluster]\u001B[0m\n",
      "\u001B[36m(ClientAppActor pid=20364)\u001B[0m Test Loss: 3.7581, Test Accuracy: 16.60%\u001B[32m [repeated 4x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(ClientAppActor pid=25344)\u001B[0m 2025-04-17 16:20:29.989 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\u001B[32m [repeated 9x across cluster]\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T14:19:02.835055Z",
     "start_time": "2025-04-17T14:19:02.822532Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "594f447d230508e6",
   "outputs": [],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
