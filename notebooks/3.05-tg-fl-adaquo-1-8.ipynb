{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed3f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239c7a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ciovi\\Desktop\\coding\\mldl\\fl-g13\\.venv\\lib\\site-packages\\dockerpycreds\\utils.py:1: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils.spawn\n",
      "\u001b[32m2025-06-29 20:09:31.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfl_g13.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Users\\ciovi\\Desktop\\coding\\mldl\\fl-g13\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import flwr\n",
    "import torch\n",
    "import dotenv\n",
    "import wandb\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from fl_g13.architectures import BaseDino\n",
    "from fl_g13.editing import SparseSGDM\n",
    "\n",
    "from fl_g13.fl_pytorch import build_fl_dependencies\n",
    "\n",
    "from fl_g13.fl_pytorch.datasets import reset_partition\n",
    "from fl_g13.modeling import load_or_create\n",
    "from fl_g13.editing import SparseSGDM, mask_dict_to_list\n",
    "from torch.optim import SGD\n",
    "\n",
    "from fl_g13.fl_pytorch.editing import load_mask\n",
    "\n",
    "from fl_g13.fl_pytorch import get_client_app, get_server_app\n",
    "from flwr.simulation import run_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e263b631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Flower 1.17.0 / PyTorch 2.7.1+cu128\n",
      "'vision_transformer.py' already exists.\n",
      "'utils.py' already exists.\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "build_fl_dependencies()\n",
    "\n",
    "if DEVICE == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
    "else:\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d4be89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\ciovi\\_netrc\n",
      "wandb: Currently logged in as: tarantino-giovanbattista01 (stefano-gamba-social-politecnico-di-torino) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    }
   ],
   "source": [
    "# login by key in .env file\n",
    "WANDB_API_KEY = dotenv.dotenv_values()[\"WANDB_API_KEY\"]\n",
    "wandb.login(key=WANDB_API_KEY)\n",
    "\n",
    "# Load checkpoint from .env file\n",
    "CHECKPOINT_DIR = dotenv.dotenv_values()[\"CHECKPOINT_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9668493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model config\n",
    "## Model Hyper-parameters\n",
    "head_layers = 3\n",
    "head_hidden_size = 512\n",
    "dropout_rate = 0.0\n",
    "unfreeze_blocks = 12\n",
    "\n",
    "## Training Hyper-parameters\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-5\n",
    "T_max = 8\n",
    "eta_min = 1e-5\n",
    "\n",
    "# FL config\n",
    "K = 100\n",
    "C = 0.1\n",
    "J = 8\n",
    "num_shards_per_partition = 1 # Nc\n",
    "partition_type = 'shard'\n",
    "\n",
    "num_rounds = 100\n",
    "\n",
    "## Server App config\n",
    "save_every = 5\n",
    "evaluate_each = 5\n",
    "fraction_fit = C        # 0.1\n",
    "fraction_evaluate = C   # 0.1\n",
    "min_fit_clients = 10\n",
    "min_evaluate_clients = 5\n",
    "min_available_clients = 10\n",
    "\n",
    "# model editing config\n",
    "model_editing = True\n",
    "mask_type = 'local'\n",
    "sparsity = 0.7\n",
    "calibration_rounds = 3\n",
    "model_editing_batch_size = 1\n",
    "mask = None\n",
    "\n",
    "## Adaptive Quorum strategy\n",
    "strategy = 'quorum'\n",
    "adaptive_quorum = True\n",
    "# Mask option\n",
    "mask_strategy = 'sum'\n",
    "initial_quorum = 1\n",
    "initial_target_sparsity = 0.7\n",
    "# Linear mode\n",
    "quorum_increment = 5\n",
    "quorum_update_frequency = 5\n",
    "# Adaptive mode\n",
    "drift_threshold = 0.00089251314 # minimum value from the last 10 rounds of the warmup\n",
    "quorum_patience = 4\n",
    "force_quorum_update = 15\n",
    "\n",
    "## simulation run config\n",
    "NUM_CLIENTS = 100\n",
    "MAX_PARALLEL_CLIENTS = 10\n",
    "\n",
    "## Base model location\n",
    "# The 200-epoch model folder\n",
    "# Ensure that the most recent file is the correct one\n",
    "model_save_path = CHECKPOINT_DIR + f\"/fl/non-iid/{num_shards_per_partition}_{J}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c42254b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading checkpoint from /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/1_8\\1_8_200_epoch.pth\n",
      "üì¶ Model class in checkpoint: BaseDino\n",
      "üîß Model configuration: {'variant': 'dino_vits16', 'dropout_rate': 0.0, 'head_hidden_size': 512, 'head_layers': 3, 'num_classes': 100, 'unfreeze_blocks': 0, 'activation_fn': 'GELU', 'pretrained': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ciovi/.cache\\torch\\hub\\facebookresearch_dino_main\n",
      "Using cache found in C:\\Users\\ciovi/.cache\\torch\\hub\\facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚û°Ô∏è Moved model to device: cuda\n",
      "‚úÖ Loaded checkpoint from /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/1_8\\1_8_200_epoch.pth, resuming at epoch 201\n"
     ]
    }
   ],
   "source": [
    "# Load Base model\n",
    "model, start_epoch = load_or_create(\n",
    "    path=model_save_path,\n",
    "    model_class=BaseDino,\n",
    "    model_config=None,\n",
    "    optimizer=None,\n",
    "    scheduler=None,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "model.to(DEVICE)\n",
    "\n",
    "if model_editing:\n",
    "    # Create a dummy mask for SparseSGDM\n",
    "    dummy_mask = [torch.ones_like(p, device=p.device) for p in model.parameters()]  \n",
    "    \n",
    "    optimizer = SparseSGDM(\n",
    "        model.parameters(),\n",
    "        mask=dummy_mask,\n",
    "        lr=lr,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "else:\n",
    "    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer=optimizer,\n",
    "    T_max=T_max,\n",
    "    eta_min=eta_min\n",
    ")\n",
    "\n",
    "# Unfreeze entire model for model_editing\n",
    "model.unfreeze_blocks(unfreeze_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ddd21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_file_name = CHECKPOINT_DIR + f'/masks/sum_{num_shards_per_partition}_{J}_{mask_type}_{sparsity}_{calibration_rounds}.pth'\n",
    "\n",
    "sum_mask = load_mask(mask_file_name)\n",
    "sum_mask = mask_dict_to_list(model, sum_mask) # converts for SparseSGDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f8d9cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using strategy 'DynmicQuorum'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ciovi\\Desktop\\coding\\mldl\\fl-g13\\.venv\\lib\\site-packages\\wandb\\analytics\\sentry.py:259: DeprecationWarning: The `Scope.user` setter is deprecated in favor of `Scope.set_user()`.\n",
      "  self.scope.user = {\"email\": email}  # noqa\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\ciovi\\Desktop\\coding\\mldl\\fl-g13\\notebooks\\wandb\\run-20250629_200937-fl_adaquo_1_8_local_0.7_3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/stefano-gamba-social-politecnico-di-torino/fl_v5_1_8_adaquo/runs/fl_adaquo_1_8_local_0.7_3' target=\"_blank\">fl_adaquo_1_8_local_0.7_3</a></strong> to <a href='https://wandb.ai/stefano-gamba-social-politecnico-di-torino/fl_v5_1_8_adaquo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/stefano-gamba-social-politecnico-di-torino/fl_v5_1_8_adaquo' target=\"_blank\">https://wandb.ai/stefano-gamba-social-politecnico-di-torino/fl_v5_1_8_adaquo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/stefano-gamba-social-politecnico-di-torino/fl_v5_1_8_adaquo/runs/fl_adaquo_1_8_local_0.7_3' target=\"_blank\">https://wandb.ai/stefano-gamba-social-politecnico-di-torino/fl_v5_1_8_adaquo/runs/fl_adaquo_1_8_local_0.7_3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      [DQ] ADAPTIVE mode enabled. Quorum: 56; Drift threshold: 0.00089251314\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=100, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 13.90batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 0] Centralized Evaluation - Loss: 2.4058, Metrics: {'centralized_accuracy': 0.3788}\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 2.405825910476831, {'centralized_accuracy': 0.3788}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 1 DQ] Generated global mask with sparsity: 0.7026\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "(ClientAppActor pid=17756) 2025-06-29 20:10:13.196 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: C:\\Users\\ciovi\\Desktop\\coding\\mldl\\fl-g13\n",
      "(ClientAppActor pid=17756) c:\\Users\\ciovi\\Desktop\\coding\\mldl\\fl-g13\\.venv\\lib\\site-packages\\dockerpycreds\\utils.py:1: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "(ClientAppActor pid=17756)   import distutils.spawn\n",
      "wandb: WARNING Tried to log to step 200 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 201 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "(ClientAppActor pid=17756) c:\\Users\\ciovi\\Desktop\\coding\\mldl\\fl-g13\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:172: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "(ClientAppActor pid=17756)   warnings.warn(\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 1] Avg Drift: 0.0010 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, {}, {}, 72.63201760000084)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 201 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 2 DQ] Generated global mask with sparsity: 0.7026\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 201 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 202 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 2] Avg Drift: 0.0013 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, {}, {}, 148.48580490000313)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 202 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 202 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 203 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 3] Avg Drift: 0.0014 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, {}, {}, 223.8762631999998)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 203 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 203 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 204 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 4] Avg Drift: 0.0014 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, {}, {}, 299.1922231999997)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 204 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 204 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 205 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 5] Avg Drift: 0.0014 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 5] Saving aggregated model at epoch 205...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_205.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:  13%|‚ñà‚ñé        | 40/313 [00:02<00:19, 13.97batch/s]wandb: WARNING Tried to log to step 205 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 13.94batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 5] Centralized Evaluation - Loss: 3.2487, Metrics: {'centralized_accuracy': 0.2465}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 3.248699161572197, {'centralized_accuracy': 0.2465}, 397.2150801000025)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 205 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 205 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 206 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 6] Avg Drift: 0.0011 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (6, {}, {}, 472.7649042999983)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 206 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 206 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 207 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 7] Avg Drift: 0.0012 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (7, {}, {}, 548.3435790000003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 207 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 207 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 208 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 8] Avg Drift: 0.0011 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (8, {}, {}, 623.7273548000012)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 208 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 208 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 209 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 9] Avg Drift: 0.0013 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (9, {}, {}, 699.2467991000012)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 209 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 209 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 210 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 10] Avg Drift: 0.0012 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 10] Saving aggregated model at epoch 210...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_210.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:  14%|‚ñà‚ñç        | 44/313 [00:03<00:19, 14.00batch/s]wandb: WARNING Tried to log to step 210 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 14.01batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 10] Centralized Evaluation - Loss: 2.3166, Metrics: {'centralized_accuracy': 0.3975}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (10, 2.3166036221166006, {'centralized_accuracy': 0.3975}, 797.1856105999977)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 210 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 11]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 210 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 211 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 11] Avg Drift: 0.0012 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (11, {}, {}, 872.5581898000019)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 211 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 12]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 211 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 212 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "wandb: WARNING Tried to log to step 212 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      [Round 12] Avg Drift: 0.0010 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (12, {}, {}, 948.2234298999974)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 13]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 212 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 213 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 13] Avg Drift: 0.0011 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (13, {}, {}, 1023.6682722000041)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 213 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 14]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 213 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 214 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 14] Avg Drift: 0.0012 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (14, {}, {}, 1098.9407358000026)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 214 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 15]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 214 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 215 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 15] Avg Drift: 0.0011 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 15] Saving aggregated model at epoch 215...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_215.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      [Round 15 DQ-ADAPTIVE] New Quorum: 61 (Forcing an update)\n",
      "Eval progress:  17%|‚ñà‚ñã        | 54/313 [00:03<00:18, 14.10batch/s]wandb: WARNING Tried to log to step 215 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 14.02batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 15] Centralized Evaluation - Loss: 2.1993, Metrics: {'centralized_accuracy': 0.4243}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (15, 2.199252530027883, {'centralized_accuracy': 0.4243}, 1196.8135432999989)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 215 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 16]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 16 DQ] Generated global mask with sparsity: 0.7176\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 215 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 216 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 16] Avg Drift: 0.0009 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (16, {}, {}, 1272.0155182000017)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 216 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 17]\n",
      "wandb: WARNING Tried to log to step 216 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 217 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 17] Avg Drift: 0.0010 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (17, {}, {}, 1347.3745417000027)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 217 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 18]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 217 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 218 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 18] Avg Drift: 0.0011 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (18, {}, {}, 1422.4675829000043)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 218 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 19]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 218 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 219 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 19] Avg Drift: 0.0009 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (19, {}, {}, 1497.5370208000022)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 219 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 20]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 219 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 220 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 20] Avg Drift: 0.0011 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 20] Saving aggregated model at epoch 220...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_220.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:  26%|‚ñà‚ñà‚ñå       | 82/313 [00:05<00:16, 14.07batch/s]wandb: WARNING Tried to log to step 220 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 14.04batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 20] Centralized Evaluation - Loss: 1.9641, Metrics: {'centralized_accuracy': 0.4694}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (20, 1.96407412378171, {'centralized_accuracy': 0.4694}, 1595.0795739000023)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 220 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 21]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 220 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 221 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 21] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 21 DQ-ADAPTIVE] New Quorum: 66 (Drift (0.0008) < Threshold (0.00089251314))\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (21, {}, {}, 1670.2496947000036)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 221 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 22]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 22 DQ] Generated global mask with sparsity: 0.7346\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 221 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 222 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 22] Avg Drift: 0.0010 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (22, {}, {}, 1744.752011800003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 222 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 23]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 222 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 223 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 23] Avg Drift: 0.0010 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (23, {}, {}, 1819.3521099999998)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 223 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 24]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 223 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 224 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 24] Avg Drift: 0.0010 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (24, {}, {}, 1893.826813300002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 224 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 25]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 224 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 225 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 25] Avg Drift: 0.0010 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 25] Saving aggregated model at epoch 225...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_225.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   2%|‚ñè         | 6/313 [00:00<00:21, 14.06batch/s]wandb: WARNING Tried to log to step 225 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 14.01batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 25] Centralized Evaluation - Loss: 1.8824, Metrics: {'centralized_accuracy': 0.4835}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (25, 1.8823892020950683, {'centralized_accuracy': 0.4835}, 1990.8713389999975)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 225 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 26]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 225 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 226 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 26] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 26 DQ-ADAPTIVE] New Quorum: 71 (Drift (0.0008) < Threshold (0.00089251314))\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (26, {}, {}, 2065.397271300004)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 226 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 27]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 27 DQ] Generated global mask with sparsity: 0.7535\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "wandb: WARNING Tried to log to step 226 that is less than the current step 227. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 27] Avg Drift: 0.0010 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (27, {}, {}, 2139.640781599999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 28]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 28] Avg Drift: 0.0010 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (28, {}, {}, 2214.1421078999992)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 29]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 29] Avg Drift: 0.0009 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (29, {}, {}, 2288.385949000003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 30]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 30] Avg Drift: 0.0010 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 30] Saving aggregated model at epoch 230...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_230.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 13.99batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 30] Centralized Evaluation - Loss: 2.0166, Metrics: {'centralized_accuracy': 0.462}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (30, 2.016564485364067, {'centralized_accuracy': 0.462}, 2385.1866945)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 31]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 31] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 31 DQ-ADAPTIVE] New Quorum: 76 (Drift (0.0007) < Threshold (0.00089251314))\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (31, {}, {}, 2459.7326914000005)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 32]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 32 DQ] Generated global mask with sparsity: 0.7739\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 32] Avg Drift: 0.0010 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (32, {}, {}, 2533.925529799999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 33]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 33] Avg Drift: 0.0009 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (33, {}, {}, 2607.5564995000022)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 34]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 34] Avg Drift: 0.0009 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (34, {}, {}, 2681.5619147000034)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 35]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 35] Avg Drift: 0.0010 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 35] Saving aggregated model at epoch 235...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_235.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 14.04batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 35] Centralized Evaluation - Loss: 1.8710, Metrics: {'centralized_accuracy': 0.4878}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (35, 1.870966547975144, {'centralized_accuracy': 0.4878}, 2777.298428300004)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 36]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 36] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 36 DQ-ADAPTIVE] New Quorum: 81 (Drift (0.0007) < Threshold (0.00089251314))\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (36, {}, {}, 2851.0243625000003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 37]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 37 DQ] Generated global mask with sparsity: 0.7958\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 37] Avg Drift: 0.0009 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (37, {}, {}, 2923.643563700003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 38]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 38] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (38, {}, {}, 2996.193928599998)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 39]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 39] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (39, {}, {}, 3068.9308087000027)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 40]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 40] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 40] Saving aggregated model at epoch 240...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_240.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      [Round 40 DQ-ADAPTIVE] New Quorum: 86 (Drift (0.0008) < Threshold (0.00089251314))\n",
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 14.04batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 40] Centralized Evaluation - Loss: 2.2697, Metrics: {'centralized_accuracy': 0.4112}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (40, 2.2696629850247416, {'centralized_accuracy': 0.4112}, 3163.7403562000036)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 41]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 41 DQ] Generated global mask with sparsity: 0.8201\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 41] Avg Drift: 0.0010 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (41, {}, {}, 3236.0443956000017)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 42]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 42] Avg Drift: 0.0009 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (42, {}, {}, 3308.577065700003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 43]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 43] Avg Drift: 0.0009 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (43, {}, {}, 3380.5409345000007)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 44]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 44] Avg Drift: 0.0009 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (44, {}, {}, 3452.8611413000035)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 45]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 45] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 45] Saving aggregated model at epoch 245...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_245.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      [Round 45 DQ-ADAPTIVE] New Quorum: 91 (Drift (0.0008) < Threshold (0.00089251314))\n",
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 13.98batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 45] Centralized Evaluation - Loss: 1.8147, Metrics: {'centralized_accuracy': 0.5077}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (45, 1.8147206538782332, {'centralized_accuracy': 0.5077}, 3547.715727499999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 46]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 46 DQ] Generated global mask with sparsity: 0.8485\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 46] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (46, {}, {}, 3618.9763373000023)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 47]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 47] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (47, {}, {}, 3690.2918382999997)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 48]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 48] Avg Drift: 0.0009 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (48, {}, {}, 3761.6420706999997)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 49]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 49] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 49 DQ-ADAPTIVE] New Quorum: 96 (Drift (0.0008) < Threshold (0.00089251314))\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (49, {}, {}, 3832.8841711999994)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 50]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 50 DQ] Generated global mask with sparsity: 0.8843\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 50] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 50] Saving aggregated model at epoch 250...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_250.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 14.02batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 50] Centralized Evaluation - Loss: 1.6533, Metrics: {'centralized_accuracy': 0.5497}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (50, 1.653316551694474, {'centralized_accuracy': 0.5497}, 3925.8568010000017)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 51]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 51] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (51, {}, {}, 3996.0101644000024)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 52]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 52] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (52, {}, {}, 4066.107154700003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 53]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 53] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 53 DQ-ADAPTIVE] New Quorum: 100 (Drift (0.0007) < Threshold (0.00089251314))\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (53, {}, {}, 4136.3846319)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 54]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 54 DQ] Generated global mask with sparsity: 0.9319\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 54] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (54, {}, {}, 4205.469213700002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 55]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 55] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 55] Saving aggregated model at epoch 255...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_255.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 14.01batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 55] Centralized Evaluation - Loss: 1.6086, Metrics: {'centralized_accuracy': 0.5541}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (55, 1.6086081426364545, {'centralized_accuracy': 0.5541}, 4297.083102500001)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 56]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 56] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (56, {}, {}, 4365.926513400002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 57]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 57] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 57 DQ-ADAPTIVE] New Quorum: 100 (Drift (0.0007) < Threshold (0.00089251314))\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (57, {}, {}, 4434.758425599997)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 58]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 58 DQ] Generated global mask with sparsity: 0.9319\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 58] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (58, {}, {}, 4503.744172899998)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 59]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 59] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (59, {}, {}, 4572.784385899999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 60]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 60] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 60] Saving aggregated model at epoch 260...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_260.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 13.98batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 60] Centralized Evaluation - Loss: 1.5938, Metrics: {'centralized_accuracy': 0.5557}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (60, 1.5938459198695782, {'centralized_accuracy': 0.5557}, 4664.415531999999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 61]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 61] Avg Drift: 0.0006 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 61 DQ-ADAPTIVE] New Quorum: 100 (Drift (0.0006) < Threshold (0.00089251314))\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (61, {}, {}, 4733.537215299999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 62]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 62 DQ] Generated global mask with sparsity: 0.9319\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 62] Avg Drift: 0.0006 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (62, {}, {}, 4802.6704175999985)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 63]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 63] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (63, {}, {}, 4872.029482899998)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 64]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 64] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (64, {}, {}, 4940.915750400003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 65]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 65] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 65] Saving aggregated model at epoch 265...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_265.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      [Round 65 DQ-ADAPTIVE] New Quorum: 100 (Drift (0.0008) < Threshold (0.00089251314))\n",
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 14.02batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 65] Centralized Evaluation - Loss: 1.7469, Metrics: {'centralized_accuracy': 0.5276}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (65, 1.7469493512528391, {'centralized_accuracy': 0.5276}, 5032.422413)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 66]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 66 DQ] Generated global mask with sparsity: 0.9319\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 66] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (66, {}, {}, 5101.672866699999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 67]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 67] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (67, {}, {}, 5170.712964700004)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 68]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 68] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (68, {}, {}, 5239.652864399999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 69]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 69] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 69 DQ-ADAPTIVE] New Quorum: 100 (Drift (0.0008) < Threshold (0.00089251314))\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (69, {}, {}, 5308.414681399998)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 70]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 70 DQ] Generated global mask with sparsity: 0.9319\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 70] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 70] Saving aggregated model at epoch 270...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_270.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 14.01batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 70] Centralized Evaluation - Loss: 1.5531, Metrics: {'centralized_accuracy': 0.5687}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (70, 1.5530890441550234, {'centralized_accuracy': 0.5687}, 5399.723652699999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 71]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 71] Avg Drift: 0.0006 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (71, {}, {}, 5468.5443725000005)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 72]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 72] Avg Drift: 0.0006 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (72, {}, {}, 5537.096168600001)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 73]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 73] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 73 DQ-ADAPTIVE] New Quorum: 100 (Drift (0.0007) < Threshold (0.00089251314))\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (73, {}, {}, 5606.020361800001)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 74]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 74 DQ] Generated global mask with sparsity: 0.9319\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 74] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (74, {}, {}, 5674.953572799997)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 75]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 75] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 75] Saving aggregated model at epoch 275...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_275.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 13.99batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 75] Centralized Evaluation - Loss: 1.6689, Metrics: {'centralized_accuracy': 0.5377}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (75, 1.6688862046875512, {'centralized_accuracy': 0.5377}, 5766.521300500004)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 76]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 76] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (76, {}, {}, 5836.271008399999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 77]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 77] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 77 DQ-ADAPTIVE] New Quorum: 100 (Drift (0.0007) < Threshold (0.00089251314))\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (77, {}, {}, 5905.461347700002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 78]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 78 DQ] Generated global mask with sparsity: 0.9319\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 78] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (78, {}, {}, 5974.3150510999985)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 79]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 79] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (79, {}, {}, 6043.194922000002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 80]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 80] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 80] Saving aggregated model at epoch 280...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_280.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 14.01batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 80] Centralized Evaluation - Loss: 1.8500, Metrics: {'centralized_accuracy': 0.4997}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (80, 1.8500059614547144, {'centralized_accuracy': 0.4997}, 6134.6795041000005)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 81]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 81] Avg Drift: 0.0009 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 81 DQ-ADAPTIVE] New Quorum: 100 (Drift (0.0009) < Threshold (0.00089251314))\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (81, {}, {}, 6203.752384799998)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 82]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 82 DQ] Generated global mask with sparsity: 0.9319\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 82] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (82, {}, {}, 6273.407749800004)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 83]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 83] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (83, {}, {}, 6343.883797100003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 84]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 84] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (84, {}, {}, 6414.409246800002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 85]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 85] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 85] Saving aggregated model at epoch 285...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_285.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      [Round 85 DQ-ADAPTIVE] New Quorum: 100 (Drift (0.0008) < Threshold (0.00089251314))\n",
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 13.65batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 85] Centralized Evaluation - Loss: 1.6432, Metrics: {'centralized_accuracy': 0.5457}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (85, 1.6431899329724784, {'centralized_accuracy': 0.5457}, 6508.113489299998)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 86]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 86 DQ] Generated global mask with sparsity: 0.9319\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 86] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (86, {}, {}, 6578.748883100001)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 87]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 87] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (87, {}, {}, 6649.290742900004)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 88]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 88] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (88, {}, {}, 6719.980203300001)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 89]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 89] Avg Drift: 0.0009 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (89, {}, {}, 6790.437910300003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 90]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 90] Avg Drift: 0.0009 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 90] Saving aggregated model at epoch 290...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_290.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:23<00:00, 13.57batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 90] Centralized Evaluation - Loss: 1.7358, Metrics: {'centralized_accuracy': 0.5282}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (90, 1.7358055560352703, {'centralized_accuracy': 0.5282}, 6883.948366299999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 91]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 91] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 91 DQ-ADAPTIVE] New Quorum: 100 (Drift (0.0007) < Threshold (0.00089251314))\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (91, {}, {}, 6954.648402400002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 92]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 92 DQ] Generated global mask with sparsity: 0.9319\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 92] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (92, {}, {}, 7025.9698708)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 93]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 93] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (93, {}, {}, 7096.3977018000005)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 94]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 94] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (94, {}, {}, 7166.956871399998)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 95]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 95] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 95] Saving aggregated model at epoch 295...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_295.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      [Round 95 DQ-ADAPTIVE] New Quorum: 100 (Drift (0.0008) < Threshold (0.00089251314))\n",
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:23<00:00, 13.60batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 95] Centralized Evaluation - Loss: 1.6374, Metrics: {'centralized_accuracy': 0.5519}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (95, 1.6373705926794595, {'centralized_accuracy': 0.5519}, 7260.518293699999)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 96]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 96 DQ] Generated global mask with sparsity: 0.9319\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 96] Avg Drift: 0.0007 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (96, {}, {}, 7331.238538800004)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 97]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 97] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (97, {}, {}, 7401.869808900003)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 98]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 98] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (98, {}, {}, 7473.465725000002)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 99]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 99] Avg Drift: 0.0009 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 99 DQ-ADAPTIVE] New Quorum: 100 (Drift (0.0009) < Threshold (0.00089251314))\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (99, {}, {}, 7542.8325391000035)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 100]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 100 DQ] Generated global mask with sparsity: 0.9319\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      [Round 100] Avg Drift: 0.0008 | Relative Drift: 0.0000\n",
      "\u001b[92mINFO \u001b[0m:      [Round 100] Saving aggregated model at epoch 300...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved checkpoint at: /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/AdaQuo/1_8_local_0.7_3\\fl_AdaQuo_BaseDino_epoch_300.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 14.00batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 100] Centralized Evaluation - Loss: 1.5619, Metrics: {'centralized_accuracy': 0.5725}\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (100, 1.5619278713917961, {'centralized_accuracy': 0.5725}, 7634.1362639)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 100 round(s) in 7650.29s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 3.355911469459534\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 3.635575234889984\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 3.2620184898376463\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 2.4276190757751466\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 2.881907069683075\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 2.8238325357437133\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 2.570778614282608\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 2.682638072967529\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 2.8682868838310243\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 2.34180970788002\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 11: 2.3324455499649046\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 12: 1.7961063265800477\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 13: 2.0047772109508513\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 14: 2.459494936466217\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 15: 1.6210597604513168\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 16: 2.0560923397541044\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 17: 2.0455182492733\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 18: 2.214039942622185\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 19: 2.253777724504471\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 20: 2.425784969329834\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 21: 1.6959196299314498\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 22: 2.046070176362991\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 23: 2.272805464267731\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 24: 1.9118404626846313\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 25: 1.8423051476478576\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 26: 2.7255669951438906\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 27: 1.8769262373447417\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 28: 2.1927829921245574\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 29: 1.9609322786331176\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 30: 2.0786435127258303\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 31: 2.3810184001922607\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 32: 1.5610482752323152\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 33: 2.3540995717048645\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 34: 2.098313367366791\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 35: 1.685689252614975\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 36: 1.7846977233886718\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 37: 1.8470655024051665\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 38: 1.6942253768444062\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 39: 1.8544191777706147\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 40: 2.5151685208082197\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 41: 1.7113337695598603\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 42: 1.9098304092884064\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 43: 1.6178648173809052\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 44: 1.6151026397943498\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 45: 2.653036814928055\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 46: 1.7266870111227035\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 47: 1.5731716752052307\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 48: 1.7490346640348435\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 49: 1.5881528317928315\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 50: 1.557889986038208\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 51: 1.2810226917266845\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 52: 1.599285262823105\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 53: 1.585787308216095\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 54: 1.5510597765445708\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 55: 1.7768203258514403\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 56: 1.3732624292373656\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 57: 1.5341031312942506\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 58: 1.861002367734909\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 59: 1.6818298399448395\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 60: 1.6104005813598632\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 61: 1.5535818338394165\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 62: 1.8297944247722626\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 63: 1.6504427909851074\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 64: 1.9641537249088288\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 65: 1.9294722259044648\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 66: 1.7044549107551574\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 67: 1.5361534833908081\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 68: 1.5509875893592835\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 69: 1.547295767068863\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 70: 1.1962753415107727\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 71: 1.7844139069318772\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 72: 1.648133248090744\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 73: 2.0157427728176116\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 74: 2.3283067405223847\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 75: 2.025253599882126\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 76: 1.4437688410282135\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 77: 1.4853802442550659\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 78: 1.817469984292984\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 79: 1.7917481362819672\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 80: 2.235863929986954\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 81: 1.3764491736888886\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 82: 1.9097090482711792\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 83: 1.8433846831321716\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 84: 1.559729140996933\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 85: 1.6511464834213256\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 86: 1.7451774597167968\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 87: 1.6806903511285782\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 88: 1.8704855978488921\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 89: 1.6550247490406036\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 90: 1.4146021783351899\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 91: 2.0634091973304747\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 92: 1.9153833508491516\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 93: 1.7129117727279664\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 94: 1.8295982301235199\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 95: 1.628278973698616\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 96: 1.7239594101905822\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 97: 1.4488551378250123\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 98: 2.157800579071045\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 99: 1.5998592853546143\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 100: 1.5676948428153992\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 2.405825910476831\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 3.248699161572197\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 2.3166036221166006\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 11: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 12: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 13: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 14: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 15: 2.199252530027883\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 16: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 17: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 18: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 19: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 20: 1.96407412378171\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 21: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 22: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 23: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 24: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 25: 1.8823892020950683\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 26: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 27: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 28: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 29: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 30: 2.016564485364067\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 31: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 32: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 33: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 34: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 35: 1.870966547975144\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 36: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 37: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 38: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 39: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 40: 2.2696629850247416\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 41: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 42: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 43: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 44: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 45: 1.8147206538782332\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 46: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 47: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 48: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 49: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 50: 1.653316551694474\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 51: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 52: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 53: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 54: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 55: 1.6086081426364545\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 56: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 57: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 58: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 59: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 60: 1.5938459198695782\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 61: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 62: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 63: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 64: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 65: 1.7469493512528391\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 66: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 67: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 68: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 69: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 70: 1.5530890441550234\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 71: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 72: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 73: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 74: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 75: 1.6688862046875512\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 76: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 77: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 78: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 79: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 80: 1.8500059614547144\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 81: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 82: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 83: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 84: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 85: 1.6431899329724784\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 86: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 87: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 88: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 89: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 90: 1.7358055560352703\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 91: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 92: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 93: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 94: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 95: 1.6373705926794595\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 96: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 97: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 98: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 99: {}\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 100: 1.5619278713917961\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, fit):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'avg_drift': [(1, np.float32(0.0010423202)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (2, np.float32(0.001259111)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (3, np.float32(0.0014236605)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (4, np.float32(0.0014001491)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (5, np.float32(0.0013549787)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (6, np.float32(0.0011382543)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (7, np.float32(0.0011607901)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (8, np.float32(0.0011442481)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (9, np.float32(0.0013332634)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (10, np.float32(0.0012210985)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (11, np.float32(0.00116754)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (12, np.float32(0.00095296453)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (13, np.float32(0.0011043927)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (14, np.float32(0.0011637425)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (15, np.float32(0.0011263163)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (16, np.float32(0.0008512449)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (17, np.float32(0.0010216505)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (18, np.float32(0.0010560728)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (19, np.float32(0.0009123781)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (20, np.float32(0.0010742255)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (21, np.float32(0.0008406104)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (22, np.float32(0.00097517384)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (23, np.float32(0.0010236822)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (24, np.float32(0.0009899416)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (25, np.float32(0.0009577803)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (26, np.float32(0.0008318962)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (27, np.float32(0.0010181876)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (28, np.float32(0.0010036975)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (29, np.float32(0.0009218931)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (30, np.float32(0.0009884683)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (31, np.float32(0.00074728)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (32, np.float32(0.000983351)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (33, np.float32(0.00092713785)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (34, np.float32(0.00093981903)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (35, np.float32(0.0010023244)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (36, np.float32(0.00074680254)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (37, np.float32(0.0008641103)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (38, np.float32(0.0008114061)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (39, np.float32(0.00074090046)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (40, np.float32(0.00081488455)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (41, np.float32(0.0009985198)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (42, np.float32(0.0008797623)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (43, np.float32(0.0008576874)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (44, np.float32(0.0009258477)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (45, np.float32(0.0008228131)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (46, np.float32(0.00080944883)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (47, np.float32(0.0008230783)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (48, np.float32(0.00088913547)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (49, np.float32(0.0007767639)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (50, np.float32(0.00079940265)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (51, np.float32(0.0006936785)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (52, np.float32(0.00082463527)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (53, np.float32(0.00070888153)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (54, np.float32(0.00067242514)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (55, np.float32(0.00070677046)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (56, np.float32(0.00065152126)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (57, np.float32(0.00066399074)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (58, np.float32(0.00071128673)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (59, np.float32(0.0007126954)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (60, np.float32(0.0007984782)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (61, np.float32(0.00056404714)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (62, np.float32(0.0006155383)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (63, np.float32(0.0006719151)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (64, np.float32(0.0006911702)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (65, np.float32(0.0007828787)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (66, np.float32(0.0007578118)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (67, np.float32(0.00071553345)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (68, np.float32(0.0006959523)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (69, np.float32(0.000764096)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (70, np.float32(0.000809484)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (71, np.float32(0.00055962184)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (72, np.float32(0.0006322374)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (73, np.float32(0.00066823314)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (74, np.float32(0.0007414843)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (75, np.float32(0.000776703)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (76, np.float32(0.0007217835)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (77, np.float32(0.00070042897)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (78, np.float32(0.0007360364)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (79, np.float32(0.0007907712)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (80, np.float32(0.0008057033)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (81, np.float32(0.00087741506)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (82, np.float32(0.000796333)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (83, np.float32(0.00083378877)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (84, np.float32(0.0007952739)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (85, np.float32(0.0007732826)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (86, np.float32(0.000816529)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (87, np.float32(0.000787648)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (88, np.float32(0.00082806987)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (89, np.float32(0.0009093197)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (90, np.float32(0.00090152863)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (91, np.float32(0.000728135)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (92, np.float32(0.00075177493)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (93, np.float32(0.000755988)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (94, np.float32(0.00080010714)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (95, np.float32(0.0007775777)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (96, np.float32(0.00073935546)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (97, np.float32(0.0007574517)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (98, np.float32(0.0008402309)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (99, np.float32(0.0008517977)),\n",
      "\u001b[92mINFO \u001b[0m:      \t               (100, np.float32(0.0008084482))],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'avg_train_loss': [(1, 0.4593115018928174),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (2, 0.634446567064867),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (3, 0.683129151135664),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (4, 0.5384794867520213),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (5, 0.46452453368039526),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (6, 0.5253790878952713),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (7, 0.5100345449777606),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (8, 0.4011185753661749),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (9, 0.5966854308416714),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (10, 0.38964379966125195),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (11, 0.5669690348517463),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (12, 0.3088118099684948),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (13, 0.43137763927145584),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (14, 0.4596338643867392),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (15, 0.38524302486764556),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (16, 0.3282760909452918),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (17, 0.42195202919363056),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (18, 0.41634688969667194),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (19, 0.25508996705775644),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (20, 0.38883483868303303),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (21, 0.33248928157907276),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (22, 0.40978904450930714),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (23, 0.4115144052366759),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (24, 0.37404863851897974),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (25, 0.3557058612421429),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (26, 0.3150090065137192),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (27, 0.3894818575186946),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (28, 0.393883087674385),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (29, 0.30014533545909217),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (30, 0.3752440907874188),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (31, 0.3067830674491233),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (32, 0.44977781245027015),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (33, 0.3359540244906384),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (34, 0.32466784969583384),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (35, 0.37446416439559016),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (36, 0.2778852699477284),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (37, 0.41971993180195566),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (38, 0.37212609970447375),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (39, 0.2719489630057069),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (40, 0.30156850881526226),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (41, 0.506503228944348),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (42, 0.3949744901765371),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (43, 0.328368825866346),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (44, 0.42559103745152244),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (45, 0.2904208375613962),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (46, 0.43647839447658043),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (47, 0.4409223109163577),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (48, 0.5150753004010766),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (49, 0.3703022725705523),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (50, 0.5558140458655544),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (51, 0.5601891681551934),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (52, 0.6456571486778557),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (53, 0.45171492952795234),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (54, 1.1305175881832839),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (55, 0.8654206980019807),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (56, 1.1031780905090272),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (57, 0.9091300773434341),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (58, 0.7942470264155418),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (59, 0.793481668131426),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (60, 1.0456855214200913),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (61, 0.6642112602479756),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (62, 0.6292333542834967),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (63, 0.7864815266802907),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (64, 0.6322595835779794),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (65, 0.7007267797831446),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (66, 0.7123885296517983),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (67, 0.5948914853157475),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (68, 0.561338551202789),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (69, 0.6674936798866838),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (70, 0.5840721827000379),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (71, 0.5212361107347533),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (72, 0.614849986473564),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (73, 0.5487689782341476),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (74, 0.6539574729278683),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (75, 0.5774892973946407),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (76, 0.6170944222249091),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (77, 0.5320439211558551),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (78, 0.5908046092605218),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (79, 0.673479992733337),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (80, 0.5431422939291224),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (81, 0.7488318227697164),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (82, 0.7051083241589368),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (83, 0.7026261032093316),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (84, 0.5424538567429409),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (85, 0.4712983877863735),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (86, 0.7492236078134737),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (87, 0.5410881560121197),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (88, 0.6348632245790213),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (89, 0.6267820213688537),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (90, 0.5599297911627218),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (91, 0.5020554318791255),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (92, 0.4929586615646258),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (93, 0.4595647658046801),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (94, 0.5202968744910322),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (95, 0.4870822024298832),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (96, 0.5603813734371215),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (97, 0.5209082979243249),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (98, 0.6147925441153348),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (99, 0.5899869209737517),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (100, 0.5435745891940315)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'relative_drift': [(1, np.float32(2.0075217e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (2, np.float32(2.4250637e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (3, np.float32(2.7419883e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (4, np.float32(2.6967048e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (5, np.float32(2.609706e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (6, np.float32(2.1922924e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (7, np.float32(2.2356967e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (8, np.float32(2.2038364e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (9, np.float32(2.5678826e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (10, np.float32(2.351852e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (11, np.float32(2.2486977e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (12, np.float32(1.8354226e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (13, np.float32(2.1270755e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (14, np.float32(2.241384e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (15, np.float32(2.1693006e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (16, np.float32(1.6395094e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (17, np.float32(1.9677132e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (18, np.float32(2.0340112e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (19, np.float32(1.7572534e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (20, np.float32(2.068974e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (21, np.float32(1.619028e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (22, np.float32(1.8781991e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (23, np.float32(1.971627e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (24, np.float32(1.9066423e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (25, np.float32(1.8446991e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (26, np.float32(1.6022444e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (27, np.float32(1.9610445e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (28, np.float32(1.9331364e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (29, np.float32(1.7755799e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (30, np.float32(1.9038049e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (31, np.float32(1.4392728e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (32, np.float32(1.8939494e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (33, np.float32(1.7856819e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (34, np.float32(1.810106e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (35, np.float32(1.9304923e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (36, np.float32(1.4383535e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (37, np.float32(1.66429e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (38, np.float32(1.562781e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (39, np.float32(1.4269859e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (40, np.float32(1.5694806e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (41, np.float32(1.923165e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (42, np.float32(1.6944358e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (43, np.float32(1.6519194e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (44, np.float32(1.7831973e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (45, np.float32(1.584751e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (46, np.float32(1.5590113e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (47, np.float32(1.5852619e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (48, np.float32(1.7124889e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (49, np.float32(1.4960597e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (50, np.float32(1.5396623e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (51, np.float32(1.3360359e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (52, np.float32(1.588261e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (53, np.float32(1.3653173e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (54, np.float32(1.2951017e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (55, np.float32(1.3612514e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (56, np.float32(1.2548405e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (57, np.float32(1.278857e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (58, np.float32(1.3699498e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (59, np.float32(1.372663e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (60, np.float32(1.537882e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (61, np.float32(1.0863639e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (62, np.float32(1.1855368e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (63, np.float32(1.2941196e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (64, np.float32(1.3312051e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (65, np.float32(1.5078372e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (66, np.float32(1.4595579e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (67, np.float32(1.378129e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (68, np.float32(1.3404153e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (69, np.float32(1.4716612e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (70, np.float32(1.5590794e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (71, np.float32(1.0778408e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (72, np.float32(1.2176995e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (73, np.float32(1.2870279e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (74, np.float32(1.4281107e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (75, np.float32(1.4959426e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (76, np.float32(1.3901667e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (77, np.float32(1.3490376e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (78, np.float32(1.417618e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (79, np.float32(1.5230382e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (80, np.float32(1.5517976e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (81, np.float32(1.6899156e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (82, np.float32(1.5337503e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (83, np.float32(1.6058907e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (84, np.float32(1.5317105e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (85, np.float32(1.4893549e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (86, np.float32(1.5726479e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (87, np.float32(1.5170228e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (88, np.float32(1.594876e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (89, np.float32(1.7513645e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (90, np.float32(1.7363586e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (91, np.float32(1.4023997e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (92, np.float32(1.4479306e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (93, np.float32(1.456045e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (94, np.float32(1.5410194e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (95, np.float32(1.4976273e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (96, np.float32(1.4240106e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (97, np.float32(1.4588641e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (98, np.float32(1.6182981e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (99, np.float32(1.6405762e-06)),\n",
      "\u001b[92mINFO \u001b[0m:      \t                    (100, np.float32(1.5570841e-06))]}\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'decentralized_avg_eval_accuracy': [(1, 0.207),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (2, 0.172),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (3, 0.198),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (4, 0.368),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (5, 0.274),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (6, 0.301),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (7, 0.336),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (8, 0.33),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (9, 0.277),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (10, 0.396),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (11, 0.329),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (12, 0.528),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (13, 0.42),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (14, 0.346),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (15, 0.579),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (16, 0.439),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (17, 0.442),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (18, 0.369),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (19, 0.48),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (20, 0.373),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (21, 0.529),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (22, 0.486),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (23, 0.365),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (24, 0.473),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (25, 0.46),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (26, 0.308),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (27, 0.503),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (28, 0.394),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (29, 0.478),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (30, 0.444),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (31, 0.372),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (32, 0.568),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (33, 0.395),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (34, 0.435),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (35, 0.539),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (36, 0.529),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (37, 0.508),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (38, 0.51),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (39, 0.501),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (40, 0.409),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (41, 0.516),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (42, 0.474),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (43, 0.519),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (44, 0.543),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (45, 0.303),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (46, 0.507),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (47, 0.563),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (48, 0.533),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (49, 0.578),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (50, 0.57),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (51, 0.662),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (52, 0.552),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (53, 0.565),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (54, 0.553),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (55, 0.502),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (56, 0.649),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (57, 0.59),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (58, 0.535),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (59, 0.511),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (60, 0.573),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (61, 0.572),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (62, 0.494),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (63, 0.546),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (64, 0.434),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (65, 0.491),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (66, 0.546),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (67, 0.577),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (68, 0.562),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (69, 0.536),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (70, 0.67),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (71, 0.514),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (72, 0.522),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (73, 0.461),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (74, 0.346),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (75, 0.46),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (76, 0.614),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (77, 0.601),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (78, 0.507),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (79, 0.495),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (80, 0.434),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (81, 0.663),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (82, 0.462),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (83, 0.467),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (84, 0.597),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (85, 0.54),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (86, 0.525),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (87, 0.567),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (88, 0.518),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (89, 0.521),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (90, 0.628),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (91, 0.363),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (92, 0.468),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (93, 0.506),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (94, 0.509),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (95, 0.572),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (96, 0.495),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (97, 0.611),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (98, 0.432),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (99, 0.572),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                     (100, 0.602)]}\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'centralized_accuracy': [(0, 0.3788),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (5, 0.2465),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (10, 0.3975),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (15, 0.4243),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (20, 0.4694),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (25, 0.4835),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (30, 0.462),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (35, 0.4878),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (40, 0.4112),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (45, 0.5077),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (50, 0.5497),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (55, 0.5541),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (60, 0.5557),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (65, 0.5276),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (70, 0.5687),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (75, 0.5377),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (80, 0.4997),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (85, 0.5457),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (90, 0.5282),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (95, 0.5519),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (100, 0.5725)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>centralized_accuracy</td><td>‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñà</td></tr><tr><td>centralized_eval_loss</td><td>‚ñÜ‚ñÑ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>decentralized_avg_eval_accuracy</td><td>‚ñÑ‚ñÇ‚ñÇ‚ñÜ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÜ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñÜ</td></tr><tr><td>decentralized_avg_eval_loss</td><td>‚ñÜ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÖ‚ñÇ</td></tr><tr><td>decentralized_avg_train_accuracy</td><td>‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ</td></tr><tr><td>decentralized_avg_train_loss</td><td>‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñà‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ</td></tr><tr><td>mask_sparsity</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>quorum</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>centralized_accuracy</td><td>0.5725</td></tr><tr><td>centralized_eval_loss</td><td>1.56193</td></tr><tr><td>decentralized_avg_eval_accuracy</td><td>0.602</td></tr><tr><td>decentralized_avg_eval_loss</td><td>1.56769</td></tr><tr><td>decentralized_avg_train_accuracy</td><td>0.85288</td></tr><tr><td>decentralized_avg_train_loss</td><td>0.54357</td></tr><tr><td>mask_sparsity</td><td>0.93191</td></tr><tr><td>quorum</td><td>100</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fl_adaquo_1_8_local_0.7_3</strong> at: <a href='https://wandb.ai/stefano-gamba-social-politecnico-di-torino/fl_v5_1_8_adaquo/runs/fl_adaquo_1_8_local_0.7_3' target=\"_blank\">https://wandb.ai/stefano-gamba-social-politecnico-di-torino/fl_v5_1_8_adaquo/runs/fl_adaquo_1_8_local_0.7_3</a><br> View project at: <a href='https://wandb.ai/stefano-gamba-social-politecnico-di-torino/fl_v5_1_8_adaquo' target=\"_blank\">https://wandb.ai/stefano-gamba-social-politecnico-di-torino/fl_v5_1_8_adaquo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250629_200937-fl_adaquo_1_8_local_0.7_3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run simulations\n",
    "reset_partition()\n",
    "\n",
    "model_checkpoint = CHECKPOINT_DIR + f\"/fl/non-iid/AdaQuo/{num_shards_per_partition}_{J}_{mask_type}_{sparsity}_{calibration_rounds}\"\n",
    "\n",
    "# Wandb settings\n",
    "use_wandb = True\n",
    "run_name = f\"fl_adaquo_{num_shards_per_partition}_{J}_{mask_type}_{sparsity}_{calibration_rounds}\"\n",
    "wandb_config = {\n",
    "    # wandb param\n",
    "    'name': run_name,\n",
    "    'project_name': f\"fl_v5_{num_shards_per_partition}_{J}_adaquo\",\n",
    "    'run_id': run_name,\n",
    "    \n",
    "    # fl config\n",
    "    \"fraction_fit\": fraction_fit,\n",
    "    \"lr\": lr,\n",
    "    \"momentum\": momentum,\n",
    "    'weight_decay': weight_decay,\n",
    "    'partition_type': partition_type,\n",
    "    'K': K,\n",
    "    'C': C,\n",
    "    'J': J,\n",
    "    'Nc': num_shards_per_partition,\n",
    "    \n",
    "    # model config\n",
    "    'head_layers': head_layers,\n",
    "    'head_hidden_size': head_hidden_size,\n",
    "    'dropout_rate': dropout_rate,\n",
    "    'unfreeze_blocks': unfreeze_blocks,\n",
    "    \n",
    "    # model editing config\n",
    "    'model_editing_batch_size': model_editing_batch_size,\n",
    "    'mask_calibration_round': calibration_rounds,\n",
    "    'mask_type': mask_type,\n",
    "    'sparsity': sparsity,\n",
    "    \n",
    "    # AdaQuo config\n",
    "    'initial_quorum': initial_quorum,\n",
    "    'initial_target_sparsity': initial_target_sparsity,\n",
    "    'quorum_increment': quorum_increment,\n",
    "    'quorum_update_frequency': quorum_update_frequency,\n",
    "    'drift_threshold': drift_threshold,\n",
    "    'quorum_patience': quorum_patience,\n",
    "    'force_quorum_update': force_quorum_update\n",
    "}\n",
    "\n",
    "client = get_client_app(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    "    partition_type=partition_type,\n",
    "    local_epochs=1,\n",
    "    local_steps=J,\n",
    "    batch_size=batch_size,\n",
    "    num_shards_per_partition=num_shards_per_partition,\n",
    "    scheduler=scheduler,\n",
    "    model_editing=model_editing,\n",
    "    mask_type=mask_type,\n",
    "    sparsity=sparsity,\n",
    "    mask=dummy_mask, # Will be replaced by the mask sent by the server\n",
    "    model_editing_batch_size=model_editing_batch_size,\n",
    "    mask_func=None,\n",
    "    mask_calibration_round=calibration_rounds,\n",
    "    strategy=strategy\n",
    ")\n",
    "\n",
    "server = get_server_app(\n",
    "    checkpoint_dir=model_checkpoint,\n",
    "    model_class=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_rounds=num_rounds,\n",
    "    fraction_fit=fraction_fit,\n",
    "    fraction_evaluate=fraction_evaluate,\n",
    "    min_fit_clients=min_fit_clients,\n",
    "    min_evaluate_clients=min_evaluate_clients,\n",
    "    min_available_clients=min_available_clients,\n",
    "    device=DEVICE,\n",
    "    use_wandb=use_wandb,\n",
    "    wandb_config=wandb_config,\n",
    "    save_every=save_every,\n",
    "    prefix='AdaQuo',\n",
    "    evaluate_each=evaluate_each,\n",
    "    model= model,\n",
    "    start_epoch= start_epoch,\n",
    "    # AdaQuo\n",
    "    strategy = strategy,\n",
    "    global_mask = sum_mask,\n",
    "    num_total_clients = NUM_CLIENTS,\n",
    "    adaptive_quorum = adaptive_quorum,\n",
    "    initial_target_sparsity = initial_target_sparsity,\n",
    "    quorum_increment = quorum_increment,\n",
    "    quorum_update_frequency = quorum_update_frequency,\n",
    "    initial_quorum = initial_quorum,\n",
    "    drift_threshold = drift_threshold,\n",
    "    quorum_patience = quorum_patience,\n",
    "    force_quorum_update = force_quorum_update\n",
    ")\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config\n",
    ")\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
