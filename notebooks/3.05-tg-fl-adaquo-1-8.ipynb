{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ed3f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239c7a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ciovi\\Desktop\\coding\\mldl\\fl-g13\\.venv\\lib\\site-packages\\dockerpycreds\\utils.py:1: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils.spawn\n",
      "\u001b[32m2025-06-28 18:19:32.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfl_g13.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Users\\ciovi\\Desktop\\coding\\mldl\\fl-g13\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import flwr\n",
    "import torch\n",
    "import dotenv\n",
    "import wandb\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from fl_g13.architectures import BaseDino\n",
    "from fl_g13.editing import SparseSGDM\n",
    "\n",
    "from fl_g13.fl_pytorch import build_fl_dependencies\n",
    "\n",
    "from fl_g13.fl_pytorch.datasets import reset_partition\n",
    "from fl_g13.modeling import load_or_create\n",
    "from fl_g13.editing import SparseSGDM, mask_dict_to_list\n",
    "from torch.optim import SGD\n",
    "\n",
    "from fl_g13.fl_pytorch.editing import load_mask\n",
    "\n",
    "from fl_g13.fl_pytorch import get_client_app, get_server_app\n",
    "from flwr.simulation import run_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e263b631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Flower 1.17.0 / PyTorch 2.7.1+cu128\n",
      "'vision_transformer.py' already exists.\n",
      "'utils.py' already exists.\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "build_fl_dependencies()\n",
    "\n",
    "if DEVICE == \"cuda\":\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 1.0}}\n",
    "else:\n",
    "    backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d4be89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\ciovi\\_netrc\n",
      "wandb: Currently logged in as: tarantino-giovanbattista01 (stefano-gamba-social-politecnico-di-torino) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    }
   ],
   "source": [
    "# login by key in .env file\n",
    "WANDB_API_KEY = dotenv.dotenv_values()[\"WANDB_API_KEY\"]\n",
    "wandb.login(key=WANDB_API_KEY)\n",
    "\n",
    "# Load checkpoint from .env file\n",
    "CHECKPOINT_DIR = dotenv.dotenv_values()[\"CHECKPOINT_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9668493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model config\n",
    "## Model Hyper-parameters\n",
    "head_layers = 3\n",
    "head_hidden_size = 512\n",
    "dropout_rate = 0.0\n",
    "unfreeze_blocks = 12\n",
    "\n",
    "## Training Hyper-parameters\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-5\n",
    "T_max = 8\n",
    "eta_min = 1e-5\n",
    "\n",
    "# FL config\n",
    "K = 100\n",
    "C = 0.1\n",
    "J = 8\n",
    "num_shards_per_partition = 1 # Nc\n",
    "partition_type = 'shard'\n",
    "\n",
    "num_rounds = 100\n",
    "\n",
    "## Server App config\n",
    "save_every = 5\n",
    "evaluate_each = 5\n",
    "fraction_fit = C        # 0.1\n",
    "fraction_evaluate = C   # 0.1\n",
    "min_fit_clients = 10\n",
    "min_evaluate_clients = 5\n",
    "min_available_clients = 10\n",
    "\n",
    "# model editing config\n",
    "model_editing = True\n",
    "mask_type = 'global'\n",
    "sparsity = 0.7\n",
    "calibration_rounds = 3\n",
    "model_editing_batch_size = 1\n",
    "mask = None\n",
    "\n",
    "## Adaptive Quorum strategy\n",
    "strategy = 'quorum'\n",
    "adaptive_quorum = True\n",
    "# Mask option\n",
    "mask_strategy = 'sum'\n",
    "initial_quorum = 1\n",
    "initial_target_sparsity = 0.65\n",
    "# Linear mode\n",
    "quorum_increment = 5\n",
    "quorum_update_frequency = 5\n",
    "# Adaptive mode\n",
    "drift_threshold = 0.0005\n",
    "quorum_patience = 4\n",
    "force_quorum_update = 15\n",
    "\n",
    "## simulation run config\n",
    "NUM_CLIENTS = 100\n",
    "MAX_PARALLEL_CLIENTS = 10\n",
    "\n",
    "## Base model location\n",
    "# The 200-epoch model folder\n",
    "# Ensure that the most recent file is the correct one\n",
    "model_save_path = CHECKPOINT_DIR + f\"/fl/non-iid/{num_shards_per_partition}_{J}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c42254b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading checkpoint from /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/1_8\\1_8_200_epoch.pth\n",
      "üì¶ Model class in checkpoint: BaseDino\n",
      "üîß Model configuration: {'variant': 'dino_vits16', 'dropout_rate': 0.0, 'head_hidden_size': 512, 'head_layers': 3, 'num_classes': 100, 'unfreeze_blocks': 0, 'activation_fn': 'GELU', 'pretrained': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ciovi/.cache\\torch\\hub\\facebookresearch_dino_main\n",
      "Using cache found in C:\\Users\\ciovi/.cache\\torch\\hub\\facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚û°Ô∏è Moved model to device: cuda\n",
      "‚úÖ Loaded checkpoint from /Users/ciovi/Desktop/coding/mldl/fl-g13/checkpoints/fl/non-iid/1_8\\1_8_200_epoch.pth, resuming at epoch 201\n"
     ]
    }
   ],
   "source": [
    "# Load Base model\n",
    "model, start_epoch = load_or_create(\n",
    "    path=model_save_path,\n",
    "    model_class=BaseDino,\n",
    "    model_config=None,\n",
    "    optimizer=None,\n",
    "    scheduler=None,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "model.to(DEVICE)\n",
    "\n",
    "if model_editing:\n",
    "    # Create a dummy mask for SparseSGDM\n",
    "    dummy_mask = [torch.ones_like(p, device=p.device) for p in model.parameters()]  \n",
    "    \n",
    "    optimizer = SparseSGDM(\n",
    "        model.parameters(),\n",
    "        mask=dummy_mask,\n",
    "        lr=lr,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "else:\n",
    "    optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer=optimizer,\n",
    "    T_max=T_max,\n",
    "    eta_min=eta_min\n",
    ")\n",
    "\n",
    "# Unfreeze entire model for model_editing\n",
    "model.unfreeze_blocks(unfreeze_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21ddd21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_file_name = CHECKPOINT_DIR + f'/masks/sum_{num_shards_per_partition}_{J}_{mask_type}_{sparsity}_{calibration_rounds}.pth'\n",
    "\n",
    "sum_mask = load_mask(mask_file_name)\n",
    "sum_mask = mask_dict_to_list(model, sum_mask) # converts for SparseSGDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8d9cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using strategy 'DynmicQuorum'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      [DQ] ADAPTIVE mode enabled. Quorum: 16; Drift threshold: 0.0005\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=100, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "Eval progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 313/313 [00:22<00:00, 13.61batch/s]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 0] Centralized Evaluation - Loss: 2.4058, Metrics: {'centralized_accuracy': 0.3788}\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 2.405825910476831, {'centralized_accuracy': 0.3788}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
      "\u001b[92mINFO \u001b[0m:      [Round 1 DQ] Generated global mask with sparsity: 0.6507\n",
      "\u001b[92mINFO \u001b[0m:      [Round 1 DQ] Sending global mask to the clients\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "(ClientAppActor pid=9736) 2025-06-28 18:20:07.313 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: C:\\Users\\ciovi\\Desktop\\coding\\mldl\\fl-g13\n",
      "(ClientAppActor pid=9736) c:\\Users\\ciovi\\Desktop\\coding\\mldl\\fl-g13\\.venv\\lib\\site-packages\\dockerpycreds\\utils.py:1: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "(ClientAppActor pid=9736)   import distutils.spawn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=9736) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=9736) Using quorum client, quorum\n",
      "(ClientAppActor pid=9736) Using DynamicQuorumClient\n",
      "(ClientAppActor pid=9736) [Client] Received global mask from the server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/4 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=9736) No prefix/name for the model was provided, choosen prefix/name: jazzy_caterpie_66\n",
      "(ClientAppActor pid=9736) Step 1/8 | Total batches: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:00<00:02,  1.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=9736) Step 2/8 | Total batches: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:01,  1.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=9736) Step 3/8 | Total batches: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [00:01<00:00,  1.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=9736) Step 4/8 | Total batches: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:01<00:00,  2.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=9736) Step 5/8 | Total batches: 4\n",
      "(ClientAppActor pid=9736) Step 6/8 | Total batches: 4\n",
      "(ClientAppActor pid=9736) Step 7/8 | Total batches: 4\n"
     ]
    }
   ],
   "source": [
    "# Run simulations\n",
    "reset_partition()\n",
    "\n",
    "model_checkpoint = CHECKPOINT_DIR + f\"/fl/non-iid/AdaQuo/{num_shards_per_partition}_{J}_{mask_type}_{sparsity}_{calibration_rounds}\"\n",
    "\n",
    "# Wandb settings\n",
    "use_wandb = True\n",
    "run_name = f\"fl_adaquo_{num_shards_per_partition}_{J}_{mask_type}_{sparsity}_{calibration_rounds}\"\n",
    "wandb_config = {\n",
    "    # wandb param\n",
    "    'name': run_name,\n",
    "    'project_name': f\"fl_v5_{num_shards_per_partition}_{J}_adaquo\",\n",
    "    'run_id': run_name,\n",
    "    \n",
    "    # fl config\n",
    "    \"fraction_fit\": fraction_fit,\n",
    "    \"lr\": lr,\n",
    "    \"momentum\": momentum,\n",
    "    'weight_decay': weight_decay,\n",
    "    'partition_type': partition_type,\n",
    "    'K': K,\n",
    "    'C': C,\n",
    "    'J': J,\n",
    "    'Nc': num_shards_per_partition,\n",
    "    \n",
    "    # model config\n",
    "    'head_layers': head_layers,\n",
    "    'head_hidden_size': head_hidden_size,\n",
    "    'dropout_rate': dropout_rate,\n",
    "    'unfreeze_blocks': unfreeze_blocks,\n",
    "    \n",
    "    # model editing config\n",
    "    'model_editing_batch_size': model_editing_batch_size,\n",
    "    'mask_calibration_round': calibration_rounds,\n",
    "    'mask_type': mask_type,\n",
    "    'sparsity': sparsity,\n",
    "    \n",
    "    # AdaQuo config\n",
    "    'initial_quorum': initial_quorum,\n",
    "    'initial_target_sparsity': initial_target_sparsity,\n",
    "    'quorum_increment': quorum_increment,\n",
    "    'quorum_update_frequency': quorum_update_frequency,\n",
    "    'drift_threshold': drift_threshold,\n",
    "    'quorum_patience': quorum_patience,\n",
    "    'force_quorum_update': force_quorum_update\n",
    "}\n",
    "\n",
    "client = get_client_app(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    "    partition_type=partition_type,\n",
    "    local_epochs=1,\n",
    "    local_steps=J,\n",
    "    batch_size=batch_size,\n",
    "    num_shards_per_partition=num_shards_per_partition,\n",
    "    scheduler=scheduler,\n",
    "    model_editing=model_editing,\n",
    "    mask_type=mask_type,\n",
    "    sparsity=sparsity,\n",
    "    mask=dummy_mask, # Will be replaced by the mask sent by the server\n",
    "    model_editing_batch_size=model_editing_batch_size,\n",
    "    mask_func=None,\n",
    "    mask_calibration_round=calibration_rounds,\n",
    "    strategy=strategy\n",
    ")\n",
    "\n",
    "server = get_server_app(\n",
    "    checkpoint_dir=model_checkpoint,\n",
    "    model_class=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_rounds=num_rounds,\n",
    "    fraction_fit=fraction_fit,\n",
    "    fraction_evaluate=fraction_evaluate,\n",
    "    min_fit_clients=min_fit_clients,\n",
    "    min_evaluate_clients=min_evaluate_clients,\n",
    "    min_available_clients=min_available_clients,\n",
    "    device=DEVICE,\n",
    "    use_wandb=use_wandb,\n",
    "    wandb_config=wandb_config,\n",
    "    save_every=save_every,\n",
    "    prefix='AdaQuo',\n",
    "    evaluate_each=1,\n",
    "    model= model,\n",
    "    start_epoch= start_epoch,\n",
    "    # AdaQuo\n",
    "    strategy = strategy,\n",
    "    global_mask = sum_mask,\n",
    "    num_total_clients = NUM_CLIENTS,\n",
    "    adaptive_quorum = adaptive_quorum,\n",
    "    initial_target_sparsity = initial_target_sparsity,\n",
    "    quorum_increment = quorum_increment,\n",
    "    quorum_update_frequency = quorum_update_frequency,\n",
    "    initial_quorum = initial_quorum,\n",
    "    drift_threshold = drift_threshold,\n",
    "    quorum_patience = quorum_patience,\n",
    "    force_quorum_update = force_quorum_update\n",
    ")\n",
    "\n",
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config\n",
    ")\n",
    "\n",
    "if use_wandb:\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
