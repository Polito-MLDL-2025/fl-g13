{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:51:33.007666Z",
     "start_time": "2025-05-15T14:51:32.906628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "5767f6b1a63e945b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:51:34.966691Z",
     "start_time": "2025-05-15T14:51:33.008651Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
   "id": "75ca9d6d54c4ce47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:51:46.390294Z",
     "start_time": "2025-05-15T14:51:34.967906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import flwr\n",
    "import torch\n",
    "from flwr.simulation import run_simulation\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "from fl_g13.architectures import BaseDino\n",
    "from fl_g13.config import RAW_DATA_DIR\n",
    "from fl_g13.editing import SparseSGDM\n",
    "from fl_g13.fl_pytorch.client_app import get_client_app\n",
    "from fl_g13.fl_pytorch.datasets import get_eval_transforms\n",
    "from fl_g13.fl_pytorch.server_app import get_server_app\n",
    "from fl_g13.modeling.eval import eval"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-05-15 16:51:41.357\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mfl_g13.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:51:46.999493Z",
     "start_time": "2025-05-15T14:51:46.391319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# DEVICE = \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "# disable_progress_bar()"
   ],
   "id": "1a4ec3eb7baf32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Flower 1.17.0 / PyTorch 2.6.0+cu118\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Login wandb",
   "id": "73fb84b164b0def7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:51:48.841570Z",
     "start_time": "2025-05-15T14:51:47.001495Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install wandb",
   "id": "6c6449ef9be1e422",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (0.19.9)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (68.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (4.13.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:51:49.312601Z",
     "start_time": "2025-05-15T14:51:48.842558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## read .env file\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n"
   ],
   "id": "5f279490dd7a970f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:51:50.801450Z",
     "start_time": "2025-05-15T14:51:49.313529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "# login by key in .env file\n",
    "WANDB_API_KEY = dotenv.dotenv_values()[\"WANDB_API_KEY\"]\n",
    "wandb.login(key=WANDB_API_KEY)"
   ],
   "id": "a218d880822fdfba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\notebook\\utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  return LooseVersion(v) >= LooseVersion(check)\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\ADMIN\\_netrc\n",
      "wandb: Currently logged in as: thanhnv-it23 (stefano-gamba-social-politecnico-di-torino) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build module local\n",
    "\n",
    "Build module local such that ClientApp can use it"
   ],
   "id": "b5a0319c8e40215a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:51:56.590365Z",
     "start_time": "2025-05-15T14:51:50.803430Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -e ..",
   "id": "8a11402a3317027f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/ADMIN/Desktop/BACKUP/study/Italy/polito/classes/20242/deep%20learning/project/source_code/fl-g13"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies: started"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Installing build dependencies: finished with status 'done'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checking if build backend supports build_editable: started"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checking if build backend supports build_editable: finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[notice] To update, run: python.exe -m pip install --upgrade pip"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Getting requirements to build editable: started"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: fl_g13\n",
      "  Building editable for fl_g13 (pyproject.toml): started\n",
      "  Building editable for fl_g13 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for fl_g13: filename=fl_g13-0.0.1-py3-none-any.whl size=4649 sha256=a588eeccbccdbea56dbfe92e55bd612babd81e07366f39e361ccc99a5ffdec08\n",
      "  Stored in directory: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-ouqrfxaf\\wheels\\b7\\e0\\6d\\5d22ced2ef400b314cfe74883357cc37e1e1d5275e7ba9175e\n",
      "Successfully built fl_g13\n",
      "Installing collected packages: fl_g13\n",
      "  Attempting uninstall: fl_g13\n",
      "    Found existing installation: fl_g13 0.0.1\n",
      "    Uninstalling fl_g13-0.0.1:\n",
      "      Successfully uninstalled fl_g13-0.0.1\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Download missing module for clients\n",
    "\n",
    "Dino model,that is serialized and sent to client by server, require some modules that have to download from source code of dino model\n"
   ],
   "id": "9399f1a9cedc8cc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:51:57.190651Z",
     "start_time": "2025-05-15T14:51:56.591376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def download_if_not_exists(file_path: str, file_url: str):\n",
    "    \"\"\"\n",
    "    Checks if a file exists at the given path. If it does not, downloads it from the specified URL.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The local path to check and save the file.\n",
    "    - file_url (str): The URL from which to download the file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"'{file_path}' not found. Downloading from {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "            print(\"Download complete.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download file: {e}\")\n",
    "    else:\n",
    "        print(f\"'{file_path}' already exists.\")"
   ],
   "id": "beb2c855fcd8933c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:51:57.713451Z",
     "start_time": "2025-05-15T14:51:57.191667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "download_if_not_exists(\"vision_transformer.py\",\n",
    "                       \"https://raw.githubusercontent.com/facebookresearch/dino/refs/heads/main/vision_transformer.py\")\n",
    "download_if_not_exists(\"utils.py\",\n",
    "                       \"https://raw.githubusercontent.com/facebookresearch/dino/refs/heads/main/utils.py\")\n"
   ],
   "id": "d93caca63a33c71f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'vision_transformer.py' already exists.\n",
      "'utils.py' already exists.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FL",
   "id": "ee82432353abfbe2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configs",
   "id": "cdb05316b163821b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:51:58.213403Z",
     "start_time": "2025-05-15T14:51:57.714327Z"
    }
   },
   "cell_type": "code",
   "source": "DEBUG = True",
   "id": "6ba4f53af219c423",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:51:58.761668Z",
     "start_time": "2025-05-15T14:51:58.214987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model config\n",
    "\n",
    "## Model Hyper-parameters\n",
    "head_layers = 3\n",
    "head_hidden_size = 512\n",
    "dropout_rate = 0.0\n",
    "unfreeze_blocks = 1\n",
    "\n",
    "## Training Hyper-parameters\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-5\n",
    "T_max = 8\n",
    "eta_min = 1e-5\n",
    "\n",
    "# FL config\n",
    "K = 100\n",
    "C = 0.1\n",
    "J = 4\n",
    "num_rounds = 30\n",
    "partition_type = 'iid'\n",
    "\n",
    "## only for partition_type = 'shard'\n",
    "num_shards_per_partition = 10\n",
    "\n",
    "## Server App config\n",
    "save_every = 1\n",
    "fraction_fit = C  # Sample of available clients for training\n",
    "fraction_evaluate = 0.1  # Sample 50% of available clients for evaluation\n",
    "min_fit_clients = 10  # Never sample less than 10 clients for training\n",
    "min_evaluate_clients = 5  # Never sample less than 5 clients for evaluation\n",
    "min_available_clients = 10  # Wait until all 10 clients are available\n",
    "device = DEVICE\n",
    "## checkpoints directory\n",
    "current_path = Path.cwd()\n",
    "model_save_path = current_path / f\"../models/fl_dino_baseline/{partition_type}\"\n",
    "checkpoint_dir = model_save_path.resolve()\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "## Wandb config\n",
    "use_wandb = True\n",
    "wandb_config = {\n",
    "    # wandb param\n",
    "    'name': 'FL_Dino_Baseline_iid',\n",
    "    'project_name': \"FL_test_chart\",\n",
    "    # model config param\n",
    "    \"fraction_fit\": fraction_fit,\n",
    "    \"lr\": lr,\n",
    "    \"momentum\": momentum,\n",
    "    'partition_type': partition_type,\n",
    "    'K': K,\n",
    "    'C': C,\n",
    "    'J': J,\n",
    "}\n",
    "\n",
    "# model editing config\n",
    "model_editing = True\n",
    "mask_type = 'global'\n",
    "sparsity = 0.2\n",
    "mask = None\n",
    "\n",
    "## simulation run config\n",
    "NUM_CLIENTS = 100\n",
    "MAX_PARALLEL_CLIENTS = 10\n",
    "\n",
    "if DEBUG:\n",
    "    use_wandb = False\n",
    "    num_rounds = 2\n",
    "    J = 4\n"
   ],
   "id": "d63bb533ec30809b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define model , optimizer and loss function",
   "id": "4c0f23c3615c6d68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:51:59.984133Z",
     "start_time": "2025-05-15T14:51:58.762888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fl_g13.modeling import load_or_create\n",
    "\n",
    "# Model\n",
    "model, start_epoch = load_or_create(\n",
    "        path=checkpoint_dir,\n",
    "        model_class=BaseDino,\n",
    "        model_config=None,\n",
    "        optimizer=None,\n",
    "        scheduler=None,\n",
    "        device=device,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# Create a dummy mask for SparseSGDM\n",
    "init_mask = [torch.ones_like(p, device=p.device) for p in\n",
    "             model.parameters()]  # Must be done AFTER the model is moved to the device\n",
    "# Optimizer, scheduler, and loss function\n",
    "optimizer = SparseSGDM(\n",
    "    model.parameters(),\n",
    "    mask=init_mask,\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer=optimizer,\n",
    "    T_max=T_max,\n",
    "    eta_min=eta_min\n",
    ")"
   ],
   "id": "9046d19b28a38ed3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_75.pth\n",
      "📦 Model class in checkpoint: BaseDino\n",
      "🔧 Model configuration: {'variant': 'dino_vits16', 'dropout_rate': 0.0, 'head_hidden_size': 512, 'head_layers': 3, 'num_classes': 100, 'unfreeze_blocks': 1, 'activation_fn': 'GELU', 'pretrained': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n",
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️ Moved model to device: cuda\n",
      "✅ Loaded checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_75.pth, resuming at epoch 76\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate the centralized mask",
   "id": "89bcbe951f4c5307"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:52:29.994844Z",
     "start_time": "2025-05-15T14:51:59.986133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fl_g13.editing import fisher_scores\n",
    "from fl_g13.fl_pytorch.datasets import load_flwr_datasets, get_transforms\n",
    "\n",
    "## calculate fisher score of each client with idd sharding\n",
    "clients_fisher_scores = []\n",
    "train_test_split_ratio = 0.2\n",
    "for i in range(NUM_CLIENTS):\n",
    "    partition_id = i\n",
    "    num_partitions = NUM_CLIENTS\n",
    "    client_trainloader, client_valloader = load_flwr_datasets(partition_id=partition_id,\n",
    "        partition_type=partition_type,\n",
    "        num_partitions=num_partitions,\n",
    "        num_shards_per_partition=num_shards_per_partition,\n",
    "        batch_size=batch_size,\n",
    "        train_test_split_ratio=train_test_split_ratio,\n",
    "        transform=get_transforms)\n",
    "    scores = fisher_scores(dataloader=client_valloader, model=model, verbose=1, loss_fn=criterion)\n",
    "    clients_fisher_scores.append(scores)\n",
    "    "
   ],
   "id": "fe6b7dd9c469b68",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  1.19batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.36batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  4.95batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.10batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.05batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.24batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.20batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.07batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.41batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.04batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.15batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.24batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.08batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.16batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.08batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.12batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.14batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  4.98batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.05batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.04batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.10batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  4.94batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.08batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.00batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.09batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.10batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.08batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.01batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.11batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.00batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.11batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  4.99batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.02batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.00batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.04batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.10batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.10batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.03batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.14batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.00batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.12batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.04batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.01batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.02batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.14batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  4.96batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.08batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.08batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.00batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.01batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.06batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.05batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.02batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.07batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.10batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.01batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.07batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.04batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.11batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.05batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.20batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.00batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.06batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.05batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.02batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  4.97batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.16batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.05batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.02batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.01batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.06batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.02batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.03batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  4.98batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.10batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.00batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.04batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  4.97batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.00batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.00batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.01batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.03batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.08batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.00batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.08batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.01batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.06batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  4.98batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  4.98batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.04batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.08batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  4.94batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.14batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.04batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.08batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.07batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.06batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.02batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  4.99batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.09batch/s]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:52:30.560998Z",
     "start_time": "2025-05-15T14:52:29.995881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "agg_scores = defaultdict(list)\n",
    "\n",
    "# Collect all scores for each parameter\n",
    "for client_scores in clients_fisher_scores:\n",
    "    for name, score in client_scores.items():\n",
    "        agg_scores[name].append(score)\n",
    "\n",
    "# Average scores across clients , this is fisher scores on server size\n",
    "avg_fisher_scores = {name: torch.mean(torch.stack(scores), dim=0) for name, scores in agg_scores.items()}\n"
   ],
   "id": "ad3df1f391ba89a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:52:31.082106Z",
     "start_time": "2025-05-15T14:52:30.561982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fl_g13.editing import create_gradiend_mask, mask_dict_to_list\n",
    "\n",
    "# compute the centralized mask\n",
    "mask_dict = create_gradiend_mask(class_score=avg_fisher_scores, sparsity=sparsity, mask_type=mask_type)\n",
    "mask = mask_dict_to_list(model, mask_dict)\n",
    "\n",
    "optimizer.set_mask(mask)"
   ],
   "id": "414e94656f0530c5",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define the Client, Server Apps",
   "id": "e73656b5d73ac995"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:52:31.568808Z",
     "start_time": "2025-05-15T14:52:31.083090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = get_client_app(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    "    partition_type=partition_type,\n",
    "    local_epochs=J,\n",
    "    batch_size=batch_size,\n",
    "    num_shards_per_partition=num_shards_per_partition,\n",
    "    scheduler=scheduler,\n",
    "    verbose=0,\n",
    "    model_editing=model_editing,\n",
    "    mask_type=mask_type,\n",
    "    sparsity=sparsity,\n",
    "    mask=mask\n",
    ")"
   ],
   "id": "70467a37aa8c09c7",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:52:32.382361Z",
     "start_time": "2025-05-15T14:52:31.569847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "server = get_server_app(checkpoint_dir=checkpoint_dir,\n",
    "                        model_class=model,\n",
    "                        optimizer=optimizer,\n",
    "                        criterion=criterion,\n",
    "                        scheduler=scheduler,\n",
    "                        num_rounds=num_rounds,\n",
    "                        fraction_fit=fraction_fit,\n",
    "                        fraction_evaluate=fraction_evaluate,\n",
    "                        min_fit_clients=min_fit_clients,\n",
    "                        min_evaluate_clients=min_evaluate_clients,\n",
    "                        min_available_clients=min_available_clients,\n",
    "                        device=device,\n",
    "                        use_wandb=use_wandb,\n",
    "                        wandb_config=wandb_config,\n",
    "                        save_every=save_every,\n",
    "                        prefix='fl_baseline'\n",
    "                        )"
   ],
   "id": "1cbac220e52a6d00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_75.pth\n",
      "📦 Model class in checkpoint: BaseDino\n",
      "🔧 Model configuration: {'variant': 'dino_vits16', 'dropout_rate': 0.0, 'head_hidden_size': 512, 'head_layers': 3, 'num_classes': 100, 'unfreeze_blocks': 1, 'activation_fn': 'GELU', 'pretrained': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️ Moved model to device: cuda\n",
      "✅ Loaded checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_75.pth, resuming at epoch 76\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Before training\n",
    "\n",
    "Test model performance before fine-turning"
   ],
   "id": "b0bed2551f5eeb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:52:33.419510Z",
     "start_time": "2025-05-15T14:52:32.384355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "testset = datasets.CIFAR100(RAW_DATA_DIR, train=False, download=True, transform=get_eval_transforms())\n",
    "testloader = DataLoader(testset, batch_size=32)"
   ],
   "id": "90f77fa322ad97c1",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:53:03.595276Z",
     "start_time": "2025-05-15T14:52:33.420341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss, test_accuracy, _ = eval(testloader, model, criterion)\n",
    "test_loss, test_accuracy"
   ],
   "id": "f9866d97ff7849c7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 313/313 [00:29<00:00, 10.54batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9389025029092551, 0.7398)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run the training\n",
   "id": "1427a966f7544b94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:53:04.096737Z",
     "start_time": "2025-05-15T14:53:03.597061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if DEVICE == \"cuda\":\n",
    "    backend_config[\"client_resources\"] = {\"num_cpus\": 1, \"num_gpus\": 0.5}\n",
    "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
    "    # and how to set up the `backend_config`"
   ],
   "id": "1388e3308f7b212b",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9a1db478a3e1221"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:57:34.855936Z",
     "start_time": "2025-05-15T14:53:04.097737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config\n",
    ")"
   ],
   "id": "1451e826d4713ec9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Server on device: cuda:0\n",
      "[Server] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      Starting Flower ServerApp, config: num_rounds=2, no round_timeout\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [INIT]\n",
      "\u001B[92mINFO \u001B[0m:      Using initial global parameters provided by strategy\n",
      "\u001B[92mINFO \u001B[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server Eval Round 0] Model device: cuda:0\n",
      "[Server Eval Round 0] CUDA available in server eval: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 313/313 [00:36<00:00,  8.65batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      [Round 0] Centralized Evaluation - Loss: 0.9389, Metrics: {'centralized_accuracy': 0.7398}\n",
      "\u001B[92mINFO \u001B[0m:      initial parameters (loss, other metrics): 0.9389025029092551, {'centralized_accuracy': 0.7398}\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 1]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "(ClientAppActor pid=19976) 2025-05-15 16:53:46.998 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=16612) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=16612) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=16612) No prefix/name for the model was provided, choosen prefix/name: dorky_pidgey_23\n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=19976) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=19976) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=16612) C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:217: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "(ClientAppActor pid=16612)   warnings.warn(\n",
      "(ClientAppActor pid=16612) 2025-05-15 16:53:47.101 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=16612) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.5368\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 85.00%\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.64s | ETA: 7.92s\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:54\n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) No prefix/name for the model was provided, choosen prefix/name: spooky_bulbasaur_32\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 3/4 (75.00%) Completed [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.5098 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 84.25% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.72s | ETA: 2.72s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:54 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=16612) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=16612) No prefix/name for the model was provided, choosen prefix/name: sneezy_pikachu_20\n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=19976) 🚀 Epoch 4/4 (100.00%) Completed [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) \t📊 Training Loss: 0.3846 [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) \t✅ Training Accuracy: 87.00% [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) \t⏳ Elapsed Time: 2.26s | ETA: 0.00s [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) \t🕒 Completed At: 16:54 [repeated 3x across cluster]\n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=19976) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=19976) No prefix/name for the model was provided, choosen prefix/name: bubbly_nidorino_39\n",
      "(ClientAppActor pid=16612) 🚀 Epoch 3/4 (75.00%) Completed [repeated 5x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.5909 [repeated 5x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 81.00% [repeated 5x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.13s | ETA: 2.13s [repeated 5x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:54 [repeated 5x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=16612) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=19976) No prefix/name for the model was provided, choosen prefix/name: peppy_pikachu_45\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 1/4 (25.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.4277 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 89.50% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.83s | ETA: 8.50s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:54 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=19976) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=16612) No prefix/name for the model was provided, choosen prefix/name: perky_pidgeotto_40\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 3/4 (75.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.4834 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 86.75% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.85s | ETA: 2.85s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:54 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=16612) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=16612) No prefix/name for the model was provided, choosen prefix/name: bouncy_venusaur_84\n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 1/4 (25.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.4373 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 89.75% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.91s | ETA: 8.73s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:54 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=19976) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=19976) No prefix/name for the model was provided, choosen prefix/name: zippy_arbok_43\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 3/4 (75.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.3117 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 89.50% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.92s | ETA: 2.92s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:54 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=19976) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=19976) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=16612) No prefix/name for the model was provided, choosen prefix/name: wacky_sandslash_20\n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) 🚀 Epoch 4/4 (100.00%) Completed [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) \t📊 Training Loss: 0.6883 [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) \t✅ Training Accuracy: 81.75% [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) \t⏳ Elapsed Time: 2.88s | ETA: 0.00s [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) \t🕒 Completed At: 16:54 [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=16612) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=19976) No prefix/name for the model was provided, choosen prefix/name: jumpy_nidorino_25\n",
      "(ClientAppActor pid=16612) 🚀 Epoch 2/4 (50.00%) Completed [repeated 3x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.5219 [repeated 3x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 82.75% [repeated 3x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 3.00s | ETA: 6.00s [repeated 3x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:54 [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 4/4 (100.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.5684 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 83.25% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.72s | ETA: 0.00s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:55 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      [Round 1] Avg Drift: 0.0312 | Relative Drift: 0.0001\n",
      "\u001B[92mINFO \u001B[0m:      [Round 1] Saving aggregated model at epoch 76...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved checkpoint at: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_76.pth\n",
      "[Server Eval Round 1] Model device: cuda:0\n",
      "[Server Eval Round 1] CUDA available in server eval: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 313/313 [00:30<00:00, 10.22batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      [Round 1] Centralized Evaluation - Loss: 0.9387, Metrics: {'centralized_accuracy': 0.7397}\n",
      "\u001B[92mINFO \u001B[0m:      fit progress: (1, 0.93871668519113, {'centralized_accuracy': 0.7397}, 113.69582900000387)\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=16612) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=16612) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=19976) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=19976) \t📊 Training Loss: 0.6556\n",
      "(ClientAppActor pid=19976) \t✅ Training Accuracy: 80.00%\n",
      "(ClientAppActor pid=19976) \t⏳ Elapsed Time: 2.72s | ETA: 0.00s\n",
      "(ClientAppActor pid=19976) \t🕒 Completed At: 16:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "(ClientAppActor pid=19976) C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:217: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "(ClientAppActor pid=19976)   warnings.warn(\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  1.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=16612) [Client] Client on device: cuda:0 [repeated 6x across cluster]\n",
      "(ClientAppActor pid=16612) [Client] CUDA available in client: True [repeated 6x across cluster]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 6x across cluster]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  1.59batch/s] [repeated 5x across cluster]\n",
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 2]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=16612) No prefix/name for the model was provided, choosen prefix/name: snazzy_raticate_57\n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.3898\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 87.50%\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.72s | ETA: 8.16s\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:55\n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) [Client] Client on device: cuda:0 [repeated 5x across cluster]\n",
      "(ClientAppActor pid=19976) [Client] CUDA available in client: True [repeated 5x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) No prefix/name for the model was provided, choosen prefix/name: zany_charizard_58\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 3/4 (75.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.2610 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 90.75% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.62s | ETA: 2.62s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:55 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=16612) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=16612) No prefix/name for the model was provided, choosen prefix/name: quirky_bulbasaur_54\n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 1/4 (25.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.6340 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 82.50% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.67s | ETA: 8.01s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:56 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=19976) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=19976) No prefix/name for the model was provided, choosen prefix/name: soggy_pidgeotto_84\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 3/4 (75.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.6164 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 80.75% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.62s | ETA: 2.62s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:56 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=16612) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=16612) No prefix/name for the model was provided, choosen prefix/name: breezy_squirtle_98\n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 1/4 (25.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.3603 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 88.25% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.95s | ETA: 8.85s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:56 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=19976) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=19976) No prefix/name for the model was provided, choosen prefix/name: jolly_kakuna_47\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 3/4 (75.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.3990 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 90.50% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.83s | ETA: 2.83s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:56 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=16612) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=16612) No prefix/name for the model was provided, choosen prefix/name: cranky_caterpie_25\n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 1/4 (25.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.5108 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 82.00% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.92s | ETA: 8.77s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:56 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=19976) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=19976) No prefix/name for the model was provided, choosen prefix/name: snazzy_pidgey_82\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 3/4 (75.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.5098 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 81.25% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.91s | ETA: 2.91s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:56 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=16612) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=16612) No prefix/name for the model was provided, choosen prefix/name: nutty_clefairy_65\n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 1/4 (25.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.5596 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 82.00% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.77s | ETA: 8.32s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:56 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=19976) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=19976) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=19976) No prefix/name for the model was provided, choosen prefix/name: funky_beedrill_19\n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=16612) 🚀 Epoch 3/4 (75.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t📊 Training Loss: 0.5965 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t✅ Training Accuracy: 83.00% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t⏳ Elapsed Time: 2.78s | ETA: 2.78s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=16612) \t🕒 Completed At: 16:56 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=19976) \n",
      "(ClientAppActor pid=16612) \n",
      "(ClientAppActor pid=19976) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      [Round 2] Avg Drift: 0.0334 | Relative Drift: 0.0001\n",
      "\u001B[92mINFO \u001B[0m:      [Round 2] Saving aggregated model at epoch 77...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved checkpoint at: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_77.pth\n",
      "[Server Eval Round 2] Model device: cuda:0\n",
      "[Server Eval Round 2] CUDA available in server eval: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 313/313 [00:30<00:00, 10.35batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      [Round 2] Centralized Evaluation - Loss: 0.9385, Metrics: {'centralized_accuracy': 0.7398}\n",
      "\u001B[92mINFO \u001B[0m:      fit progress: (2, 0.9384764046333849, {'centralized_accuracy': 0.7398}, 220.40991240000585)\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=16612) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=16612) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=19976) 🚀 Epoch 4/4 (100.00%) Completed [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) \t📊 Training Loss: 0.7052 [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) \t✅ Training Accuracy: 78.50% [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) \t⏳ Elapsed Time: 2.82s | ETA: 0.00s [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) \t🕒 Completed At: 16:56 [repeated 3x across cluster]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 4x across cluster]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  1.60batch/s] [repeated 4x across cluster]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=16612) [Client] Client on device: cuda:0 [repeated 6x across cluster]\n",
      "(ClientAppActor pid=16612) [Client] CUDA available in client: True [repeated 6x across cluster]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 6x across cluster]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  1.60batch/s] [repeated 6x across cluster]\n",
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [SUMMARY]\n",
      "\u001B[92mINFO \u001B[0m:      Run finished 2 round(s) in 230.85s\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, distributed):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 0.9718967080116272\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 0.9135420501232148\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, centralized):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 0: 0.9389025029092551\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 0.93871668519113\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 0.9384764046333849\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, distributed, fit):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'avg_drift': [(1, 0.031229414977133274), (2, 0.033368970081210134)],\n",
      "\u001B[92mINFO \u001B[0m:      \t 'avg_train_loss': [(1, 0.4946932760998607), (2, 0.5839086569845676)]}\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'decentralized_avg_eval_accuracy': [(1, 0.733), (2, 0.748)]}\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, centralized):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'centralized_accuracy': [(0, 0.7398), (1, 0.7397), (2, 0.7398)]}\n",
      "\u001B[92mINFO \u001B[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=19976) [Client] Client on device: cuda:0 [repeated 3x across cluster]\n",
      "(ClientAppActor pid=19976) [Client] CUDA available in client: True [repeated 3x across cluster]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 3x across cluster]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  1.75batch/s] [repeated 4x across cluster]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T14:57:34.871825Z",
     "start_time": "2025-05-15T14:57:34.859935Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "36857bb14d6fe5f1",
   "outputs": [],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
