{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:01.838181Z",
     "start_time": "2025-05-14T16:23:01.749932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "5767f6b1a63e945b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:03.518716Z",
     "start_time": "2025-05-14T16:23:01.839141Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
   "id": "75ca9d6d54c4ce47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:13.067966Z",
     "start_time": "2025-05-14T16:23:03.519699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import flwr\n",
    "import torch\n",
    "from flwr.simulation import run_simulation\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "from fl_g13.architectures import BaseDino\n",
    "from fl_g13.config import RAW_DATA_DIR\n",
    "from fl_g13.editing import SparseSGDM\n",
    "from fl_g13.fl_pytorch.client_app import get_client_app\n",
    "from fl_g13.fl_pytorch.datasets import get_eval_transforms\n",
    "from fl_g13.fl_pytorch.server_app import get_server_app\n",
    "from fl_g13.modeling.eval import eval"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-05-14 18:23:08.745\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mfl_g13.config\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m11\u001B[0m - \u001B[1mPROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:13.558075Z",
     "start_time": "2025-05-14T16:23:13.069114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# DEVICE = \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "# disable_progress_bar()"
   ],
   "id": "1a4ec3eb7baf32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Flower 1.17.0 / PyTorch 2.6.0+cu118\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Login wandb",
   "id": "73fb84b164b0def7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:15.283183Z",
     "start_time": "2025-05-14T16:23:13.559058Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install wandb",
   "id": "6c6449ef9be1e422",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (0.19.9)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (68.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (4.13.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:15.725054Z",
     "start_time": "2025-05-14T16:23:15.284063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## read .env file\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n"
   ],
   "id": "5f279490dd7a970f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:17.153402Z",
     "start_time": "2025-05-14T16:23:15.725960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "# login by key in .env file\n",
    "WANDB_API_KEY = dotenv.dotenv_values()[\"WANDB_API_KEY\"]\n",
    "wandb.login(key=WANDB_API_KEY)"
   ],
   "id": "a218d880822fdfba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\notebook\\utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  return LooseVersion(v) >= LooseVersion(check)\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\ADMIN\\_netrc\n",
      "wandb: Currently logged in as: thanhnv-it23 (stefano-gamba-social-politecnico-di-torino) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build module local\n",
    "\n",
    "Build module local such that ClientApp can use it"
   ],
   "id": "b5a0319c8e40215a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:22.296913Z",
     "start_time": "2025-05-14T16:23:17.154359Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -e ..",
   "id": "8a11402a3317027f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/ADMIN/Desktop/BACKUP/study/Italy/polito/classes/20242/deep%20learning/project/source_code/fl-g13"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies: started"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checking if build backend supports build_editable: finished with status 'done'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[notice] To update, run: python.exe -m pip install --upgrade pip"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: fl_g13\n",
      "  Building editable for fl_g13 (pyproject.toml): started\n",
      "  Building editable for fl_g13 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for fl_g13: filename=fl_g13-0.0.1-py3-none-any.whl size=4649 sha256=a588eeccbccdbea56dbfe92e55bd612babd81e07366f39e361ccc99a5ffdec08\n",
      "  Stored in directory: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-24s7s6ts\\wheels\\b7\\e0\\6d\\5d22ced2ef400b314cfe74883357cc37e1e1d5275e7ba9175e\n",
      "Successfully built fl_g13\n",
      "Installing collected packages: fl_g13\n",
      "  Attempting uninstall: fl_g13\n",
      "    Found existing installation: fl_g13 0.0.1\n",
      "    Uninstalling fl_g13-0.0.1:\n",
      "      Successfully uninstalled fl_g13-0.0.1\n",
      "Successfully installed fl_g13-0.0.1\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Download missing module for clients\n",
    "\n",
    "Dino model,that is serialized and sent to client by server, require some modules that have to download from source code of dino model\n"
   ],
   "id": "9399f1a9cedc8cc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:22.835746Z",
     "start_time": "2025-05-14T16:23:22.298913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def download_if_not_exists(file_path: str, file_url: str):\n",
    "    \"\"\"\n",
    "    Checks if a file exists at the given path. If it does not, downloads it from the specified URL.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The local path to check and save the file.\n",
    "    - file_url (str): The URL from which to download the file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"'{file_path}' not found. Downloading from {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "            print(\"Download complete.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download file: {e}\")\n",
    "    else:\n",
    "        print(f\"'{file_path}' already exists.\")"
   ],
   "id": "beb2c855fcd8933c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:23.324236Z",
     "start_time": "2025-05-14T16:23:22.836731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "download_if_not_exists(\"vision_transformer.py\",\n",
    "                       \"https://raw.githubusercontent.com/facebookresearch/dino/refs/heads/main/vision_transformer.py\")\n",
    "download_if_not_exists(\"utils.py\",\n",
    "                       \"https://raw.githubusercontent.com/facebookresearch/dino/refs/heads/main/utils.py\")\n"
   ],
   "id": "d93caca63a33c71f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'vision_transformer.py' already exists.\n",
      "'utils.py' already exists.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FL",
   "id": "ee82432353abfbe2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configs",
   "id": "cdb05316b163821b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:23.793346Z",
     "start_time": "2025-05-14T16:23:23.325250Z"
    }
   },
   "cell_type": "code",
   "source": "DEBUG = True",
   "id": "6ba4f53af219c423",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:24.266183Z",
     "start_time": "2025-05-14T16:23:23.794334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model config\n",
    "\n",
    "## Model Hyper-parameters\n",
    "head_layers = 3\n",
    "head_hidden_size = 512\n",
    "dropout_rate = 0.0\n",
    "unfreeze_blocks = 1\n",
    "\n",
    "## Training Hyper-parameters\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-5\n",
    "T_max = 8\n",
    "eta_min = 1e-5\n",
    "\n",
    "# FL config\n",
    "K = 100\n",
    "C = 0.1\n",
    "J = 4\n",
    "num_rounds = 30\n",
    "partition_type = 'iid'\n",
    "\n",
    "## only for partition_type = 'shard'\n",
    "num_shards_per_partition = 10\n",
    "\n",
    "## Server App config\n",
    "save_every = 1\n",
    "fraction_fit = C  # Sample of available clients for training\n",
    "fraction_evaluate = 0.1  # Sample 50% of available clients for evaluation\n",
    "min_fit_clients = 10  # Never sample less than 10 clients for training\n",
    "min_evaluate_clients = 5  # Never sample less than 5 clients for evaluation\n",
    "min_available_clients = 10  # Wait until all 10 clients are available\n",
    "device = DEVICE\n",
    "## checkpoints directory\n",
    "current_path = Path.cwd()\n",
    "model_save_path = current_path / f\"../models/fl_dino_baseline/{partition_type}\"\n",
    "checkpoint_dir = model_save_path.resolve()\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "## Wandb config\n",
    "use_wandb = True\n",
    "wandb_config = {\n",
    "    # wandb param\n",
    "    'name': 'FL_Dino_Baseline_iid',\n",
    "    'project_name': \"FL_test_chart\",\n",
    "    # model config param\n",
    "    \"fraction_fit\": fraction_fit,\n",
    "    \"lr\": lr,\n",
    "    \"momentum\": momentum,\n",
    "    'partition_type': partition_type,\n",
    "    'K': K,\n",
    "    'C': C,\n",
    "    'J': J,\n",
    "}\n",
    "\n",
    "# model editing config\n",
    "model_editing = True\n",
    "mask_type = 'global'\n",
    "sparsity = 0.2\n",
    "mask = None\n",
    "\n",
    "## simulation run config\n",
    "NUM_CLIENTS = 100\n",
    "MAX_PARALLEL_CLIENTS = 10\n",
    "\n",
    "if DEBUG:\n",
    "    use_wandb = False\n",
    "    num_rounds = 2\n",
    "    J = 4\n"
   ],
   "id": "d63bb533ec30809b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define model , optimizer and loss function",
   "id": "4c0f23c3615c6d68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:25.430121Z",
     "start_time": "2025-05-14T16:23:24.267167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fl_g13.modeling import load_or_create\n",
    "\n",
    "# Model\n",
    "model, start_epoch = load_or_create(\n",
    "        path=checkpoint_dir,\n",
    "        model_class=BaseDino,\n",
    "        model_config=None,\n",
    "        optimizer=None,\n",
    "        scheduler=None,\n",
    "        device=device,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# Create a dummy mask for SparseSGDM\n",
    "init_mask = [torch.ones_like(p, device=p.device) for p in\n",
    "             model.parameters()]  # Must be done AFTER the model is moved to the device\n",
    "# Optimizer, scheduler, and loss function\n",
    "optimizer = SparseSGDM(\n",
    "    model.parameters(),\n",
    "    mask=init_mask,\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer=optimizer,\n",
    "    T_max=T_max,\n",
    "    eta_min=eta_min\n",
    ")"
   ],
   "id": "9046d19b28a38ed3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_73.pth\n",
      "📦 Model class in checkpoint: BaseDino\n",
      "🔧 Model configuration: {'variant': 'dino_vits16', 'dropout_rate': 0.0, 'head_hidden_size': 512, 'head_layers': 3, 'num_classes': 100, 'unfreeze_blocks': 1, 'activation_fn': 'GELU', 'pretrained': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n",
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️ Moved model to device: cuda\n",
      "✅ Loaded checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_73.pth, resuming at epoch 74\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define the Client, Server Apps",
   "id": "e73656b5d73ac995"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:25.887780Z",
     "start_time": "2025-05-14T16:23:25.432104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = get_client_app(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    "    partition_type=partition_type,\n",
    "    local_epochs=J,\n",
    "    batch_size=batch_size,\n",
    "    num_shards_per_partition=num_shards_per_partition,\n",
    "    scheduler=scheduler,\n",
    "    verbose=0,\n",
    "    model_editing=model_editing,\n",
    "    mask_type=mask_type,\n",
    "    sparsity=sparsity,\n",
    "    mask=mask\n",
    ")"
   ],
   "id": "70467a37aa8c09c7",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:26.646195Z",
     "start_time": "2025-05-14T16:23:25.888609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "server = get_server_app(checkpoint_dir=checkpoint_dir,\n",
    "                        model_class=model,\n",
    "                        optimizer=optimizer,\n",
    "                        criterion=criterion,\n",
    "                        scheduler=scheduler,\n",
    "                        num_rounds=num_rounds,\n",
    "                        fraction_fit=fraction_fit,\n",
    "                        fraction_evaluate=fraction_evaluate,\n",
    "                        min_fit_clients=min_fit_clients,\n",
    "                        min_evaluate_clients=min_evaluate_clients,\n",
    "                        min_available_clients=min_available_clients,\n",
    "                        device=device,\n",
    "                        use_wandb=use_wandb,\n",
    "                        wandb_config=wandb_config,\n",
    "                        save_every=save_every,\n",
    "                        prefix='fl_baseline'\n",
    "                        )"
   ],
   "id": "1cbac220e52a6d00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_73.pth\n",
      "📦 Model class in checkpoint: BaseDino\n",
      "🔧 Model configuration: {'variant': 'dino_vits16', 'dropout_rate': 0.0, 'head_hidden_size': 512, 'head_layers': 3, 'num_classes': 100, 'unfreeze_blocks': 1, 'activation_fn': 'GELU', 'pretrained': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️ Moved model to device: cuda\n",
      "✅ Loaded checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_73.pth, resuming at epoch 74\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Before training\n",
    "\n",
    "Test model performance before fine-turning"
   ],
   "id": "b0bed2551f5eeb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:27.640007Z",
     "start_time": "2025-05-14T16:23:26.647177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "testset = datasets.CIFAR100(RAW_DATA_DIR, train=False, download=True, transform=get_eval_transforms())\n",
    "testloader = DataLoader(testset, batch_size=32)"
   ],
   "id": "90f77fa322ad97c1",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:57.427455Z",
     "start_time": "2025-05-14T16:23:27.641011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss, test_accuracy, _ = eval(testloader, model, criterion)\n",
    "test_loss, test_accuracy"
   ],
   "id": "f9866d97ff7849c7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 313/313 [00:29<00:00, 10.68batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9482528897710502, 0.7367)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run the training\n",
   "id": "1427a966f7544b94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:23:57.886103Z",
     "start_time": "2025-05-14T16:23:57.428543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if DEVICE == \"cuda\":\n",
    "    backend_config[\"client_resources\"] = {\"num_cpus\": 1, \"num_gpus\": 0.5}\n",
    "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
    "    # and how to set up the `backend_config`"
   ],
   "id": "1388e3308f7b212b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9a1db478a3e1221"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T16:28:18.687411Z",
     "start_time": "2025-05-14T16:23:57.886103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config\n",
    ")"
   ],
   "id": "1451e826d4713ec9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Server on device: cuda:0\n",
      "[Server] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      Starting Flower ServerApp, config: num_rounds=2, no round_timeout\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [INIT]\n",
      "\u001B[92mINFO \u001B[0m:      Using initial global parameters provided by strategy\n",
      "\u001B[92mINFO \u001B[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server Eval Round 0] Model device: cuda:0\n",
      "[Server Eval Round 0] CUDA available in server eval: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 313/313 [00:32<00:00,  9.49batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      [Round 0] Centralized Evaluation - Loss: 0.9483, Metrics: {'centralized_accuracy': 0.7367}\n",
      "\u001B[92mINFO \u001B[0m:      initial parameters (loss, other metrics): 0.9482528897710502, {'centralized_accuracy': 0.7367}\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 1]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "(ClientAppActor pid=12852) 2025-05-14 18:24:35.981 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=12852) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=12852) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "(ClientAppActor pid=5820) 2025-05-14 18:24:35.981 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  1.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) No prefix/name for the model was provided, choosen prefix/name: spunky_weedle_66\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=5820) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=5820) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=12852) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:217: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "(ClientAppActor pid=5820)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=5820) \t📊 Training Loss: 0.6040\n",
      "(ClientAppActor pid=5820) \t✅ Training Accuracy: 79.50%\n",
      "(ClientAppActor pid=5820) \t⏳ Elapsed Time: 1.93s | ETA: 5.78s\n",
      "(ClientAppActor pid=5820) \t🕒 Completed At: 18:24\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) No prefix/name for the model was provided, choosen prefix/name: dorky_clefairy_84\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 3/4 (75.00%) Completed [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.7480 [repeated 5x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 77.75% [repeated 5x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 2.32s | ETA: 2.32s [repeated 5x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:24 [repeated 5x across cluster]\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 2x across cluster]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  1.30batch/s]\n",
      "(ClientAppActor pid=12852) C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:217: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "(ClientAppActor pid=12852)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=5820) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) No prefix/name for the model was provided, choosen prefix/name: zippy_nidoran_34\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 1/4 (25.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.5119 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 83.75% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 2.61s | ETA: 7.82s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:25 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=12852) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=12852) No prefix/name for the model was provided, choosen prefix/name: peppy_nidoqueen_84\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 3/4 (75.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.4835 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 85.50% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 2.65s | ETA: 2.65s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:25 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 2x across cluster]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  8.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=5820) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) No prefix/name for the model was provided, choosen prefix/name: funky_bulbasaur_60\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 1/4 (25.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.4868 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 87.25% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 2.16s | ETA: 6.49s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:25 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=12852) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=12852) No prefix/name for the model was provided, choosen prefix/name: plucky_blastoise_44\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 4/4 (100.00%) Completed [repeated 6x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.4493 [repeated 6x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 89.25% [repeated 6x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 1.41s | ETA: 0.00s [repeated 6x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:25 [repeated 6x across cluster]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 2x across cluster]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  8.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=5820) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  6.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) No prefix/name for the model was provided, choosen prefix/name: funky_butterfree_32\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 2/4 (50.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.6392 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 77.50% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 2.09s | ETA: 4.19s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:25 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=12852) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=12852) No prefix/name for the model was provided, choosen prefix/name: fluffy_beedrill_87\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 2x across cluster]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  8.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=5820) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) No prefix/name for the model was provided, choosen prefix/name: peppy_venusaur_54\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 4/4 (100.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.6396 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 80.00% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 1.43s | ETA: 0.00s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:25 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=12852) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=12852) No prefix/name for the model was provided, choosen prefix/name: cranky_nidoking_81\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 3/4 (75.00%) Completed [repeated 6x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.8737 [repeated 6x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 76.25% [repeated 6x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 2.14s | ETA: 2.14s [repeated 6x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:25 [repeated 6x across cluster]\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      [Round 1] Avg Drift: 0.1141 | Relative Drift: 0.0002\n",
      "\u001B[92mINFO \u001B[0m:      [Round 1] Saving aggregated model at epoch 74...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved checkpoint at: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_74.pth\n",
      "[Server Eval Round 1] Model device: cuda:0\n",
      "[Server Eval Round 1] CUDA available in server eval: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 313/313 [00:30<00:00, 10.19batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      [Round 1] Centralized Evaluation - Loss: 0.9425, Metrics: {'centralized_accuracy': 0.7373}\n",
      "\u001B[92mINFO \u001B[0m:      fit progress: (1, 0.9425141271977379, {'centralized_accuracy': 0.7373}, 100.22247920000154)\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=12852) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=12852) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=12852) 🚀 Epoch 4/4 (100.00%) Completed [repeated 2x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.7315 [repeated 2x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 78.75% [repeated 2x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 1.31s | ETA: 0.00s [repeated 2x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:25 [repeated 2x across cluster]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 2x across cluster]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  8.27batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.19batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  2.25batch/s]\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 2x across cluster]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.38batch/s] [repeated 2x across cluster]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 5x across cluster]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.52batch/s] [repeated 5x across cluster]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) [Client] Client on device: cuda:0 [repeated 6x across cluster]\n",
      "(ClientAppActor pid=5820) [Client] CUDA available in client: True [repeated 6x across cluster]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 2]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=12852) [Client] Client on device: cuda:0 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) [Client] CUDA available in client: True [repeated 4x across cluster]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 5x across cluster]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  8.21batch/s] [repeated 4x across cluster]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 4x across cluster]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  1.58batch/s] [repeated 4x across cluster]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=12852) No prefix/name for the model was provided, choosen prefix/name: zippy_spearow_50\n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=5820) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=5820) \t📊 Training Loss: 0.4603\n",
      "(ClientAppActor pid=5820) \t✅ Training Accuracy: 88.25%\n",
      "(ClientAppActor pid=5820) \t⏳ Elapsed Time: 2.83s | ETA: 8.49s\n",
      "(ClientAppActor pid=5820) \t🕒 Completed At: 18:26\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=5820) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=5820) No prefix/name for the model was provided, choosen prefix/name: soggy_wartortle_32\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 3/4 (75.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.3724 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 85.50% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 2.85s | ETA: 2.85s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:26 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 2x across cluster]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.50batch/s] [repeated 2x across cluster]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=12852) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=12852) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=12852) No prefix/name for the model was provided, choosen prefix/name: loopy_blastoise_92\n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) 🚀 Epoch 4/4 (100.00%) Completed [repeated 3x across cluster]\n",
      "(ClientAppActor pid=5820) \t📊 Training Loss: 0.2891 [repeated 3x across cluster]\n",
      "(ClientAppActor pid=5820) \t✅ Training Accuracy: 91.75% [repeated 3x across cluster]\n",
      "(ClientAppActor pid=5820) \t⏳ Elapsed Time: 2.94s | ETA: 0.00s [repeated 3x across cluster]\n",
      "(ClientAppActor pid=5820) \t🕒 Completed At: 18:26 [repeated 3x across cluster]\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=5820) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=5820) No prefix/name for the model was provided, choosen prefix/name: sneezy_raticate_93\n",
      "(ClientAppActor pid=12852) 🚀 Epoch 2/4 (50.00%) Completed [repeated 3x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.6479 [repeated 3x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 79.50% [repeated 3x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 2.90s | ETA: 5.79s [repeated 3x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:26 [repeated 3x across cluster]\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 4/4 (100.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.5739 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 80.25% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 3.09s | ETA: 0.00s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:26 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=5820) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 2x across cluster]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.15batch/s] [repeated 2x across cluster]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=12852) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=12852) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=12852) No prefix/name for the model was provided, choosen prefix/name: zippy_charmander_14\n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 1/4 (25.00%) Completed [repeated 2x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.2881 [repeated 2x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 91.25% [repeated 2x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 2.99s | ETA: 8.98s [repeated 2x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:26 [repeated 2x across cluster]\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=5820) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=5820) No prefix/name for the model was provided, choosen prefix/name: fluffy_pidgeot_57\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 3/4 (75.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.2639 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 91.75% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 2.82s | ETA: 2.82s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:27 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 2x across cluster]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.26batch/s] [repeated 2x across cluster]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=12852) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=12852) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=5820) No prefix/name for the model was provided, choosen prefix/name: perky_butterfree_18\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) 🚀 Epoch 4/4 (100.00%) Completed [repeated 3x across cluster]\n",
      "(ClientAppActor pid=5820) \t📊 Training Loss: 0.4256 [repeated 3x across cluster]\n",
      "(ClientAppActor pid=5820) \t✅ Training Accuracy: 84.75% [repeated 3x across cluster]\n",
      "(ClientAppActor pid=5820) \t⏳ Elapsed Time: 2.87s | ETA: 0.00s [repeated 3x across cluster]\n",
      "(ClientAppActor pid=5820) \t🕒 Completed At: 18:27 [repeated 3x across cluster]\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=5820) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=5820) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=12852) No prefix/name for the model was provided, choosen prefix/name: itchy_charmeleon_79\n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 2/4 (50.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.4830 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 87.00% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 2.70s | ETA: 5.40s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:27 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 4/4 (100.00%) Completed [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.3626 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 88.00% [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 2.34s | ETA: 0.00s [repeated 4x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:27 [repeated 4x across cluster]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=5820) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  6.14batch/s]\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) No prefix/name for the model was provided, choosen prefix/name: cranky_sandslash_44\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) 🚀 Epoch 1/4 (25.00%) Completed [repeated 2x across cluster]\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.7032 [repeated 2x across cluster]\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 79.75% [repeated 2x across cluster]\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 2.40s | ETA: 7.19s [repeated 2x across cluster]\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:27 [repeated 2x across cluster]\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=12852) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=12852) No prefix/name for the model was provided, choosen prefix/name: sleepy_nidorina_90\n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=12852) \n",
      "(ClientAppActor pid=5820) \n",
      "(ClientAppActor pid=5820) 🚀 Epoch 4/4 (100.00%) Completed [repeated 5x across cluster]\n",
      "(ClientAppActor pid=5820) \t📊 Training Loss: 0.4539 [repeated 5x across cluster]\n",
      "(ClientAppActor pid=5820) \t✅ Training Accuracy: 84.50% [repeated 5x across cluster]\n",
      "(ClientAppActor pid=5820) \t⏳ Elapsed Time: 2.25s | ETA: 0.00s [repeated 5x across cluster]\n",
      "(ClientAppActor pid=5820) \t🕒 Completed At: 18:27 [repeated 5x across cluster]\n",
      "(ClientAppActor pid=12852) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      [Round 2] Avg Drift: 0.1086 | Relative Drift: 0.0002\n",
      "\u001B[92mINFO \u001B[0m:      [Round 2] Saving aggregated model at epoch 75...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved checkpoint at: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_75.pth\n",
      "[Server Eval Round 2] Model device: cuda:0\n",
      "[Server Eval Round 2] CUDA available in server eval: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 313/313 [00:29<00:00, 10.47batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      [Round 2] Centralized Evaluation - Loss: 0.9389, Metrics: {'centralized_accuracy': 0.7398}\n",
      "\u001B[92mINFO \u001B[0m:      fit progress: (2, 0.9389025029092551, {'centralized_accuracy': 0.7398}, 210.93392680000034)\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.71batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=12852) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=12852) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=12852) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=12852) \t📊 Training Loss: 0.5341\n",
      "(ClientAppActor pid=12852) \t✅ Training Accuracy: 82.75%\n",
      "(ClientAppActor pid=12852) \t⏳ Elapsed Time: 1.91s | ETA: 0.00s\n",
      "(ClientAppActor pid=12852) \t🕒 Completed At: 18:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.55batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  1.60batch/s]\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 3x across cluster]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.19batch/s] [repeated 3x across cluster]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=5820) [Client] Client on device: cuda:0 [repeated 4x across cluster]\n",
      "(ClientAppActor pid=5820) [Client] CUDA available in client: True [repeated 4x across cluster]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 3x across cluster]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  1.51batch/s] [repeated 3x across cluster]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=12852) [Client] Client on device: cuda:0 [repeated 5x across cluster]\n",
      "(ClientAppActor pid=12852) [Client] CUDA available in client: True [repeated 5x across cluster]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 4x across cluster]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.04batch/s] [repeated 4x across cluster]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 4x across cluster]\n",
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "(ClientAppActor pid=12852)\u001B[92mINFO \u001B[0m:      [SUMMARY]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.10batch/s]\u001B[92mINFO \u001B[0m:      Run finished 2 round(s) in 224.53s\n",
      " [repeated 6x across cluster]\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, distributed):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 0.9027259171009063\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 0.9887704610824585\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, centralized):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 0: 0.9482528897710502\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 0.9425141271977379\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 0.9389025029092551\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, distributed, fit):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'avg_drift': [(1, 0.11413903683423995), (2, 0.10861288532614707)],\n",
      "\u001B[92mINFO \u001B[0m:      \t 'avg_train_loss': [(1, 0.5461518630385399), (2, 0.42265024073421953)]}\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'decentralized_avg_eval_accuracy': [(1, 0.727), (2, 0.732)]}\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, centralized):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'centralized_accuracy': [(0, 0.7367), (1, 0.7373), (2, 0.7398)]}\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.64batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s] [repeated 2x across cluster]\n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
