{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:51:54.874416Z",
     "start_time": "2025-05-14T14:51:54.772519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "5767f6b1a63e945b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:51:56.791678Z",
     "start_time": "2025-05-14T14:51:54.876549Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
   "id": "75ca9d6d54c4ce47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (4.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:53:15.131199Z",
     "start_time": "2025-05-14T14:53:14.571597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import flwr\n",
    "import torch\n",
    "from flwr.simulation import run_simulation\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "from fl_g13.architectures import BaseDino\n",
    "from fl_g13.config import RAW_DATA_DIR\n",
    "from fl_g13.editing import SparseSGDM\n",
    "from fl_g13.fl_pytorch.client_app import get_client_app\n",
    "from fl_g13.fl_pytorch.datasets import get_eval_transforms\n",
    "from fl_g13.fl_pytorch.server_app import get_server_app\n",
    "from fl_g13.modeling.eval import eval"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:52:10.405379Z",
     "start_time": "2025-05-14T14:52:09.758997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# DEVICE = \"cpu\"\n",
    "print(f\"Training on {DEVICE}\")\n",
    "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
    "# disable_progress_bar()"
   ],
   "id": "1a4ec3eb7baf32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda\n",
      "Flower 1.17.0 / PyTorch 2.6.0+cu118\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Login wandb",
   "id": "73fb84b164b0def7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:52:12.300810Z",
     "start_time": "2025-05-14T14:52:10.405379Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install wandb",
   "id": "6c6449ef9be1e422",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (0.19.9)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (68.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from wandb) (4.13.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:52:12.824117Z",
     "start_time": "2025-05-14T14:52:12.300810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## read .env file\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n"
   ],
   "id": "5f279490dd7a970f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:52:14.446080Z",
     "start_time": "2025-05-14T14:52:12.824117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "# login by key in .env file\n",
    "WANDB_API_KEY = dotenv.dotenv_values()[\"WANDB_API_KEY\"]\n",
    "wandb.login(key=WANDB_API_KEY)"
   ],
   "id": "a218d880822fdfba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\notebook\\utils.py:280: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  return LooseVersion(v) >= LooseVersion(check)\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\ADMIN\\_netrc\n",
      "wandb: Currently logged in as: thanhnv-it23 (stefano-gamba-social-politecnico-di-torino) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build module local\n",
    "\n",
    "Build module local such that ClientApp can use it"
   ],
   "id": "b5a0319c8e40215a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:10:04.320911Z",
     "start_time": "2025-05-14T15:09:56.894962Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install -e ..",
   "id": "8a11402a3317027f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/ADMIN/Desktop/BACKUP/study/Italy/polito/classes/20242/deep%20learning/project/source_code/fl-g13"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies: started"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -otebook (c:\\users\\admin\\desktop\\backup\\study\\italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies: finished with status 'done'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Checking if build backend supports build_editable: started"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[notice] To update, run: python.exe -m pip install --upgrade pip"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Checking if build backend supports build_editable: finished with status 'done'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: fl_g13\n",
      "  Building editable for fl_g13 (pyproject.toml): started\n",
      "  Building editable for fl_g13 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for fl_g13: filename=fl_g13-0.0.1-py3-none-any.whl size=4649 sha256=a588eeccbccdbea56dbfe92e55bd612babd81e07366f39e361ccc99a5ffdec08\n",
      "  Stored in directory: C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-auar90en\\wheels\\b7\\e0\\6d\\5d22ced2ef400b314cfe74883357cc37e1e1d5275e7ba9175e\n",
      "Successfully built fl_g13\n",
      "Installing collected packages: fl_g13\n",
      "  Attempting uninstall: fl_g13\n",
      "    Found existing installation: fl_g13 0.0.1\n",
      "    Uninstalling fl_g13-0.0.1:\n",
      "      Successfully uninstalled fl_g13-0.0.1\n",
      "Successfully installed fl_g13-0.0.1\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Download missing module for clients\n",
    "\n",
    "Dino model,that is serialized and sent to client by server, require some modules that have to download from source code of dino model\n"
   ],
   "id": "9399f1a9cedc8cc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:52:21.295480Z",
     "start_time": "2025-05-14T14:52:20.682745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "def download_if_not_exists(file_path: str, file_url: str):\n",
    "    \"\"\"\n",
    "    Checks if a file exists at the given path. If it does not, downloads it from the specified URL.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path (str): The local path to check and save the file.\n",
    "    - file_url (str): The URL from which to download the file.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"'{file_path}' not found. Downloading from {file_url}...\")\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "            print(\"Download complete.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download file: {e}\")\n",
    "    else:\n",
    "        print(f\"'{file_path}' already exists.\")"
   ],
   "id": "beb2c855fcd8933c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:52:21.784746Z",
     "start_time": "2025-05-14T14:52:21.296481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "download_if_not_exists(\"vision_transformer.py\",\n",
    "                       \"https://raw.githubusercontent.com/facebookresearch/dino/refs/heads/main/vision_transformer.py\")\n",
    "download_if_not_exists(\"utils.py\",\n",
    "                       \"https://raw.githubusercontent.com/facebookresearch/dino/refs/heads/main/utils.py\")\n"
   ],
   "id": "d93caca63a33c71f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'vision_transformer.py' already exists.\n",
      "'utils.py' already exists.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FL",
   "id": "ee82432353abfbe2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configs",
   "id": "cdb05316b163821b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:52:22.272714Z",
     "start_time": "2025-05-14T14:52:21.785746Z"
    }
   },
   "cell_type": "code",
   "source": "DEBUG = True",
   "id": "6ba4f53af219c423",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:00:29.968684Z",
     "start_time": "2025-05-14T15:00:28.286690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model config\n",
    "\n",
    "## Model Hyper-parameters\n",
    "head_layers = 3\n",
    "head_hidden_size = 512\n",
    "dropout_rate = 0.0\n",
    "unfreeze_blocks = 1\n",
    "\n",
    "## Training Hyper-parameters\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-5\n",
    "T_max = 8\n",
    "eta_min = 1e-5\n",
    "\n",
    "# FL config\n",
    "K = 100\n",
    "C = 0.1\n",
    "J = 4\n",
    "num_rounds = 30\n",
    "partition_type = 'iid'\n",
    "\n",
    "## only for partition_type = 'shard'\n",
    "num_shards_per_partition = 10\n",
    "\n",
    "## Server App config\n",
    "save_every = 1\n",
    "fraction_fit = C  # Sample of available clients for training\n",
    "fraction_evaluate = 0.1  # Sample 50% of available clients for evaluation\n",
    "min_fit_clients = 10  # Never sample less than 10 clients for training\n",
    "min_evaluate_clients = 5  # Never sample less than 5 clients for evaluation\n",
    "min_available_clients = 10  # Wait until all 10 clients are available\n",
    "device = DEVICE\n",
    "## checkpoints directory\n",
    "current_path = Path.cwd()\n",
    "model_save_path = current_path / f\"../models/fl_dino_baseline/{partition_type}\"\n",
    "checkpoint_dir = model_save_path.resolve()\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "## Wandb config\n",
    "use_wandb = True\n",
    "wandb_config = {\n",
    "    # wandb param\n",
    "    'name': 'FL_Dino_Baseline_iid',\n",
    "    'project_name': \"FL_test_chart\",\n",
    "    # model config param\n",
    "    \"fraction_fit\": fraction_fit,\n",
    "    \"lr\": lr,\n",
    "    \"momentum\": momentum,\n",
    "    'partition_type': partition_type,\n",
    "    'K': K,\n",
    "    'C': C,\n",
    "    'J': J,\n",
    "}\n",
    "\n",
    "# model editing config\n",
    "model_editing = True\n",
    "mask_type = 'global'\n",
    "sparsity = 0.2\n",
    "mask = None\n",
    "\n",
    "## simulation run config\n",
    "NUM_CLIENTS = 100\n",
    "MAX_PARALLEL_CLIENTS = 10\n",
    "\n",
    "if DEBUG:\n",
    "    use_wandb = False\n",
    "    num_rounds = 4\n",
    "    J = 4\n"
   ],
   "id": "d63bb533ec30809b",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define model , optimizer and loss function",
   "id": "4c0f23c3615c6d68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:59:29.443186Z",
     "start_time": "2025-05-14T14:59:28.169930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fl_g13.modeling import load_or_create\n",
    "\n",
    "# Model\n",
    "model, start_epoch = load_or_create(\n",
    "        path=checkpoint_dir,\n",
    "        model_class=BaseDino,\n",
    "        model_config=None,\n",
    "        optimizer=None,\n",
    "        scheduler=None,\n",
    "        device=device,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "model.to(DEVICE)\n",
    "\n",
    "# optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# Create a dummy mask for SparseSGDM\n",
    "init_mask = [torch.ones_like(p, device=p.device) for p in\n",
    "             model.parameters()]  # Must be done AFTER the model is moved to the device\n",
    "# Optimizer, scheduler, and loss function\n",
    "optimizer = SparseSGDM(\n",
    "    model.parameters(),\n",
    "    mask=init_mask,\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer=optimizer,\n",
    "    T_max=T_max,\n",
    "    eta_min=eta_min\n",
    ")"
   ],
   "id": "9046d19b28a38ed3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_iid_epoch_70.pth\n",
      "📦 Model class in checkpoint: BaseDino\n",
      "🔧 Model configuration: {'variant': 'dino_vits16', 'dropout_rate': 0.0, 'head_hidden_size': 512, 'head_layers': 3, 'num_classes': 100, 'unfreeze_blocks': 1, 'activation_fn': 'GELU', 'pretrained': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n",
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️ Moved model to device: cuda\n",
      "✅ Loaded checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_iid_epoch_70.pth, resuming at epoch 71\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define the Client, Server Apps",
   "id": "e73656b5d73ac995"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:10:05.059238Z",
     "start_time": "2025-05-14T15:10:04.322916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = get_client_app(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=DEVICE,\n",
    "    partition_type=partition_type,\n",
    "    local_epochs=J,\n",
    "    batch_size=batch_size,\n",
    "    num_shards_per_partition=num_shards_per_partition,\n",
    "    scheduler=scheduler,\n",
    "    verbose=0,\n",
    "    model_editing=model_editing,\n",
    "    mask_type=mask_type,\n",
    "    sparsity=sparsity,\n",
    "    mask=mask\n",
    ")"
   ],
   "id": "70467a37aa8c09c7",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:59:34.940233Z",
     "start_time": "2025-05-14T14:59:33.619660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "server = get_server_app(checkpoint_dir=checkpoint_dir,\n",
    "                        model_class=model,\n",
    "                        optimizer=optimizer,\n",
    "                        criterion=criterion,\n",
    "                        scheduler=scheduler,\n",
    "                        num_rounds=num_rounds,\n",
    "                        fraction_fit=fraction_fit,\n",
    "                        fraction_evaluate=fraction_evaluate,\n",
    "                        min_fit_clients=min_fit_clients,\n",
    "                        min_evaluate_clients=min_evaluate_clients,\n",
    "                        min_available_clients=min_available_clients,\n",
    "                        device=device,\n",
    "                        use_wandb=use_wandb,\n",
    "                        wandb_config=wandb_config,\n",
    "                        save_every=save_every,\n",
    "                        prefix='fl_baseline'\n",
    "                        )"
   ],
   "id": "1cbac220e52a6d00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loading checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_iid_epoch_70.pth\n",
      "📦 Model class in checkpoint: BaseDino\n",
      "🔧 Model configuration: {'variant': 'dino_vits16', 'dropout_rate': 0.0, 'head_hidden_size': 512, 'head_layers': 3, 'num_classes': 100, 'unfreeze_blocks': 1, 'activation_fn': 'GELU', 'pretrained': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ADMIN/.cache\\torch\\hub\\facebookresearch_dino_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➡️ Moved model to device: cuda\n",
      "✅ Loaded checkpoint from C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_iid_epoch_70.pth, resuming at epoch 71\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Before training\n",
    "\n",
    "Test model performance before fine-turning"
   ],
   "id": "b0bed2551f5eeb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T14:59:53.975436Z",
     "start_time": "2025-05-14T14:59:52.427346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "testset = datasets.CIFAR100(RAW_DATA_DIR, train=False, download=True, transform=get_eval_transforms())\n",
    "testloader = DataLoader(testset, batch_size=32)"
   ],
   "id": "90f77fa322ad97c1",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:00:28.283689Z",
     "start_time": "2025-05-14T14:59:57.263850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_loss, test_accuracy, _ = eval(testloader, model, criterion)\n",
    "test_loss, test_accuracy"
   ],
   "id": "f9866d97ff7849c7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 313/313 [00:30<00:00, 10.29batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.976986115804305, 0.729)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Run the training\n",
   "id": "1427a966f7544b94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:00:35.515739Z",
     "start_time": "2025-05-14T15:00:34.683230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Specify the resources each of your clients need\n",
    "# By default, each client will be allocated 1x CPU and 0x GPUs\n",
    "backend_config = {\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}}\n",
    "\n",
    "# When running on GPU, assign an entire GPU for each client\n",
    "if DEVICE == \"cuda\":\n",
    "    backend_config[\"client_resources\"] = {\"num_cpus\": 1, \"num_gpus\": 0.5}\n",
    "    # Refer to our Flower framework documentation for more details about Flower simulations\n",
    "    # and how to set up the `backend_config`"
   ],
   "id": "1388e3308f7b212b",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9a1db478a3e1221"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T15:14:55.820049Z",
     "start_time": "2025-05-14T15:10:12.464780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run simulation\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_CLIENTS,\n",
    "    backend_config=backend_config\n",
    ")"
   ],
   "id": "1451e826d4713ec9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server] Server on device: cuda:0\n",
      "[Server] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      Starting Flower ServerApp, config: num_rounds=2, no round_timeout\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [INIT]\n",
      "\u001B[92mINFO \u001B[0m:      Using initial global parameters provided by strategy\n",
      "\u001B[92mINFO \u001B[0m:      Starting evaluation of initial global parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Server Eval Round 0] Model device: cuda:0\n",
      "[Server Eval Round 0] CUDA available in server eval: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 313/313 [00:35<00:00,  8.82batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      [Round 0] Centralized Evaluation - Loss: 0.9770, Metrics: {'centralized_accuracy': 0.729}\n",
      "\u001B[92mINFO \u001B[0m:      initial parameters (loss, other metrics): 0.976986115804305, {'centralized_accuracy': 0.729}\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 1]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "(ClientAppActor pid=3332) 2025-05-14 17:10:53.874 | INFO     | fl_g13.config:<module>:11 - PROJ_ROOT path is: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:01<00:00,  1.07s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: sneezy_rattata_81\n",
      "(ClientAppActor pid=3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:217: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "(ClientAppActor pid=3332)   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.9503\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 76.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.34s | ETA: 4.01s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.9625\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 76.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.51s | ETA: 3.01s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.6948\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 79.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.48s | ETA: 1.48s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.7236\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 77.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.31s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: sassy_pidgey_21\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.7367\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 81.75%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.34s | ETA: 4.03s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.6358\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 81.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.29s | ETA: 2.58s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.5022\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 84.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.42s | ETA: 1.42s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.5006\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 86.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.35s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  4.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: cheeky_raichu_38\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.5547\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 80.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.33s | ETA: 4.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.7074\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 80.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.39s | ETA: 2.78s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4877\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 82.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.45s | ETA: 1.45s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4676\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 83.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.36s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  6.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: grumpy_blastoise_82\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4676\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 82.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.83s | ETA: 5.49s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4596\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 83.75%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.42s | ETA: 2.84s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4361\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 85.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.60s | ETA: 1.60s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.5341\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 86.75%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.40s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  4.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: fluffy_bulbasaur_47\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3287\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 89.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.43s | ETA: 4.28s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3323\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 90.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.34s | ETA: 2.69s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3698\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 90.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.35s | ETA: 1.35s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3588\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 90.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.44s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  6.73batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: jumpy_nidorino_26\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.7974\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 78.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.32s | ETA: 3.96s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.6689\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 78.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.39s | ETA: 2.78s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.6521\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 80.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.70s | ETA: 1.70s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.6416\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 81.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.35s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: frosty_fearow_39\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4735\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 84.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.44s | ETA: 4.32s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4790\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 87.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.33s | ETA: 2.65s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:11\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4495\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 88.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.30s | ETA: 1.30s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:12\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3399\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 88.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.27s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:12\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: bubbly_spearow_97\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3804\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 88.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.34s | ETA: 4.02s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:12\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3584\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 87.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.25s | ETA: 2.51s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:12\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3761\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 88.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.23s | ETA: 1.23s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:12\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.2858\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 91.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.24s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:12\n",
      "(ClientAppActor pid=3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: zippy_ekans_10\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.9187\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 73.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.35s | ETA: 4.05s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:12\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.9287\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 71.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.25s | ETA: 2.50s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:12\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.9350\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 72.75%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.24s | ETA: 1.24s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:12\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.7856\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 74.75%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.21s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:12\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  5.36batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: funky_charizard_91\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.6477\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 79.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.35s | ETA: 4.04s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:12\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.7002\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 83.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.25s | ETA: 2.50s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:12\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4965\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 82.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.26s | ETA: 1.26s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:12\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.5042\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 85.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.22s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:12\n",
      "(ClientAppActor pid=3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      [Round 1] Avg Drift: 0.1130 | Relative Drift: 0.0002\n",
      "\u001B[92mINFO \u001B[0m:      [Round 1] Saving aggregated model at epoch 71...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved checkpoint at: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_71.pth\n",
      "[Server Eval Round 1] Model device: cuda:0\n",
      "[Server Eval Round 1] CUDA available in server eval: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 313/313 [00:31<00:00, 10.08batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      [Round 1] Centralized Evaluation - Loss: 0.9653, Metrics: {'centralized_accuracy': 0.732}\n",
      "\u001B[92mINFO \u001B[0m:      fit progress: (1, 0.9652549539225551, {'centralized_accuracy': 0.732}, 126.72127879999971)\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.89batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.72batch/s]\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.87batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.66batch/s]\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.93batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  8.20batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.66batch/s]\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00, 10.31batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.69batch/s]\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.89batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  9.52batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.72batch/s]\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  8.12batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.45batch/s]\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  8.63batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [ROUND 2]\n",
      "\u001B[92mINFO \u001B[0m:      configure_fit: strategy sampled 10 clients (out of 100)\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.52batch/s]\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: jolly_kakuna_34\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.6020\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 79.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.29s | ETA: 3.87s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.7310\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 80.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.26s | ETA: 2.51s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.8003\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 78.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.31s | ETA: 1.31s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.6789\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 82.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.29s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: nutty_squirtle_51\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3259\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 88.75%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.28s | ETA: 3.83s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3530\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 89.75%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.23s | ETA: 2.46s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4315\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 88.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.21s | ETA: 1.21s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3222\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 90.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.23s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: groovy_squirtle_72\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.6163\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 80.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.27s | ETA: 3.81s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.6406\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 81.75%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.22s | ETA: 2.44s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.6894\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 81.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.23s | ETA: 1.23s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.6120\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 83.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.20s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  8.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: cheeky_ivysaur_62\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4633\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 86.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.31s | ETA: 3.94s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4424\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 88.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.22s | ETA: 2.44s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4340\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 88.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.20s | ETA: 1.20s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3519\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 88.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.23s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: soggy_beedrill_42\n",
      "(ClientAppActor pid=3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[91mERROR \u001B[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001B[91mERROR \u001B[0m:     \u001B[36mray::ClientAppActor.run()\u001B[39m (pid=3332, ip=127.0.0.1, actor_id=6ed380f6e364563de4a8a83a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x00000288E24FCC40>)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\client_app.py\", line 144, in __call__\n",
      "    return self._call(message, context)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\client_app.py\", line 128, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 128, in handle_legacy_message_from_msgtype\n",
      "    fit_res = maybe_call_fit(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\client.py\", line 224, in maybe_call_fit\n",
      "    return client.fit(fit_ins)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\numpy_client.py\", line 227, in _fit\n",
      "    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\fl_pytorch\\client_app.py\", line 113, in fit\n",
      "    all_training_losses, _, all_training_accuracies, _ = train(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\modeling\\train.py\", line 178, in train\n",
      "    train_loss, training_accuracy, _ = train_one_epoch(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\modeling\\train.py\", line 70, in train_one_epoch\n",
      "    optimizer.step()\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 493, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\editing\\sparseSGDM.py\", line 127, in step\n",
      "    p.data.add_(grad * m, alpha=-lr)\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001B[36mray::ClientAppActor.run()\u001B[39m (pid=3332, ip=127.0.0.1, actor_id=6ed380f6e364563de4a8a83a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x00000288E24FCC40>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1890, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1991, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "\u001B[91mERROR \u001B[0m:     Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\vce_api.py\", line 111, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 187, in process_message\n",
      "    raise ex\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 175, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001B[36mray::ClientAppActor.run()\u001B[39m (pid=3332, ip=127.0.0.1, actor_id=6ed380f6e364563de4a8a83a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x00000288E24FCC40>)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\client_app.py\", line 144, in __call__\n",
      "    return self._call(message, context)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\client_app.py\", line 128, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 128, in handle_legacy_message_from_msgtype\n",
      "    fit_res = maybe_call_fit(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\client.py\", line 224, in maybe_call_fit\n",
      "    return client.fit(fit_ins)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\numpy_client.py\", line 227, in _fit\n",
      "    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\fl_pytorch\\client_app.py\", line 113, in fit\n",
      "    all_training_losses, _, all_training_accuracies, _ = train(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\modeling\\train.py\", line 178, in train\n",
      "    train_loss, training_accuracy, _ = train_one_epoch(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\modeling\\train.py\", line 70, in train_one_epoch\n",
      "    optimizer.step()\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 493, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\editing\\sparseSGDM.py\", line 127, in step\n",
      "    p.data.add_(grad * m, alpha=-lr)\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001B[36mray::ClientAppActor.run()\u001B[39m (pid=3332, ip=127.0.0.1, actor_id=6ed380f6e364563de4a8a83a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x00000288E24FCC40>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1890, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1991, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  9.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: bubbly_sandshrew_88\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.6490\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 78.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.27s | ETA: 3.81s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.8662\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 77.75%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.27s | ETA: 2.53s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.5620\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 80.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.28s | ETA: 1.28s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.5609\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 83.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.22s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  7.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: breezy_wartortle_28\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.5683\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 82.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.30s | ETA: 3.91s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.5772\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 83.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.25s | ETA: 2.49s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.5680\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 83.75%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.28s | ETA: 1.28s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.5811\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 84.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.29s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  8.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: dorky_pidgey_18\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.6248\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 84.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.30s | ETA: 3.89s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.5424\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 86.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.33s | ETA: 2.65s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3697\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 87.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.27s | ETA: 1.27s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:13\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3934\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 87.50%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.28s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:14\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n",
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: loopy_weedle_38\n",
      "(ClientAppActor pid=3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[91mERROR \u001B[0m:     An exception was raised when processing a message by RayBackend\n",
      "\u001B[91mERROR \u001B[0m:     \u001B[36mray::ClientAppActor.run()\u001B[39m (pid=3332, ip=127.0.0.1, actor_id=6ed380f6e364563de4a8a83a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x00000288E24FCC40>)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\client_app.py\", line 144, in __call__\n",
      "    return self._call(message, context)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\client_app.py\", line 128, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 128, in handle_legacy_message_from_msgtype\n",
      "    fit_res = maybe_call_fit(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\client.py\", line 224, in maybe_call_fit\n",
      "    return client.fit(fit_ins)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\numpy_client.py\", line 227, in _fit\n",
      "    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\fl_pytorch\\client_app.py\", line 113, in fit\n",
      "    all_training_losses, _, all_training_accuracies, _ = train(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\modeling\\train.py\", line 178, in train\n",
      "    train_loss, training_accuracy, _ = train_one_epoch(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\modeling\\train.py\", line 70, in train_one_epoch\n",
      "    optimizer.step()\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 493, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\editing\\sparseSGDM.py\", line 127, in step\n",
      "    p.data.add_(grad * m, alpha=-lr)\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001B[36mray::ClientAppActor.run()\u001B[39m (pid=3332, ip=127.0.0.1, actor_id=6ed380f6e364563de4a8a83a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x00000288E24FCC40>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1890, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1991, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "\u001B[91mERROR \u001B[0m:     Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\vce_api.py\", line 111, in worker\n",
      "    out_mssg, updated_context = backend.process_message(message, context)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 187, in process_message\n",
      "    raise ex\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\server\\superlink\\fleet\\vce\\backend\\raybackend.py\", line 175, in process_message\n",
      "    ) = self.pool.fetch_result_and_return_actor_to_pool(future)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 480, in fetch_result_and_return_actor_to_pool\n",
      "    _, out_mssg, updated_context = ray.get(future)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 2639, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\_private\\worker.py\", line 864, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(ClientAppException): \u001B[36mray::ClientAppActor.run()\u001B[39m (pid=3332, ip=127.0.0.1, actor_id=6ed380f6e364563de4a8a83a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x00000288E24FCC40>)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\client_app.py\", line 144, in __call__\n",
      "    return self._call(message, context)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\client_app.py\", line 128, in ffn\n",
      "    out_message = handle_legacy_message_from_msgtype(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\message_handler\\message_handler.py\", line 128, in handle_legacy_message_from_msgtype\n",
      "    fit_res = maybe_call_fit(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\client.py\", line 224, in maybe_call_fit\n",
      "    return client.fit(fit_ins)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\client\\numpy_client.py\", line 227, in _fit\n",
      "    results = self.numpy_client.fit(parameters, ins.config)  # type: ignore\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\fl_pytorch\\client_app.py\", line 113, in fit\n",
      "    all_training_losses, _, all_training_accuracies, _ = train(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\modeling\\train.py\", line 178, in train\n",
      "    train_loss, training_accuracy, _ = train_one_epoch(\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\modeling\\train.py\", line 70, in train_one_epoch\n",
      "    optimizer.step()\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 493, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\fl_g13\\editing\\sparseSGDM.py\", line 127, in step\n",
      "    p.data.add_(grad * m, alpha=-lr)\n",
      "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001B[36mray::ClientAppActor.run()\u001B[39m (pid=3332, ip=127.0.0.1, actor_id=6ed380f6e364563de4a8a83a01000000, repr=<flwr.simulation.ray_transport.ray_actor.ClientAppActor object at 0x00000288E24FCC40>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1890, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1991, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1896, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1837, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 691, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 467, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\.venv\\lib\\site-packages\\flwr\\simulation\\ray_transport\\ray_actor.py\", line 64, in run\n",
      "    raise ClientAppException(str(ex)) from ex\n",
      "flwr.client.client_app.ClientAppException: \n",
      "Exception ClientAppException occurred. Message: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n",
      "\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  8.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) No prefix/name for the model was provided, choosen prefix/name: zesty_butterfree_60\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 1/4 (25.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4232\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 87.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.26s | ETA: 3.79s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:14\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 2/4 (50.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4091\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 86.00%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.20s | ETA: 2.41s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:14\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 3/4 (75.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.4065\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 89.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.21s | ETA: 1.21s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:14\n",
      "(ClientAppActor pid=3332) \n",
      "(ClientAppActor pid=3332) 🚀 Epoch 4/4 (100.00%) Completed\n",
      "(ClientAppActor pid=3332) \t📊 Training Loss: 0.3961\n",
      "(ClientAppActor pid=3332) \t✅ Training Accuracy: 90.25%\n",
      "(ClientAppActor pid=3332) \t⏳ Elapsed Time: 1.20s | ETA: 0.00s\n",
      "(ClientAppActor pid=3332) \t🕒 Completed At: 17:14\n",
      "(ClientAppActor pid=3332) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO \u001B[0m:      aggregate_fit: received 8 results and 2 failures\n",
      "\u001B[92mINFO \u001B[0m:      [Round 2] Avg Drift: 0.1101 | Relative Drift: 0.0002\n",
      "\u001B[92mINFO \u001B[0m:      [Round 2] Saving aggregated model at epoch 72...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Saved checkpoint at: C:\\Users\\ADMIN\\Desktop\\BACKUP\\study\\Italy\\polito\\classes\\20242\\deep learning\\project\\source_code\\fl-g13\\models\\fl_dino_baseline\\iid\\fl_fl_baseline_BaseDino_epoch_72.pth\n",
      "[Server Eval Round 2] Model device: cuda:0\n",
      "[Server Eval Round 2] CUDA available in server eval: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress: 100%|██████████| 313/313 [00:30<00:00, 10.34batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      [Round 2] Centralized Evaluation - Loss: 0.9545, Metrics: {'centralized_accuracy': 0.7342}\n",
      "\u001B[92mINFO \u001B[0m:      fit progress: (2, 0.9545405791542781, {'centralized_accuracy': 0.7342}, 229.12336509999932)\n",
      "\u001B[92mINFO \u001B[0m:      configure_evaluate: strategy sampled 10 clients (out of 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  6.67batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  8.99batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.56batch/s]\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  9.90batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.52batch/s]\n",
      "Fisher Score:   0%|          | 0/1 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fisher Score: 100%|██████████| 1/1 [00:00<00:00,  8.99batch/s]\n",
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ClientAppActor pid=3332) [Client] Client on device: cuda:0\n",
      "(ClientAppActor pid=3332) [Client] CUDA available in client: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval progress:   0%|          | 0/1 [00:00<?, ?batch/s]\n",
      "\u001B[92mINFO \u001B[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "\u001B[92mINFO \u001B[0m:      [SUMMARY]\n",
      "\u001B[92mINFO \u001B[0m:      Run finished 2 round(s) in 243.44s\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, distributed):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 0.9988244712352753\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 1.0302831828594208\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (loss, centralized):\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 0: 0.976986115804305\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 1: 0.9652549539225551\n",
      "\u001B[92mINFO \u001B[0m:      \t\tround 2: 0.9545405791542781\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, distributed, fit):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'avg_drift': [(1, 0.11302309930324554), (2, 0.11005966458469629)],\n",
      "\u001B[92mINFO \u001B[0m:      \t 'avg_train_loss': [(1, 0.5141701810061932), (2, 0.4870726624503732)]}\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'decentralized_avg_eval_accuracy': [(1, 0.713), (2, 0.721)]}\n",
      "\u001B[92mINFO \u001B[0m:      \tHistory (metrics, centralized):\n",
      "\u001B[92mINFO \u001B[0m:      \t{'centralized_accuracy': [(0, 0.729), (1, 0.732), (2, 0.7342)]}\n",
      "\u001B[92mINFO \u001B[0m:      \n",
      "Eval progress: 100%|██████████| 1/1 [00:00<00:00,  3.69batch/s]\n"
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
